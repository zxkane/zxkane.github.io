<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Amazon Redshift on The road</title><link>https://kane.mx/tags/amazon-redshift/</link><description>Recent content in Amazon Redshift on The road</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 22 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://kane.mx/tags/amazon-redshift/index.xml" rel="self" type="application/rss+xml"/><item><title>Deep dive clickstream analytic series: Data Modeling</title><link>https://kane.mx/posts/deep-dive-clickstream-analytics/data-modeling/</link><pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/deep-dive-clickstream-analytics/data-modeling/</guid><description>
&lt;p>In this post, we will delve into the data modeling module of our &lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/preface/">clickstream solution&lt;/a>. This module is an optional component that creates data models in the &lt;a href="https://aws.amazon.com/redshift/">Amazon Redshift&lt;/a> data warehouse and calculates reporting dimensions based on the event, session, and user factor tables generated in the &lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/">data processing module&lt;/a>.&lt;/p>
&lt;h2 id="overview-architecture">Overview Architecture&lt;/h2>
&lt;p>
&lt;figure>
&lt;picture>
&lt;source srcset="https://kane.mx/posts/deep-dive-clickstream-analytics/data-modeling/images/architecture.avif" type="image/avif">
&lt;source srcset="https://kane.mx/posts/deep-dive-clickstream-analytics/data-modeling/images/architecture.webp" type="image/webp">
&lt;img
loading="lazy"
decoding="async"
alt="Overview architecture"
class="image_figure image_internal image_processed"
width="1000"
height="777"
src="https://kane.mx/posts/deep-dive-clickstream-analytics/data-modeling/images/architecture.png"
title="Overview architecture for data modeling module"
/>
&lt;figcaption class="caption_figure caption_internal">Overview architecture for data modeling module&lt;/figcaption>&lt;/picture>
&lt;/figure>
&lt;/p>
&lt;p>The overview architecture demonstrates how the solution orchestrates loading clickstream data into the Amazon Redshift data warehouse and triggers data modeling within Redshift.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/data-modeling/">Read More&lt;/a>&lt;/p></description></item><item><title>Redshift Serverless: Cost Deep Dive and Use Cases</title><link>https://kane.mx/posts/2024/redshift-serverless-cost-deep-dive/</link><pubDate>Sat, 24 Feb 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/redshift-serverless-cost-deep-dive/</guid><description>
&lt;p>Serverless computing is all the rage, promising pay-as-you-go magic and freedom from infrastructure woes. But what about serverless for data warehouses? Let's delve into the fascinating (and sometimes confusing) world of &lt;strong>&lt;a href="https://aws.amazon.com/redshift/redshift-serverless/">Redshift Serverless&lt;/a>&lt;/strong>: its cost structure, ideal use cases, and situations where it might not be the best fit.&lt;/p>
&lt;h2 id="cost-breakdown-beyond-the-illusion-of-free">Cost Breakdown: Beyond the Illusion of Free&lt;/h2>
&lt;p>Redshift Serverless offers a compelling promise: only pay for what you use. But like any good magic trick, there's more to the story. Here's the primary cost breakdown:&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/redshift-serverless-cost-deep-dive/">Read More&lt;/a>&lt;/p></description></item></channel></rss>