<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>effective-cloud-computing on The road</title><link>https://kane.mx/series/effective-cloud-computing/</link><description>Recent content in effective-cloud-computing on The road</description><generator>Hugo -- gohugo.io</generator><copyright>Copyright © 2021, Kane Zhu; all rights reserved.</copyright><lastBuildDate>Fri, 16 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://kane.mx/series/effective-cloud-computing/index.xml" rel="self" type="application/rss+xml"/><item><title>在AWS上快速部署专用的NAT实例</title><link>https://kane.mx/posts/2021/simple-nat-on-aws/</link><pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/simple-nat-on-aws/</guid><description>
&lt;p>本方案的起因是，一个源代码托管在Github上的项目fix一个重要的bug后，在AWS上的持续部署流水线一直失败。分析日志后，发现流水线中的数个步骤需要克隆源代码，但是访问Github的网络非常不稳定，这数个流水线任务持续因连接超时，连接拒绝等网络错误而失败。而流水线任务大量使用了CodeBuild, Lambda等AWS托管服务，无法为执行环境配置可靠的网络连接。&lt;/p>
&lt;p>本方案思路如下，&lt;/p>
&lt;ul>
&lt;li>在 VPC public subnets 中创建 NAT instance 即 EC2 虚拟机，&lt;/li>
&lt;li>配置 NAT instance，使用 tunnel 网络访问 github，&lt;/li>
&lt;li>修改 private subnets 的路由表，添加 github 服务的 IP CIDRs，将对这些IP地址的请求通过 NAT instance 转发。&lt;/li>
&lt;/ul>
&lt;p>综上，实现了不用对现有持续部署流水线做任何修改，流水线中运行在 VPC private subnet 内的任务(包括但不限于CodeBuild, Fargate, Lambda, Glue等)，对外网的请求目标地址如在路由表的特殊规则(IP CIDRs)中，网络请求将会通过 NAT instance 来转发。&lt;/p>
&lt;p>为此，创建了一个基于 &lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a> &lt;a href="https://docs.aws.amazon.com/cdk/latest/guide/constructs.html">construct&lt;/a> 的开源项目 &lt;a href="https://github.com/zxkane/snat">SimpleNAT&lt;/a> 来封装和复用创建配置 NAT instances，并且将指定的IP地址段更新到路由表设置路由规则。&lt;/p>
&lt;p>该项目同时提供了一个&lt;a href="https://github.com/zxkane/snat/tree/main/example">完整示例应用&lt;/a>，演示了如何配置 NAT instance 使用 &lt;a href="https://github.com/sshuttle/sshuttle">sshuttle&lt;/a> 建立网络隧道，并且将指定的IP地址段请求通过 NAT instance 来转发。&lt;/p></description></item><item><title>Effective AWS CDK for AWS CloudFormation</title><link>https://kane.mx/posts/2020/effective-aws-cdk-for-aws-cloudformation/</link><pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/effective-aws-cdk-for-aws-cloudformation/</guid><description>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">Infrastructure as Code&lt;/a> is the trend to manage the resources of application. &lt;a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation&lt;/a> is the managed serive offering the IaC capability on AWS &lt;a href="https://aws.amazon.com/blogs/aws/cloudformation-create-your-aws-stack-from-a-recipe/">since 2011&lt;/a>. CloudFormation uses the &lt;a href="https://en.wikipedia.org/wiki/Declarative_programming">declarative language&lt;/a> to manage your AWS resources with the style what you get is what you declare.&lt;/p>
&lt;p>However there are cons of CloudFormation as a declarative language,&lt;/p>
&lt;ul>
&lt;li>the readability and maintanence for applications involving lots of resources&lt;/li>
&lt;li>the reuseable of code, &lt;a href="https://aws.amazon.com/blogs/mt/introducing-aws-cloudformation-modules/">CloudFormation modules&lt;/a> released in re:Invent 2020 might help mitgate it&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a> provides the programming way to define the infra in code by your preferred programming languages, such as Typescript, Javascripte, Python, Java and C#. AWS CDK will synthesis the code to CloudFormation template, then deploying the stack via AWS CloudForamtion service. It benefits the Devops engineers manage the infra on AWS as programming application, having version control, code review, unit testing, integration testing and CI/CD pipelines, the deployment still depends on the mature CloudFormation service to rolling update the resources and rollback when failing.&lt;/p>
&lt;p>For solution development, using CDK indeed improves the productivity then publish the deployment assets as CloudFormation templates.&lt;/p>
&lt;p>Though CDK application can be synthesized to CloudFormation template, there are still some differences blocking the synthesized tempaltes to be deployed across multiple AWS regeions.&lt;/p>
&lt;p>This post will share the tips on how effectively writing AWS CDK application then deploying the application by CloudFormation across multiple regions.&lt;/p>
&lt;h2 id="general">General&lt;/h2>
&lt;h3 id="environment-agnostic-stack">Environment-agnostic stack&lt;/h3>
&lt;p>Don’t specify env with &lt;code>account&lt;/code> and &lt;code>region&lt;/code> like below that will generate account/region hardcode in CloudFormation template.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-ts" data-lang="ts">&lt;span class="ln">1&lt;/span>&lt;span class="k">new&lt;/span> &lt;span class="nx">MyStack&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">app&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Stack1&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="nx">env&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="nx">account&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;123456789012&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="nx">region&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;us-east-1&amp;#39;&lt;/span>
&lt;span class="ln">5&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">6&lt;/span>&lt;span class="p">});&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;h3 id="use-cfnmappingcfncondition-instead-of-if-else-clause">use CfnMapping/CfnCondition instead of if-else clause&lt;/h3>
&lt;p>CloudFormation does not have logistic processing like programming language. Use &lt;code>CfnMapping&lt;/code> or &lt;code>CfnCondition&lt;/code> instead.&lt;/p>
&lt;p>&lt;strong>Note&lt;/strong>: the &lt;code>CfnMapping&lt;/code> does not support default value, you have to list all supported regions like below code snippet,&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-ts" data-lang="ts">&lt;span class="ln"> 1&lt;/span>&lt;span class="nx">getAwsLoadBalancerControllerRepo() {&lt;/span>
&lt;span class="ln"> 2&lt;/span> &lt;span class="kr">const&lt;/span> &lt;span class="nx">albImageMapping&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">CfnMapping&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;ALBImageMapping&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="nx">mapping&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="s1">&amp;#39;me-south-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;558608220178&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="s1">&amp;#39;eu-south-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;590381155156&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="s1">&amp;#39;ap-northeast-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;602401143452&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="s1">&amp;#39;ap-northeast-2&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;602401143452&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="p">...&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="s1">&amp;#39;ap-east-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;800184023465&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="s1">&amp;#39;af-south-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">21&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;877085696533&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">22&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">23&lt;/span> &lt;span class="s1">&amp;#39;cn-north-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">24&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;918309763551&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">25&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">26&lt;/span> &lt;span class="s1">&amp;#39;cn-northwest-1&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">27&lt;/span> &lt;span class="mi">2&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;961992271922&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">28&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">29&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">30&lt;/span> &lt;span class="p">});&lt;/span>
&lt;span class="ln">31&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="sb">`&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nx">albImageMapping&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">findInMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Aws&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">REGION&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;2&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="sb">.dkr.ecr.&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Aws&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">REGION&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="sb">.&lt;/span>&lt;span class="si">${&lt;/span>&lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Aws&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">URL_SUFFIX&lt;/span>&lt;span class="si">}&lt;/span>&lt;span class="sb">/amazon/aws-load-balancer-controller`&lt;/span>&lt;span class="p">;&lt;/span>
&lt;span class="ln">32&lt;/span> &lt;span class="p">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;h2 id="never-use-stackregion">never use Stack.region&lt;/h2>
&lt;p>&lt;strong>Don’t&lt;/strong> rely on &lt;code>stack.region&lt;/code> to do the logistic for China regions. Use additional &lt;code>context&lt;/code> parameter or &lt;code>CfnMapping&lt;/code> like below snippet,&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-ts" data-lang="ts">&lt;span class="ln"> 1&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">partitionMapping&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">CfnMapping&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;PartitionMapping&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 2&lt;/span> &lt;span class="nx">mapping&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="nx">aws&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="nx">nexus&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;quay.io/travelaudience/docker-nexus&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="nx">nexusProxy&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;quay.io/travelaudience/docker-nexus-proxy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="s1">&amp;#39;aws-cn&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nx">nexus&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;048912060910.dkr.ecr.cn-northwest-1.amazonaws.com.cn/quay/travelaudience/docker-nexus&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="nx">nexusProxy&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;048912060910.dkr.ecr.cn-northwest-1.amazonaws.com.cn/quay/travelaudience/docker-nexus-proxy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="p">});&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="nx">partitionMapping&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">findInMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Aws&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">PARTITION&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;nexus&amp;#39;&lt;/span>&lt;span class="p">);&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Use &lt;strong>core.Aws.region&lt;/strong> token refered to the region which region of the stack is deployed.&lt;/p>
&lt;h3 id="explicitly-add-dependencies-on-resources-to-control-the-creationdeletion-order-of-resources">explicitly add dependencies on resources to control the creation/deletion order of resources&lt;/h3>
&lt;p>For example, when deploying a solution with creating a new VPC with NAT gateway, then deploying EMR cluster in private subnets of VPC. The EMR cluster might fail on creation due to network issue. It’s caused by the NAT gateway is not ready when initializing the EMR cluster, you have to manually create the dependencies among EMR cluster and NAT gateway.&lt;/p>
&lt;h2 id="eks-moduleaws-cdkaws-eks">EKS module(@aws-cdk/aws-eks)&lt;/h2>
&lt;h3 id="specify-kubectl-layer-when-creating-eks-cluster">&lt;del>specify kubectl layer when creating EKS cluster&lt;/del>&lt;/h3>
&lt;p>&lt;strong>NOTE&lt;/strong>: This tricky only applies for AWS CDK prior to &lt;a href="https://github.com/aws/aws-cdk/releases/tag/v1.81.0">1.81.0&lt;/a>. CDK will &lt;a href="https://github.com/aws/aws-cdk/pull/12129">bundle &lt;code>kubectl&lt;/code>, &lt;code>helm&lt;/code> and &lt;code>awscli&lt;/code> as lambda layer&lt;/a> instead of SAR appliction since &lt;a href="https://github.com/aws/aws-cdk/releases/tag/v1.81.0">1.81.0&lt;/a>, it resolves below limitation.&lt;/p>
&lt;p>EKS uses a lambda layer to run &lt;code>kubectl&lt;/code>/&lt;code>helm&lt;/code> cli as custom resource, the &lt;code>@aws-cdk/aws-eks&lt;/code> module depends on the &lt;code>Stack.region&lt;/code> to check the region to be deployed in synthesizing phase. It violates the principle of Environment-agnostic stack! Use below workaround to create the EKS cluster,&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-ts" data-lang="ts">&lt;span class="ln"> 1&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">partitionMapping&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">CfnMapping&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;PartitionMapping&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 2&lt;/span> &lt;span class="nx">mapping&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="nx">aws&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="c1">// see https://github.com/aws/aws-cdk/blob/60c782fe173449ebf912f509de7db6df89985915/packages/%40aws-cdk/aws-eks/lib/kubectl-layer.ts#L6
&lt;/span>&lt;span class="ln"> 5&lt;/span>&lt;span class="c1">&lt;/span> &lt;span class="nx">kubectlLayerAppid&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;arn:aws:serverlessrepo:us-east-1:903779448426:applications/lambda-layer-kubectl&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="s1">&amp;#39;aws-cn&amp;#39;&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nx">kubectlLayerAppid&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;arn:aws-cn:serverlessrepo:cn-north-1:487369736442:applications/lambda-layer-kubectl&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="p">});&lt;/span>
&lt;span class="ln">12&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">kubectlLayer&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">eks&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">KubectlLayer&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;KubeLayer&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="nx">applicationId&lt;/span>: &lt;span class="kt">partitionMapping.findInMap&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">cdk&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Aws&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">PARTITION&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;kubectlLayerAppid&amp;#39;&lt;/span>&lt;span class="p">),&lt;/span>
&lt;span class="ln">15&lt;/span>&lt;span class="p">});&lt;/span>
&lt;span class="ln">16&lt;/span>&lt;span class="kr">const&lt;/span> &lt;span class="nx">cluster&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">eks&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Cluster&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;MyK8SCluster&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="nx">vpc&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">18&lt;/span> &lt;span class="nx">defaultCapacity&lt;/span>: &lt;span class="kt">0&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">19&lt;/span> &lt;span class="nx">kubectlEnabled&lt;/span>: &lt;span class="kt">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">20&lt;/span> &lt;span class="nx">mastersRole&lt;/span>: &lt;span class="kt">clusterAdmin&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">21&lt;/span> &lt;span class="nx">version&lt;/span>: &lt;span class="kt">eks.KubernetesVersion.V1_16&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">22&lt;/span> &lt;span class="nx">coreDnsComputeType&lt;/span>: &lt;span class="kt">eks.CoreDnsComputeType.EC2&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">23&lt;/span> &lt;span class="nx">kubectlLayer&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">24&lt;/span>&lt;span class="p">});&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>If you're interested on this issue, &lt;a href="https://github.com/aws/aws-cdk/issues/12018">see cdk issue for detail&lt;/a>.&lt;/p>
&lt;h3 id="manage-the-lifecycle-of-helm-chart-deployment">manage the lifecycle of helm chart deployment&lt;/h3>
&lt;p>The k8s helm chart might create AWS resources out of CloudFormation scope. You have to manage the lifecycle of those resources by yourself.&lt;/p>
&lt;p>For example, there is an EKS cluster with AWS load balancer controller, then you deploy a helm chart with ingress that will create ALB/NLB by the chart, you must clean those load balancers in deletion of the chart. Also the uninstallation of Helm chart is asynchronous, you have to watch the deletion of resource completing before continuing to clean other resources.&lt;/p>
&lt;h2 id="the-end">THE END&lt;/h2>
&lt;blockquote>
&lt;p>The tips will be updated when something new is found or the one is deprecated after CDK is updated.&lt;/p>
&lt;p>HAPPY CDK :satisfied:&lt;/p>
&lt;/blockquote></description></item><item><title>跨账号跨区域部署AWS CDK编排的应用</title><link>https://kane.mx/posts/2020/deploy-aws-cdk-applications-cross-accounts/</link><pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/deploy-aws-cdk-applications-cross-accounts/</guid><description>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a>是编排部署AWS云上资源最佳的工具之一。基于AWS CDK的应用应该如何实践DevOps持续集成和部署呢？&lt;/p>
&lt;p>通常我们有下面几种方法，&lt;/p>
&lt;ol>
&lt;li>使用&lt;a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline&lt;/a>来完成DevOps pipeline搭建。CodePipeline是AWS Code系列服务中的持续集成编排工具，它可以集成CodeBuild项目，在CodeBuild项目build中安装&lt;code>cdk&lt;/code>，并执行&lt;code>cdk deploy&lt;/code>命令来实现应用部署。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>这种方法简单直接的实现了DevOps部署流水线。但缺少staging，将最新提交直接部署到生产是一种非常高风险的做法。&lt;/p>
&lt;/blockquote>
&lt;ol start="2">
&lt;li>CDK近期发布了体验性的新特性&lt;a href="https://aws.amazon.com/blogs/developer/cdk-pipelines-continuous-delivery-for-aws-cdk-applications/">CDK Pipelines&lt;/a>来封装CDK应用持续部署流水线的配置。CDK Pipelines也是基于AWS CodePipeline服务，提供快速创建可跨账号区域的持续部署流水线，同时支持部署流水线项目的自升级更新。整个流水线流程如下图所示，&lt;/li>
&lt;/ol>
&lt;figure>&lt;img src="https://d2908q01vomqb2.cloudfront.net/0716d9708d321ffb6a00818614779e779925365c/2020/07/02/CDKPipelines_1.png"
alt="workflow of cdk pipelines"/>
&lt;/figure>
&lt;p>CDK Pipelines是非常高效且灵活的持续部署流水线创建的方式，但由于是体验性特性，在生产应用中还有一些局限性。例如，&lt;/p>
&lt;ul>
&lt;li>不支持context provider查找。也就是说，无法支持CDK应用查找账户中存在的VPC，R53 HostedZone等。&lt;/li>
&lt;li>由于CDK Pipelines实际是使用CodePipeline来编排部署流水线，CodePipeline的局限性，CDK Pipelines同样存在。&lt;/li>
&lt;li>CodePipeline在某些分区和区域还不可用。例如，AWS中国区暂时还没有CodePipeline服务，CDK Pipelines在AWS中国区也就无法使用。&lt;/li>
&lt;/ul>
&lt;ol start="3">
&lt;li>使用&lt;a href="https://aws.amazon.com/step-functions/">AWS Step Functions&lt;/a>来编排CDK应用部署的流水线。在Step Functions编译的部署流水线中，可用通过CodeBuild项目来完成&lt;code>cdk deploy&lt;/code>执行做到完整的支持CDK的所有功能。同时Step Functions具备最大的灵活性来支持持续部署过程中的各种编排需求，例如，跨账户部署应用的不同stage，引入人工审批流程，通过Slack等chatops工具来完成审批。&lt;/li>
&lt;/ol>
&lt;p>&lt;a href="https://opentuna.cn">Opentuna&lt;/a>项目就实践了用Step Functions来编排&lt;a href="https://github.com/tuna/opentuna/blob/master/pipeline.md">持续部署流水线&lt;/a>。整个部署流程如下图，&lt;/p>
&lt;figure>&lt;img src="images/opentuna-pipeline.png"
alt="OpenTUNA部署流程"/>
&lt;/figure>
&lt;p>如果对基于Step Functions实现的CDK应用持续部署感兴趣，可以访问OpenTUNA项目实现的&lt;a href="https://github.com/tuna/opentuna/blob/master/lib/pipeline-stack.ts">源码&lt;/a>了解更多细节。&lt;/p></description></item><item><title>Deploy Sonatype Nexus repository OSS on EKS</title><link>https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/</link><pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/</guid><description>
&lt;p>&lt;a href="https://www.sonatype.com/nexus-repository-oss">Sonatype Nexus repository OSS&lt;/a> is an artifact repository that supports most software repositories such as Maven, Pypi, Npmjs, Rubygems, Yum, Apt, Docker registry and etc. In the enterprise Nexus repository is widely used for storing proprietary artifacts and caching the artifacts for speeding up the devops.&lt;/p>
&lt;p>Building a production ready Nexus repository always is a requirement for devops team, it should satisfy below criterias at least,&lt;/p>
&lt;ul>
&lt;li>&lt;strong>artifacts storage management&lt;/strong> It's difficult to predicate the storage usage of artifacts, allocating large volume is not cost optimized.&lt;/li>
&lt;li>&lt;strong>the durability of nexus3 data storage&lt;/strong> We need a way to make sure data storage of nexus when updating Nexus OSS to newer version or recover the service from unhealthy status.&lt;/li>
&lt;li>&lt;strong>self healing capability when the service is down&lt;/strong> A reliable way recovers the Nexus repository OSS when it's unhealth.&lt;/li>
&lt;/ul>
&lt;p>There is a well-architected &lt;a href="https://github.com/aws-samples/nexus-oss-on-aws">solution&lt;/a>(maintained by AWS team) to quickly(~10 minutes) deploy &lt;a href="https://www.sonatype.com/nexus-repository-oss">Nexus OSS&lt;/a> leveraging below capabilities,&lt;/p>
&lt;ul>
&lt;li>Host on EKS cluster using managed EC2 nodes with &lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html">IRSA&lt;/a>&lt;/li>
&lt;li>Expose service via AWS Application load balancer managed by &lt;a href="https://github.com/kubernetes-sigs/aws-load-balancer-controller">AWS load balancer controller&lt;/a>(former ALB Ingress Controller)&lt;/li>
&lt;li>Use dedicated S3 bucket for storing Nexus OSS blobstore with ulimited and on-demand storage&lt;/li>
&lt;li>Use EFS, &lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/efs-csi.html">EFS CSI Driver&lt;/a>, PV and PVC storing nexus data&lt;/li>
&lt;li>Use &lt;a href="https://helm.sh/">Helm&lt;/a> to deploy &lt;a href="https://hub.helm.sh/charts/oteemo/sonatype-nexus">Sonatype Nexus chart&lt;/a>&lt;/li>
&lt;li>&lt;code>Optional&lt;/code> Use &lt;a href="https://github.com/kubernetes-sigs/external-dns">External DNS&lt;/a> to registry the domain record of Nexus repository to Route 53&lt;/li>
&lt;li>&lt;code>Optional&lt;/code> Use AWS Certificate Manager to create SSL certificate of domain name of Nexus repository&lt;/li>
&lt;/ul>
&lt;p>Enjoy it:smirk:&lt;/p></description></item><item><title>无服务器架构的Docker镜像数据分析应用</title><link>https://kane.mx/posts/2020/serverless-docker-images-analytics/</link><pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/serverless-docker-images-analytics/</guid><description>
&lt;p>近期对Docker镜像做了些数据分析，这里分享一下利用云原生技术快速且低成本的实现任意数量的数据分析。&lt;/p>
&lt;p>之前通过文章介绍了&lt;a href="https://kane.mx/posts/2020/get-docker-image-size-without-pulling-image/">不用拉取Docker镜像就可获取镜像的大小&lt;/a>的一种方法，通过其中的示例脚本，我们可以获取到待分析的原始数据。&lt;/p>
&lt;p>比如&lt;code>nginx&lt;/code>镜像的部分原始数据(csv格式)如下，&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-txt" data-lang="txt">1.18.0-alpine,sha256:676b8117782d9e8c20af8e1b19356f64acc76c981f3a65c66e33a9874877892a,amd64,linux,null,null,&amp;#34;sha256:cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08&amp;#34;,2813316
1.18.0-alpine,sha256:676b8117782d9e8c20af8e1b19356f64acc76c981f3a65c66e33a9874877892a,amd64,linux,null,null,&amp;#34;sha256:6ade829cd166df9b2331da48e3e60342aef9f95e1e45cde8d20e6b01be7e6d9a&amp;#34;,6477096
1.18.0-alpine,sha256:70feed62d5204358ed500463c0953dce6c269a0ebeef147a107422a2c78799a9,arm,linux,v6,null,&amp;#34;sha256:b9e3228833e92f0688e0f87234e75965e62e47cfbb9ca8cc5fa19c2e7cd13f80&amp;#34;,2619936
1.18.0-alpine,sha256:70feed62d5204358ed500463c0953dce6c269a0ebeef147a107422a2c78799a9,arm,linux,v6,null,&amp;#34;sha256:a03f81873d278ad248976b107883f0452d33c6f907ebcdd832a6041f1d33118a&amp;#34;,6080562
1.18.0-alpine,sha256:2ba714ccbdc4c2a7b5a5673ebbc8f28e159cf2687a664d540dcb91d325934f32,arm64,linux,v8,null,&amp;#34;sha256:29e5d40040c18c692ed73df24511071725b74956ca1a61fe6056a651d86a13bd&amp;#34;,2724424
1.18.0-alpine,sha256:2ba714ccbdc4c2a7b5a5673ebbc8f28e159cf2687a664d540dcb91d325934f32,arm64,linux,v8,null,&amp;#34;sha256:806787fcd4f9e2f814506fb53e81b6fb33f9eea04e5b537b31fa5fb601a497ee&amp;#34;,6423816
1.18.0-alpine,sha256:6d6f19360150548bbb568ecd3e1affabbdce0fcc39156e70fbae8a0aa656541a,386,linux,null,null,&amp;#34;sha256:2826c1e79865da7e0da0a993a2a38db61c3911e05b5df617439a86d4deac90fb&amp;#34;,2808418
1.18.0-alpine,sha256:6d6f19360150548bbb568ecd3e1affabbdce0fcc39156e70fbae8a0aa656541a,386,linux,null,null,&amp;#34;sha256:f2ab0e3b0ff04d1695df322540631708c42b0a68925788de2290c9497e44fef3&amp;#34;,6845295
1.18.0-alpine,sha256:c0684c6ee14c7383e4ef1d458edf3535cd62b432eeba6b03ddf0d880633207da,ppc64le,linux,null,null,&amp;#34;sha256:9a8fdc5b698322331ee7eba7dd6f66f3a4e956554db22dd1e834d519415b4f8e&amp;#34;,2821843
1.18.0-alpine,sha256:c0684c6ee14c7383e4ef1d458edf3535cd62b432eeba6b03ddf0d880633207da,ppc64le,linux,null,null,&amp;#34;sha256:30a37aac8b54a38e14e378f5122186373cf233951783587517243e342728a828&amp;#34;,6746511
1.18.0-alpine,sha256:714439fec7e1f55c29b57552213e45c96bbfeefddea2b3b30d7568591966c914,s390x,linux,null,null,&amp;#34;sha256:7184c046fdf17da4c16ca482e5ede36e1f2d41ac8cea9c036e488fd149d6e8e7&amp;#34;,2582859
1.18.0-alpine,sha256:714439fec7e1f55c29b57552213e45c96bbfeefddea2b3b30d7568591966c914,s390x,linux,null,null,&amp;#34;sha256:214dff8a034aad01facf6cf63613ed78e9d23d9a6345f1dee2ad871d6f94b689&amp;#34;,6569410&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;p>各列的含义分别是，&lt;code>镜像tag&lt;/code>, &lt;code>镜像&lt;/code>&lt;a href="https://docs.docker.com/registry/spec/api/#content-digests">Digest&lt;/a>, &lt;code>镜像对应平台的Architecture&lt;/code>, &lt;code>镜像对应平台的OS&lt;/code>, &lt;code>镜像对应平台的变种&lt;/code>（例如，ARM的v7, v8等）, &lt;code>镜像对应平台的OS版本&lt;/code>, &lt;code>镜像组成层的&lt;/code>&lt;a href="https://docs.docker.com/registry/spec/api/#content-digests">Digest&lt;/a>, &lt;code>镜像组成层的大小&lt;/code>。&lt;/p>
&lt;p>上面&lt;code>nginx&lt;/code>镜像的示例数据，告诉我们镜像名&lt;code>nginx&lt;/code>且tag为&lt;code>1.18.0-alpine&lt;/code>的镜像包含了&lt;code>amd64-linux&lt;/code>, &lt;code>arm-linux-v6&lt;/code>, &lt;code>arm64-linux-v8&lt;/code>, &lt;code>386-linux&lt;/code>, &lt;code>ppc64le-linux&lt;/code>以及&lt;code>s390x-linux&lt;/code>共5种Arch合计6个版本的镜像。且每个平台的对应镜像包含了两个层以及这两个层的大小。&lt;/p>
&lt;p>当我们有了成百数千甚至海量镜像的原始数据后，如何能快速且低成本的分析这些数据呢？&lt;/p>
&lt;p>在AWS上，我们可以利用&lt;a href="https://aws.amazon.com/big-data/datalakes-and-analytics/">数据湖&lt;/a>相关的系列产品来实现低成本的交互式分析。&lt;/p>
&lt;ol>
&lt;li>在Docker镜像分析这个场景下，我已经获取到了待分析镜像的平台、层等数据。我将这些数据上传到&lt;a href="https://aws.amazon.com/s3/">Amazon S3&lt;/a>作为数据湖的数据源。&lt;/li>
&lt;li>接下来使用&lt;a href="https://aws.amazon.com/glue/">AWS Glue&lt;/a>以S3中的数据创建Table并且从中提前数据的metadata。同时做数据分区，为接下来的查询做性能和成本优化。&lt;/li>
&lt;li>打开&lt;a href="https://aws.amazon.com/athena/">Amazon Athena&lt;/a>，根据业务需求通过SQL语句查询分析Docker镜像数据。&lt;/li>
&lt;/ol>
&lt;p>就是通过以上3个简单步骤，我就得到了一个无服务器架构的Docker镜像数据分析应用！整个应用完全是按量计费的，主要成本包括S3对象存储费用，和Athena费用（根据每次查询扫描数据的大小来计算）。&lt;/p>
&lt;p>使用该分析应用，我统计了&lt;a href="https://hub.docker.com/search?image_filter=official&amp;amp;type=image">Docker Hub官方镜像&lt;/a>中包含层最多的10个镜像(分平台统计)，
&lt;figure>&lt;img src="https://kane.mx/posts/2020/serverless-docker-images-analytics/images/top-10-layers-of-official-images.png"
alt="Top 10 layers"/>
&lt;/figure>
&lt;/p>
&lt;p>最后，得力于AWS Infra as Code的强大能力，&lt;a href="https://github.com/zxkane/serverless-docker-images-analytics">整个应用&lt;/a>也是通过代码管理的且开源的，有兴趣的读者也可以部署自己的分析应用。&lt;/p></description></item><item><title>基于CodeCommit代码管理的无服务器架构Devops</title><link>https://kane.mx/posts/2020/codecommit-devops-model/</link><pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/codecommit-devops-model/</guid><description>
&lt;p>&lt;a href="https://github.com/">Github&lt;/a>/&lt;a href="https://about.gitlab.com/">Gitlab&lt;/a>已经成为众多开发者非常熟悉的代码协作平台，通过他们参与开源项目或实施企业内部项目协作。&lt;/p>
&lt;p>AWS也提供了托管的、基于Git、安全且高可用的代码服务&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>。&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>主要针对企业用户场景，所以他并没有社交功能以及代码仓库fork功能，是否&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>就无法实现&lt;a href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests">Github基于Pull Request&lt;/a>的协同工作模式呢？&lt;/p>
&lt;p>答案是，&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>完全可以实现&lt;strong>基于Pull Request的代码协作&lt;/strong>。由于&lt;a href="https://git-scm.com/">Git&lt;/a>的分布式代码管理特性，首先fork上游项目仓库，将修改后的代码提交到fork仓库，通过Pull Request申请修改请求合并。Github将这套协作流程推广开来并被开源项目广泛采用。其实还有另外的Git仓库协同方式来完成多人的协作开发，例如&lt;a href="https://www.gerritcodereview.com/">Gerrit Code Review&lt;/a>。目前Android、Eclipse Foundation下面的各种项目都在使用Gerrit作为协同开发工具。&lt;a href="https://www.gerritcodereview.com/">Gerrit&lt;/a>通过控制同一个代码仓库中不同角色的用户可提交代码分支的权限来实现代码贡献、Review、持续集成以及协同开发的。&lt;/p>
&lt;p>&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>作为AWS托管的服务，同IAM认证和授权管理做了很好的集成。完全可以通过IAM Policy的设置，为同一个代码仓库中不同用户角色设置不同的权限。使用类似&lt;a href="https://www.gerritcodereview.com/">Gerrit&lt;/a>的权限控制思路，&lt;/p>
&lt;ul>
&lt;li>任意代码仓库&lt;em>协作者&lt;/em>可以提交代码到特定含义的分支，例如，&lt;code>features/*&lt;/code>, &lt;code>bugs/*&lt;/code>。可以允许多人协同工作在某一特定分支上。协作者同时可以创建新的Pull Request请求合并代码到主分支，例如&lt;code>master&lt;/code>或者&lt;code>mainline&lt;/code>。&lt;/li>
&lt;li>代码仓库Master/Owner有权限合并Pull Request。&lt;/li>
&lt;li>拒绝任何人直接推送代码到仓库主分支，包括仓库Owner/Admin。&lt;/li>
&lt;li>监听仓库Pull Request创建和PR源分支更新事件，自动触发该PR对应分支的automation build，编译、测试等通过后，自动为PR的&lt;code>通过&lt;/code>投票+1。反之若失败，则取消投票。&lt;/li>
&lt;li>为代码仓库设置PR Review规则，至少需要收到PR automation build和仓库Master/Owner合计两票&lt;code>通过&lt;/code>才允许合并代码。&lt;/li>
&lt;li>监听代码仓库主分支，任意新提交将触发自动化发布Build。将最新变更在整个系统上做集成。&lt;/li>
&lt;/ul>
&lt;p>是不是很棒！完全做到了Github、Github Pull Request、Github Action/Travis CI整套devops协同开发的流程。&lt;/p>
&lt;p>协作流程如下图，
&lt;figure>&lt;img src="images/codecommit-devops-model.png"
alt="基于CodeCommit代码管理的协同流程"/>
&lt;/figure>
&lt;/p>
&lt;p>同时，以上整套基于CodeCommit代码管理的devops工作流程可以利用CloudFormation实现AWS资源编排，将Devops依赖的Infra使用代码来做管理！这样的好处是，企业内部即使有数百数千甚至更多代码仓库都可以统一管理，新仓库的申请也可以通过Infra代码的PR，在通过审批合并后自动从AWS provisioning创建出符合企业管理要求的安全代码仓库。很酷吧:laughing:&lt;/p>
&lt;p>&lt;a href="https://github.com/zxkane/cdk-collections/tree/master/codecommit-collaboration-model">这里&lt;/a>有一套完整的创建以上工作流的演示，有兴趣的读者可以在自己的账户内体验。整套方案完全使用的是AWS托管服务，仅按实际使用量(如使用CodeBuild编译了代码)计费。&lt;/p></description></item><item><title>AWS Cloud Debugging初探</title><link>https://kane.mx/posts/2019/aws-cloud-debugging/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-cloud-debugging/</guid><description>
&lt;p>在&lt;a href="https://reinvent.awsevents.com/?nc2=h_ql_re">re:Invent&lt;/a> 2019之前，&lt;a href="https://aws.amazon.com/getting-started/tools-sdks/?nc2=h_ql_prod_dt_tsdk">AWS Toolkit&lt;/a>发布了&lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/11/announcing-cloud-debugging-beta/?nc1=h_ls">Cloud Debugging beta&lt;/a>功能。该功能支持在IntelliJ IDEs(IntelliJ, PyCharm, Webstorm, 以及 Rider)中远程调试 ECS &lt;a href="https://aws.amazon.com/fargate/">Fargate&lt;/a> 容器中执行的应用程序。&lt;/p>
&lt;p>对&lt;a href="https://github.com/zxkane/alibabacloud-microservice-demo/tree/cloud-debug">ECS Fargate demo&lt;/a>启用了远程调试并调试成功后，这里记录一下该功能的使用体验并且分享体验过程中掉进去过的一些坑。&lt;/p>
&lt;h4 id="试用体验">试用体验&lt;/h4>
&lt;ul>
&lt;li>首先，该功能不适用于生产环境。因为对ECS Fargate类型的Service启用&lt;strong>Cloud Debugging&lt;/strong>功能会将原始的&lt;code>ECS Services&lt;/code>收缩为&lt;strong>0&lt;/strong>个task副本，同时创建一个新的Service并启用新的Task Definition，新的Task Definition中会加入&lt;code>Cloud Debug Sidecar&lt;/code>容器来辅助实现远程调试。整个过程会对生产环境造成变更。&lt;/li>
&lt;li>如果ECS集群是通过CI/CD持续部署，并且是多人协同使用的环境，该功能也不适用。因为，对某些容器服务启用&lt;code>Cloud Debugging&lt;/code>将导致他人的持续部署失败或不生效。&lt;/li>
&lt;li>启用&lt;code>Cloud Debugging&lt;/code>操作比较麻烦，且启用状态下无法更新ECS中部署的版本。需要先停用&lt;code>Cloud Debugging&lt;/code>，部署新版本代码，然后再次启用&lt;code>Cloud Debugging&lt;/code>才能调试新代码。尽可能的不要依赖&lt;code>Cloud Debugging&lt;/code>来调试程序，花功能做好单元测试，集成测试以及E2E测试来避免调试云端环境。&lt;/li>
&lt;/ul>
&lt;h4 id="试用经验">试用经验&lt;/h4>
&lt;ul>
&lt;li>按照&lt;a href="https://docs.aws.amazon.com/zh_cn/toolkit-for-jetbrains/latest/userguide/ecs-debug.html#ecs-prereqs">官方文档启用&lt;code>Cloud Debugging&lt;/code>&lt;/a>后，创建&lt;a href="https://docs.aws.amazon.com/zh_cn/toolkit-for-jetbrains/latest/userguide/edit-configuration-dialog.html#edit-configuration-dialog-ecs">Cloud Debugging Launch Configuration&lt;/a>并执行调试，遇到**&lt;code>Retrieve execution role finished exceptionally&lt;/code>**错误。错误的原因是，文档中没有提到&lt;code>Cloud Debug Sidecar&lt;/code>需要&lt;code>logs:CreateLogStream&lt;/code>权限创建CloudWatch Logs Stream。解决方案是，为ECS Task Execution Role添加&lt;code>logs:CreateLogStream&lt;/code>权限。&lt;/li>
&lt;li>在&lt;a href="https://github.com/aws/aws-toolkit-jetbrains">AWS Toolkit Jetbrains&lt;/a>当前的版本&lt;em>1.9-193&lt;/em>不支持启用了&lt;a href="https://github.com/aws/aws-toolkit-jetbrains/issues/1463">AppMesh&lt;/a>或&lt;a href="https://github.com/aws/aws-toolkit-jetbrains/issues/1464">X-Ray&lt;/a>的Task。解决方案是，对需要启用&lt;code>Cloud Debugging&lt;/code>的Task暂时禁用App Mesh和X-Ray。&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>&lt;code>Cloud Debugging&lt;/code>是一个不错的开发工具尝试思路，帮助开发者更好的做出Cloud Native应用。但是该项目仍然是一个早期项目，有许多问题需要修复和改进。&lt;/p>
&lt;/blockquote></description></item><item><title>AWS Batch简介</title><link>https://kane.mx/posts/2019/aws-batch/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-batch/</guid><description>
&lt;p>&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>是一个全托管的批处理调度服务，它可为用户管理所有基础设施，从而避免了预置、管理、监控和扩展批处理计算作业所带来的复杂性。当然&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>已与 AWS 平台原生集成，让用户能够利用 AWS 的扩展、联网和访问管理功能。让用户轻松运行能够安全地从 AWS 数据存储（如 Amazon S3 和 Amazon DynamoDB）中检索数据并向其中写入数据的作业。&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>可根据所提交的批处理作业的数量和资源要求预置计算资源并优化作业分配。能够将计算资源动态扩展至运行批处理作业所需的任何数量，从而不必受固定容量集群的限制。&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>还可以利用 Spot 实例，从而进一步降低运行批处理作业产生的费用。&lt;/p>
&lt;p>&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>服务本身是&lt;strong>免费&lt;/strong>的，仅收取实际使用的 EC2 实例费用。&lt;/p>
&lt;p>我创建了一个&lt;a href="https://github.com/zxkane/cdk-collections/blob/master/batch-demo/README.md">Batch App demo&lt;/a>来演示&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>相关使用方法。该示例通过一个Restful API接口来提交批处理任务，Restful API通过&lt;a href="https://aws.amazon.com/cn/elasticloadbalancing/">ALB&lt;/a> + &lt;a href="https://aws.amazon.com/cn/lambda/">Lambda函数&lt;/a>来暴露服务。Lambda函数被触发后，将新任务请求发送到&lt;a href="https://aws.amazon.com/cn/sqs/">SQS&lt;/a>服务。随后另一个Lambda将消费这个SQS，并将调用&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a> API来提交新的批处理任务，同时将任务信息储存到&lt;a href="https://aws.amazon.com/cn/dynamodb/">DynamoDB&lt;/a>中。同时Demo创建了Batch任务会使用到的Docker Image，并且预先提交到&lt;a href="https://aws.amazon.com/cn/ecr/">ECR&lt;/a>中。同时Batch任务定义了使用的EC2实例类型(c5系列实例，且包括Spot和按需两种计费方式的实例，且优先使用Spot实例)，实例默认伸缩数量为0(没有可执行任务时将中止实例)。并且提交的任务分为计算任务和统计归并任务，统计归并任务会依赖所以计算任务执行完毕才开始执行。最后通过另一Restful接口查询计算任务的最终结果，该接口同样使用&lt;a href="https://aws.amazon.com/cn/elasticloadbalancing/">ALB&lt;/a> + &lt;a href="https://aws.amazon.com/cn/lambda/">Lambda函数&lt;/a>来实现。&lt;/p>
&lt;figure>&lt;img src="https://kane.mx/posts/2019/aws-batch/aws-batch-app-demo.png"
alt="Batch App架构图"/>
&lt;/figure>
&lt;p>Enjoy this &lt;a href="https://github.com/zxkane/cdk-collections/blob/master/batch-demo/README.md">Batch App demo&lt;/a> orchestrated by &lt;a href="https://aws.amazon.com/cn/cdk/">AWS CDK&lt;/a>.&lt;/p></description></item><item><title>AWS CDK简介</title><link>https://kane.mx/posts/2019/aws-cdk/</link><pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-cdk/</guid><description>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">Infrastructure as Code&lt;/a>(架构即代码)一直是衡量公有云是否支持良好运维能力的重要指标。作为云计算领先的AWS，通过服务&lt;a href="https://aws.amazon.com/cn/cloudformation/">CloudFormation&lt;/a>来编排云环境中的基础设施资源。不过由于CloudFormation是使用YAML/JSON编写的声明式语言，不善于处理逻辑，编写繁琐且不利于调试排错，对于新上手的Devops工程师来说也有不小的学习曲线。三方开源的工具&lt;a href="https://en.wikipedia.org/wiki/Terraform_(software)">Terraform&lt;/a>同样没有很好解决&lt;a href="https://aws.amazon.com/cn/cloudformation/">CloudFormation&lt;/a>存在的这些问题。&lt;/p>
&lt;p>&lt;a href="https://aws.amazon.com/cn/cdk/">AWS CDK&lt;/a>的出现解决了目前&lt;a href="https://aws.amazon.com/cn/cloudformation/">CloudFormation&lt;/a>存在的绝大部分问题，极大的提升基础设施编排代码的开发和维护效率。&lt;/p>
&lt;p>AWS CDK是一种开源软件开发框架，开发者可以用自己使用熟悉的编程语言模拟和预置云应用程序资源，目前支持Typescript/Javascript、Python、Java和.Net。AWS CDK将云中资源抽象对象化，通过极其简单语法描述资源对象或设置其各种属性(重载CDK默认属性设置)来创建或更新云中资源。&lt;/p>
&lt;p>例如，下面简单几行将创建一个新的名为&lt;code>Gameday&lt;/code>的VPC网络，并且跨了两个可用区分别创建了公有子网和私有子网。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-typescript" data-lang="typescript">&lt;span class="ln"> 1&lt;/span> &lt;span class="k">this&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">vpc&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">ec2&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">Vpc&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">this&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Gameday&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 2&lt;/span> &lt;span class="nx">cidr&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;10.0.0.0/16&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="nx">maxAzs&lt;/span>: &lt;span class="kt">2&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="nx">subnetConfiguration&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="nx">cidrMask&lt;/span>: &lt;span class="kt">24&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="nx">name&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;Public&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="nx">subnetType&lt;/span>: &lt;span class="kt">SubnetType.PUBLIC&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="p">},&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="nx">cidrMask&lt;/span>: &lt;span class="kt">24&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="nx">name&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;Private&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="nx">subnetType&lt;/span>: &lt;span class="kt">SubnetType.PRIVATE&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="p">]&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="p">});&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>我创建了两个示例项目使用了&lt;a href="https://aws.amazon.com/cn/cdk/">AWS CDK&lt;/a>快速创建应用环境且部署应用，&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/zxkane/gameday-cdk">Gameday&lt;/a> 为一个ECS上运行的Web应用编排了完整的环境，包括VPC、RDS Aurora、NAT Gateway、安全组、ECS集群、ECS Task定义、ALB负载均衡。&lt;/li>
&lt;li>&lt;a href="https://github.com/zxkane/serverless-domain-redirect">Serverlss Domain Redirect&lt;/a> 基于AWS搭建了无服务器架构的域名重定向服务。基于不同的配置参数，提供了基于 S3 + CloudFront + Route 53 或是 Lambda + API Gateway + Route 53 两种解决方案。&lt;/li>
&lt;/ul>
&lt;p>总体的来说，&lt;a href="https://aws.amazon.com/cn/cdk/">AWS CDK&lt;/a>是一个非常值得采用的云中资源编排和管理方式，高效的管理了AWS上的资源。&lt;/p>
&lt;p>由于CDK还在相对早期，成熟度还不是那么完美。我在使用中发现下面一些值得注意的问题。&lt;/p>
&lt;ol>
&lt;li>CDK程序最终还是创建了CloudFormation配置，提交到CloudFormation完成资源变更。核心的用户体验，需要依赖CloudFormation的能力。CloudFormation的创建或回退超时过长，时常影响资源部署体验。另外，清理资源的时候，遇到部分资源无法清理且缺少明确提示。比如Aurora集群。&lt;/li>
&lt;li>CDK类库缺少配置校验。这类错误只能通过CloudFormation部署后，才会被资源方发现并返回错误。导致整个创建的堆栈回退，调试大型的部署栈将花费比较长的时间。建议将整个部署拆分为多个小的堆栈，减小每次部署时间，方便调试。&lt;/li>
&lt;li>文档还比较简陋。缺少较为深入的示例。增加了开发人员的学习曲线。&lt;/li>
&lt;li>新版本向后兼容性不够好，时常新版本有break changes。在1.0GA之后发布的版本break changes相对减少，但仍然有出现。&lt;/li>
&lt;/ol></description></item><item><title>无服务器架构的域名重定向服务</title><link>https://kane.mx/posts/effective-cloud-computing/serverless-domain-redirect/</link><pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/serverless-domain-redirect/</guid><description>
&lt;p>业务时常有需求将某个域名(A)的访问重定向到其他域名(B)，即使实现这样一个很简单的需求通常也需要部署Web服务器（例如Nginx），为域名A的请求返回302响应，并提供新的Location地址重定向到域名B。现在基于云计算服务，我们可以使用一些托管服务来实现同样的事情，无需管理服务器和维护应用，同时做到最低成本实现该需求。&lt;/p>
&lt;p>接下来将介绍如何利用AWS上的服务实现该需求。&lt;/p>
&lt;h3 id="使用aws-s3和aws-cloudfront实现域名重定向">使用AWS S3和AWS CloudFront实现域名重定向&lt;/h3>
&lt;ol>
&lt;li>创建一个新的S3 bucket，例如 &lt;code>redirect.domain.com&lt;/code>&lt;/li>
&lt;li>配置新bucket属性，开启静态网站托管，同时配置为重定向请求到期望的域名 &lt;code>redirected-host.domain.com&lt;/code>&lt;/li>
&lt;li>创建新的CloudFront分发，设置第一步创建的S3 bucket作为&lt;a href="https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/private-content-restricting-access-to-s3.html">自定义源站(不可以配置源站为S3 bucket)&lt;/a>。并且配置使用自定义域名 &lt;code>redirect.domain.com&lt;/code>。注意，配置自定义CNames需要提供域名对应的SSL证书，可以使用AWS Certificate Manager创建免费的SSL/TLS证书&lt;/li>
&lt;li>在域名&lt;code>domain.com&lt;/code>解析服务商为域名&lt;code>redirect.domain.com&lt;/code>创建新的解析记录&lt;/li>
&lt;/ol>
&lt;h3 id="使用aws-lambda和api-gateway实现域名重定向">使用AWS Lambda和API Gateway实现域名重定向&lt;/h3>
&lt;ol>
&lt;li>创建一个Lambda函数来返回302请求或者HTML页面，在页面中通过Javascript实现重定向页面&lt;/li>
&lt;li>为该Lambda函数创建API Gateway触发器&lt;/li>
&lt;li>为该API Gateway接口创建自定义域名&lt;/li>
&lt;li>在域名&lt;code>domain.com&lt;/code>解析服务商为域名&lt;code>redirect.domain.com&lt;/code>创建新的解析记录&lt;/li>
&lt;/ol>
&lt;p>我创建了一个基于&lt;a href="https://aws.amazon.com/cdk/?nc1=h_ls">AWS CDK&lt;/a>的&lt;a href="https://github.com/zxkane/serverless-domain-redirect#use-aws-s3-and-cloudfront-for-domain-redirect">Github项目&lt;/a>，利用AWS Infrastructure as Code的强大能力一键部署以上两种无服务器环境，有需要的可以作为实现参考。&lt;/p></description></item><item><title>Spring Cloud Function -- 跨Serverless平台的函数计算框架</title><link>https://kane.mx/posts/effective-cloud-computing/spring-cloud-function-for-aws/</link><pubDate>Fri, 28 Jun 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/spring-cloud-function-for-aws/</guid><description>
&lt;p>&lt;a href="https://kane.mx/posts/2019/serverless-framework/">基于serverless框架的钉钉回调函数&lt;/a>中介绍了serverless framework，一款支持跨云厂商/Serverless平台的部署工具。但是函数代码还是需要针对不同的serverless平台作对应的适配。而&lt;a href="https://spring.io/projects/spring-cloud-function">Spring Clound Function&lt;/a>就是针对这种情况专门开发的跨serverless平台的框架，实现一套代码通过不同的打包实现跨serverless平台。Spring Clound Function目前支持AWS Lambda, Microsoft Azure Function以及Apache OpenWhisk。&lt;/p>
&lt;p>这里我们继续使用&lt;a href="https://kane.mx/posts/effective-cloud-computing/serverless-dingtalk-callback/">无函数版本的钉钉回掉函数&lt;/a>来演示&lt;a href="https://spring.io/projects/spring-cloud-function">Spring Clound Function&lt;/a> for AWS的使用。&lt;/p>
&lt;p>首先将&lt;code>spring cloud function for aws adapter&lt;/code>添加到项目依赖，&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-kotlin" data-lang="kotlin">&lt;span class="ln">1&lt;/span>&lt;span class="n">implementation&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;org.springframework.cloud:spring-cloud-function-adapter-aws:&lt;/span>&lt;span class="si">${springCloudFunctionVersion}&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>其次创建函数&lt;code>Handler&lt;/code>，实现Spring Cloud Function跨函数计算实现抽象的&lt;code>SpringBootRequestHandler&lt;/code>类，或者是继承自它的trigger类，例如&lt;code>SpringBootApiGatewayRequestHandler&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-kotlin" data-lang="kotlin">&lt;span class="ln">1&lt;/span>&lt;span class="k">import&lt;/span> &lt;span class="nn">org.springframework.cloud.function.adapter.aws.SpringBootApiGatewayRequestHandler&lt;/span>
&lt;span class="ln">2&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="k">class&lt;/span> &lt;span class="nc">Handler&lt;/span> &lt;span class="p">:&lt;/span> &lt;span class="n">SpringBootApiGatewayRequestHandler&lt;/span>&lt;span class="p">()&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>接下来创建Spring Boot应用程序，并将serverless实现函数注册为&lt;code>Spring Bean&lt;/code>，函数的实现部分就是serverless函数具体做的业务逻辑。&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-kotlin" data-lang="kotlin">&lt;span class="ln"> 1&lt;/span>&lt;span class="nd">@SpringBootApplication&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="k">open&lt;/span> &lt;span class="k">class&lt;/span> &lt;span class="nc">DingtalkCallbackApplication&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 3&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="nd">@Bean&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="k">open&lt;/span> &lt;span class="k">fun&lt;/span> &lt;span class="nf">dingtalkCallback&lt;/span>&lt;span class="p">():&lt;/span> &lt;span class="n">Function&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="n">Message&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="n">EncryptedEvent&lt;/span>&lt;span class="p">&amp;gt;,&lt;/span> &lt;span class="n">Map&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">String&lt;/span>&lt;span class="p">&amp;gt;&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="k">val&lt;/span> &lt;span class="py">callback&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="n">Callback&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">Function&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln"> 8&lt;/span> &lt;span class="n">callback&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">handleRequest&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="k">it&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 9&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">10&lt;/span> &lt;span class="p">}&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="k">fun&lt;/span> &lt;span class="nf">main&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">Array&lt;/span>&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="p">&amp;gt;)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="n">SpringApplication&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">DingtalkCallbackApplication&lt;/span>&lt;span class="o">::&lt;/span>&lt;span class="k">class&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="n">java&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">*&lt;/span>&lt;span class="n">args&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">14&lt;/span>&lt;span class="p">}&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>最后将函数打包为fat jar（如果将依赖打包为lambda layer，可不用打包为fat jar）作为lambda的代码。&lt;/p>
&lt;p>函数的部署同其他的lambda函数没有任何区别，这个示例中沿用了之前的SAM/CloudFormation配置或者&lt;a href="https://serverless.com/">serverless framework&lt;/a>部署配置。&lt;/p>
&lt;p>完整的可运行、部署代码请访问&lt;a href="https://github.com/zxkane/dingtalk-callback-on-aws/tree/spring-cloud-function">这个分支&lt;/a>。&lt;/p>
&lt;blockquote>
&lt;p>总体来说，&lt;a href="https://spring.io/projects/spring-cloud-function">Spring Clound Function&lt;/a>的实现原理并不复杂，定义统一的函数实现入口，通过不同serverless平台的adapter对接不同平台的API接口，做到编写一次函数实现，通过打包不同的adapter做到跨serverless平台运行。&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>但个人认为现实中这样的场景并不多。并且serverless函数触发方式很多，例如AWS上的APIGateway、Kinesis、CloudWatch、IoT等服务，与这些服务对接或API调用其实也产生了耦合，并不能简单的迁移到三方的serverless平台去执行。同时，开发者需要引入spring/spring boot/spring cloud相关的依赖，增加了程序的复杂度，又延长了lambda函数clod start需要的时间。另外，开发者需要学习spring cloud function相关的知识，无形中增加了复杂度。总之使用spring cloud function作为函数计算框架收益并不高，整个项目给人感觉比较鸡肋。&lt;/p>
&lt;/blockquote></description></item><item><title>Spring Cloud or Cloud Native</title><link>https://kane.mx/posts/effective-cloud-computing/spring-cloud-or-cloud-native/</link><pubDate>Mon, 29 Apr 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/spring-cloud-or-cloud-native/</guid><description>
&lt;p>基于Java的&lt;a href="https://spring.io/projects/spring-cloud">Spring Cloud&lt;/a>是由Java最大开源生态&lt;a href="https://spring.io/">Spring&lt;/a>社区推出的Out-of-Box分布式&lt;a href="https://en.wikipedia.org/wiki/Microservices">微服务&lt;/a>解决方案，&lt;a href="https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Angel-Release-Notes/6e0e1ba3d510d4a30b95c1468007b22f2427fa25">自2016年发布&lt;/a>起就被众多开发者看好。Java作为广为流行的服务端编程语言，&lt;a href="https://spring.io/projects/spring-cloud">Spring Cloud&lt;/a>也就越来越多的被用于微服务开发。&lt;/p>
&lt;p>&lt;a href="https://spring.io/projects/spring-cloud">Spring Cloud&lt;/a>集成了&lt;a href="https://netflix.github.io/">Netflix OSS&lt;/a>开源项目实现了很多功能(或作为实现之一)，包括服务治理、网关路由、客户端负载均衡、服务间调用、断路器等。&lt;a href="https://spring.io/projects/spring-cloud-netflix">Spring Cloud Netflix&lt;/a>将很多生产级别微服务能力开箱即用的带到了Spring Cloud架构下的微服务中，帮助开发者快速的构建满足&lt;a href="https://12factor.net/">12要素&lt;/a>的应用。&lt;/p>
&lt;p>在去年底发布的&lt;a href="https://spring.io/blog/2018/12/12/spring-cloud-greenwich-rc1-available-now#spring-cloud-netflix-projects-entering-maintenance-mode">Spring Cloud Greenwich版本&lt;/a>中宣布&lt;a href="https://spring.io/projects/spring-cloud-netflix">Spring Cloud Netflix&lt;/a>中重要的组件&lt;a href="https://github.com/Netflix/Hystrix#hystrix-status">Hystrix&lt;/a>、&lt;a href="https://github.com/Netflix/ribbon#project-status-on-maintenance">Ribbon&lt;/a>、&lt;code>Zuul 1&lt;/code>等由于上游开源项目进入维护状态，对应的Spring Cloud Netflix项目也进入到维护状态。这些项目将&lt;strong>不再适合&lt;/strong>用于长期维护的产品中！&lt;/p>
&lt;p>同时随着近年云计算的发展，特别是&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>成为容器编排平台的事实标准，加上&lt;a href="https://www.nginx.com/blog/what-is-a-service-mesh/">Service Mesh(服务网格)&lt;/a>对微服务的服务治理和流量控制，为&lt;a href="https://www.redhat.com/en/topics/cloud-native-apps">云原生应用&lt;/a>提供了更为现代、平台无关的解决方案。&lt;/p>
&lt;p>让我们逐一看看在&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>加上Serivce Mesh(例如&lt;a href="https://istio.io/">Istio&lt;/a>)如何实现微服务的服务发现、路由、链路追踪、断路器等功能。&lt;/p>
&lt;h3 id="配置中心">配置中心&lt;/h3>
&lt;p>&lt;a href="https://spring.io/projects/spring-cloud-config">Spring Cloud Config&lt;/a>默认提供了多种配置管理后端，例如&lt;code>Git&lt;/code>、&lt;code>Vault&lt;/code>、&lt;code>JDBC Backend&lt;/code>等。同时也有很多开源方案可以作为替换方案，比如&lt;a href="https://github.com/alibaba/nacos">Alibaba Nacos&lt;/a>。&lt;/p>
&lt;p>作为部署在&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>中的应用，最佳实践是平衡&lt;a href="https://kubernetes.io/docs/user-guide/configmap/">Configmap&lt;/a>和&lt;a href="https://spring.io/projects/spring-cloud-config">Spring Cloud Config&lt;/a>。将涉及程序功能的配置放置在&lt;a href="https://kubernetes.io/docs/user-guide/configmap/">Configmap&lt;/a>和Secret，随同微服务的发布一起做版本管理，可以做到&lt;strong>随着应用回退的时候同时回退到历史对应的配置版本&lt;/strong>，而不会因为历史版本的代码被最新版本的配置所中断。&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes">Spring Cloud Kuberentes&lt;/a>项目很好的支持了Spring Cloud应用从&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes#kubernetes-propertysource-implementations">Configmap&lt;/a>和&lt;a href="https://github.com/spring-cloud/spring-cloud-kubernetes#secrets-propertysource">Secret&lt;/a>中读取配置项。而涉及业务的配置选项，将可以考虑放到Spring Cloud Config后端实现统一管理。如果应用是部署在阿里云，使用阿里云托管的配置服务和&lt;a href="https://github.com/alibaba/nacos">Spring Cloud Config -- Nacos&lt;/a>将是很好的选择。&lt;/p>
&lt;h3 id="服务发现">服务发现&lt;/h3>
&lt;p>&lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/#discovering-services">Kubernetes Services&lt;/a>提供了集群内原生的服务发现能力，是&lt;a href="https://spring.io/projects/spring-cloud-netflix">Eureka&lt;/a>或&lt;a href="https://spring.io/projects/spring-cloud-zookeeper">Spring Cloud Zookeeper&lt;/a>等服务发现服务的很好替代品。基于K8S Services的服务发现，很容易通过Service Mesh能力实现限流、A/B测试、金丝雀发布、断路器、chaos注入等服务治理能力。同时对微服务应用来说，不用在应用端添加对应三方库来实现服务注册及发现，减少了应用端开发需求。&lt;/p>
&lt;h3 id="各种流量治理场景">各种流量治理场景&lt;/h3>
&lt;p>应用被服务化后，一定会面临流量治理的问题。对于各种服务间如何实现限流、A/B测试、金丝雀发布、断路器、chaos注入测试、链接追踪等，这其实是一类通用的问题。&lt;/p>
&lt;p>&lt;a href="https://spring.io/projects/spring-cloud">Spring Cloud&lt;/a>提供的是一种客户端解决思路，需要每个应用引入对应功能的libraries的支持。即使通过&lt;a href="https://www.baeldung.com/spring-boot-starters">spring boot starter&lt;/a>提供了近似开箱即用的能力，但是每个应用仍然需要自行添加对应的能力，版本更新、安全漏洞fix等场景都需要手动升级、测试、打包、部署。在异构编程语言实现的微服务架构下，未必每种编程框架都能提供很好的对应能力支持。除非有特别的服务治理策略，不推荐在微服务自身来实现服务流量的控制。&lt;/p>
&lt;p>Service Mesh(例如&lt;a href="https://istio.io/">Istio&lt;/a>或&lt;a href="https://linkerd.io/">Linkerd&lt;/a>)从整个服务治理层面对上述需求提供了统一的解决方案，而不需要微服务做自身的升级或改动。在基于Kuberentes部署运行的微服务应用，Service Mesh提供了统一的服务治理方案，将用户从不同的微服务中自身维护服务治理功能中解放出来，从平台层面提供更加统一一致的解决方案。&lt;/p>
&lt;p>在去年的SpringOne Platform 2018上也有一个Topic &lt;a href="https://youtu.be/AMJQO9zs2eo">A Tale of Two Frameworks: Spring Cloud and Istio&lt;/a> 探讨什么场景应该使用Service Mesh，什么时候使用Spring Cloud服务治理组件，有兴趣的朋友可以看一看。&lt;/p>
&lt;div class="youtube container">
&lt;iframe class="youtube" type="text/html"
src="https://www.youtube.com/embed/AMJQO9zs2eo"
allowfullscreen frameborder="0">
&lt;/iframe>
&lt;/div></description></item><item><title>为Kubernetes中任意应用添加基于oauth2的认证保护 (下)</title><link>https://kane.mx/posts/effective-cloud-computing/oauth2-proxy-on-kubernetes/part2/</link><pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/oauth2-proxy-on-kubernetes/part2/</guid><description>
&lt;p>本文是&lt;a href="https://kane.mx/posts/effective-cloud-computing/oauth2-proxy-on-kubernetes/part1/">为Kubernetes中任意应用添加基于oauth2的认证保护&lt;/a>的下篇，将图文详解如何使用基于&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/kymkv6">钉钉认证&lt;/a>的&lt;a href="https://github.com/bitly/oauth2_proxy">oauth2 proxy&lt;/a>为自身本没有认证授权功能的Web站点实现认证及授权。&lt;/p>
&lt;blockquote>
&lt;p>示例是使用的&lt;a href="https://aws.amazon.com/eks/?nc1=f_ls">AWS EKS&lt;/a>服务作为K8S环境。鉴于K8S的应用运行时属性，该示例也可以部署在其他云厂商托管的K8S。&lt;/p>
&lt;/blockquote>
&lt;h3 id="示例模块简介">示例模块简介&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/ingress-nginx">Nginx Ingress Controller&lt;/a>为K8S集群内Web应用提供反向代理，以及支持外部认证。&lt;/li>
&lt;li>简单的Web站点，基于&lt;a href="https://hub.docker.com/_/nginx">Nginx docker容器&lt;/a>。该站点默认没有认证及授权功能，使用外部&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/kymkv6">钉钉&lt;/a>应用作为认证及授权。&lt;/li>
&lt;li>&lt;a href="https://github.com/zxkane/oauth2_proxy">OAuth2 Proxy on Dingtalk&lt;/a>提供基于&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/kymkv6">钉钉&lt;/a>应用的扫码认证及授权，只有认证且授权的用户才可以访问上面的Web站点。&lt;/li>
&lt;/ul>
&lt;h3 id="默认设定">默认设定&lt;/h3>
&lt;ul>
&lt;li>Web站点域名&lt;code>web.kane.mx&lt;/code>&lt;/li>
&lt;li>认证服务域名&lt;code>oauth.kane.mx&lt;/code>&lt;/li>
&lt;/ul>
&lt;h3 id="准备aws-eksaws-eks环境">准备&lt;a href="https://aws.amazon.com/eks/?nc1=f_ls">AWS EKS&lt;/a>环境&lt;/h3>
&lt;ol>
&lt;li>&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html">创建EKS集群&lt;/a>。由于&lt;a href="https://github.com/kubernetes/ingress-nginx">Nginx Ingress&lt;/a>服务是LoadBalancer类型，EKS创建NLB或ELB对应的targets时需要targets部署在public VPC subnets，所以为了简化部署EKS集群的VPC subnets都选择public subnet。新建的EKS集群允许公开访问。&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/managing-auth.html">本地安装配置kubectl, aws-iam-authenticator&lt;/a>用于远程管理集群。&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/launch-workers.html">为集群添加worker节点&lt;/a>。&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/helm.html">配置Helm部署环境&lt;/a>。&lt;/li>
&lt;/ol>
&lt;h3 id="钉钉应用准备">钉钉应用准备&lt;/h3>
&lt;ol>
&lt;li>为企业或组织开通&lt;a href="https://open-dev.dingtalk.com/#/index">钉钉开发平台&lt;/a>&lt;/li>
&lt;li>创建一个新的&lt;a href="https://open-dev.dingtalk.com/#/loginAndShareApp">移动应用&lt;/a>。回调域名填写&lt;code>&amp;lt;http or https&amp;gt;/&amp;lt;认证服务域名&amp;gt;/oauth2/callback&lt;/code>。记录下来应用的&lt;code>appId&lt;/code>和&lt;code>appSecret&lt;/code>。&lt;/li>
&lt;li>创建一个&lt;a href="https://open-dev.dingtalk.com/#/create-bench/self">企业内部工作台应用&lt;/a>。地址可以随意设置。服务器出口IP设置为&lt;code>EKS集群中工作节点的公网IP&lt;/code>或者&lt;code>NAT EIP&lt;/code>，取决于工作节点如何访问Internet。并记录下来应用&lt;code>appKey&lt;/code>和&lt;code>appSecret&lt;/code>。&lt;/li>
&lt;/ol>
&lt;h3 id="部署示例应用">部署示例应用&lt;/h3>
&lt;ol>
&lt;li>克隆&lt;a href="https://github.com/zxkane/hands-on-dingtalk-oauth2-proxy">示例&lt;/a>部署脚本。&lt;/li>
&lt;li>替换&lt;code>values.yaml&lt;/code>中的&lt;code>dingtalk_corpid&lt;/code>为工作台应用的&lt;code>appKey&lt;/code>， &lt;code>dingtalk_corpsecret&lt;/code>为工作台应用的&lt;code>appSecret&lt;/code>。
由于社区维护的&lt;a href="https://github.com/helm/charts/tree/master/stable/oauth2-proxy">oauth2-proxy charts&lt;/a>并不支持dingtalk扩展的SECRET ENV，所以将密钥配置到了&lt;code>configmap&lt;/code>中。用于生产环境的话，建议按&lt;a href="https://github.com/pilipa-cn/charts/commit/7ac0f67acc71577275f743bdcf9a870bd65361b0">这个commit&lt;/a>使用&lt;code>secret&lt;/code>保存应用secret。
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;span class="lnt">70
&lt;/span>&lt;span class="hl">&lt;span class="lnt">71
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">72
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">oauth2-proxy&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">config&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">clientID&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">aaa&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">clientSecret&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">bbb&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">cookieSecret&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ccc&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">configFile&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">|+&lt;/span>&lt;span class="sd">
&lt;/span>&lt;span class="sd"> email_domains = [ &amp;#34;*&amp;#34; ]
&lt;/span>&lt;span class="sd"> cookie_domain = &amp;#34;kane.mx&amp;#34;
&lt;/span>&lt;span class="sd"> cookie_secure = false
&lt;/span>&lt;span class="hl">&lt;span class="sd"> dingtalk_corpid = &amp;#34;&amp;lt;appkey of dingtalk app&amp;gt;&amp;#34;
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="sd"> dingtalk_corpsecret = &amp;#34;&amp;lt;appsecret of dingtalk app&amp;gt;&amp;#34;&lt;/span>&lt;span class="w"> &lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
如果仅希望企业部分部门的员工可以获得授权，在上面&lt;code>configFile&lt;/code>配置下添加如下配置，
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="ln">1&lt;/span>&lt;span class="l">dingtalk_departments = [&amp;#34;xx公司/产品技术中心&amp;#34;,&amp;#34;xx公司/部门2/子部门3&amp;#34;]&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>替换部署应用的域名为你的域名。&lt;/li>
&lt;li>执行以下命令安装Helm部署依赖。
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>helm dep up&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>执行以下命令部署nginx ingress controller, web应用以及oauth2 proxy
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>helm upgrade --install -f values.yaml --set oauth2-proxy.config.clientID&lt;span class="o">=&lt;/span>&amp;lt;移动应用appid&amp;gt;,oauth2-proxy.config.clientSecret&lt;span class="o">=&lt;/span>&amp;lt;移动应用appsecret&amp;gt; site-with-auth --wait ./&lt;/code>&lt;/pre>&lt;/div>
如果集群中已经部署了&lt;code>Nginx Ingress Controller&lt;/code>，修改&lt;code>values.yaml&lt;/code>如下将忽略部署Nginx ingress，
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="hl">&lt;span class="lnt">50
&lt;/span>&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">affinity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>{}&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">nginx-ingress&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">enabled&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">controller&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ingressClass&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">nginx&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">config:&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>部署成功后，获取&lt;code>ELB&lt;/code>地址。
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-zsh" data-lang="zsh">&lt;span class="ln">1&lt;/span>kubectl get svc -o &lt;span class="nv">jsonpath&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;{ $.status.loadBalancer.ingress[*].hostname }&amp;#39;&lt;/span> &amp;lt;deployment name&amp;gt;-nginx-ingress-controller&lt;span class="p">;&lt;/span>&lt;span class="nb">echo&lt;/span>
&lt;span class="ln">2&lt;/span>a3afe672259c511e98e2a0a0d88fda3e-xx.elb.ap-southeast-1.amazonaws.com&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h3 id="部署成功后配置">部署成功后配置&lt;/h3>
&lt;p>将站点和oauth服务域名解析到上面部署创建的ELB上。&lt;/p>
&lt;h3 id="测试">测试&lt;/h3>
&lt;p>访问Web站点(如本示例中的&lt;code>http://web.kane.mx&lt;/code>)，未授权的情况下，调转到钉钉应用扫码登录界面。使用组织内成员的钉钉扫码授权后，将跳转回Web站点应用，可以正常浏览该域名下的页面。&lt;/p></description></item><item><title>基于函数计算的钉钉回调函数接口</title><link>https://kane.mx/posts/effective-cloud-computing/serverless-dingtalk-callback/</link><pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/serverless-dingtalk-callback/</guid><description>
&lt;p>由于企业内部管理的需要，用到了&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/lo5n6i">钉钉的业务事件回调&lt;/a>能力，正好将这个轻量级的接口使用&lt;a href="https://kane.mx/posts/effective-cloud-computing/serverless-computing-101/">无服务器技术&lt;/a>来实现部署，以应对流量无规律下的动态扩展伸缩、按需使用、按量计费等需求。&lt;/p>
&lt;h3 id="阿里云函数计算版本">阿里云函数计算版本&lt;/h3>
&lt;p>由于公司系统部署在阿里云，首先选择使用&lt;a href="https://www.aliyun.com/product/fc">阿里云函数计算&lt;/a>来实现及部署。该接口使用了JVM上语言Kotlin开发，虽然阿里云函数计算官方支持的&lt;a href="https://help.aliyun.com/document_detail/74712.html">开发语言有Java但没有Kotlin&lt;/a>。其实无论Java或Kotlin最终部署文件都是Java Class字节码，加上Kotlin与Java良好的互操作性，实测函数计算可以完美支持Kotlin开发(个人认为任意JVM上的开发语言都是支持的)。&lt;/p>
&lt;p>同时该函数使用了&lt;a href="https://www.aliyun.com/product/ots">表格存储&lt;/a>来持久化回调事件。表格存储是个按量计费的分布式存储，有兴趣的可以自行查阅文档了解更多。&lt;/p>
&lt;p>该函数通过&lt;a href="https://www.aliyun.com/product/apigateway">API网关&lt;/a>和&lt;a href="https://help.aliyun.com/document_detail/100092.html">表格存储触发器&lt;/a>来触发。访问日志和执行日志被存储在&lt;a href="https://www.aliyun.com/product/sls">日志服务&lt;/a>中。&lt;/p>
&lt;p>函数的本地测试和线上部署，使用了函数计算提供的命令行工具&lt;a href="https://help.aliyun.com/document_detail/64204.html">Fun&lt;/a>。基于&lt;a href="https://github.com/aliyun/fun/blob/master/docs/specs/2018-04-03-zh-cn.md?spm=a2c4g.11186623.2.24.717428femnY0Et&amp;amp;file=2018-04-03-zh-cn.md">Fun定义的阿里云Serverless模型&lt;/a>实现了对函数们使用资源的声明和编排，集成&lt;a href="https://about.gitlab.com/product/continuous-integration/">Gitlab CI&lt;/a>实现了&lt;a href="https://github.com/zxkane/dingtalk-callback-on-aliyunfc/blob/master/.gitlab-ci.yml">函数的CI/CD自动化发布流程&lt;/a>。&lt;/p>
&lt;p>不涉及公司业务的代码已&lt;a href="https://github.com/zxkane/dingtalk-callback-on-aliyunfc">开源在Github&lt;/a>，有兴趣的可以作为参考。&lt;/p>
&lt;p>目前&lt;a href="https://help.aliyun.com/document_detail/54301.html">函数计算&lt;/a>和&lt;a href="https://help.aliyun.com/document_detail/52733.html">表格存储&lt;/a>有各自的免费配额，在业务量不大的情况下，该服务完全免费。&lt;/p>
&lt;h3 id="aws-lambda版本">AWS Lambda版本&lt;/h3>
&lt;p>&lt;a href="https://aws.amazon.com/lambda/">AWS Lambda&lt;/a>是目前全球使用最为广泛的serverless服务，同时也是函数计算发展方向的引领者。&lt;/p>
&lt;p>由于一些个人原因，笔者最近接触了部分AWS服务，同时尝试将钉钉回调函数移植到了&lt;a href="https://aws.amazon.com/lambda/">AWS Lambda&lt;/a>上。阿里云上使用的云服务改为由AWS上对应服务来实现，例如存储使用了&lt;a href="https://aws.amazon.com/dynamodb/">DynamoDB&lt;/a>，日志使用&lt;a href="https://aws.amazon.com/cloudwatch/">CloudWatch&lt;/a>收集和查询。&lt;/p>
&lt;p>本地测试和部署工具，使用的是&lt;a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/what-is-sam.html">SAM CLI&lt;/a>，持续集成和持续部署使用的是&lt;a href="https://aws.amazon.com/codebuild/">AWS CodeBuild&lt;/a>和&lt;a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline&lt;/a>。此外AWS通过&lt;a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation&lt;/a>提供一种非常强大的能力，可以将AWS上的各种资源通过配置声明的方式来管理(也就是现在非常热门的一个概念--&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">Infrastructure as Code&lt;/a>)。&lt;a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation&lt;/a>会为每次一个或多个资源的变更生成ChangeSet，提供查看对比、版本管理、遇到变更错误整体回退等能力。所以，AWS版本也将该项目的CI/CD部署用到的&lt;a href="https://aws.amazon.com/codebuild/">AWS CodeBuild&lt;/a>、&lt;a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline&lt;/a>、&lt;a href="https://aws.amazon.com/dynamodb/">Amazon DynamoDB&lt;/a>等资源通过CloudFormation的配置管理起来。&lt;/p>
&lt;p>配置代码段如下，
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="hl">&lt;span class="lnt">56
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">57
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">58
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">59
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">60
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">61
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">62
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">63
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">64
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">65
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">66
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">67
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">68
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">69
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">70
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">71
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">72
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">73
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">74
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">75
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">76
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">77
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">78
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">79
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">80
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">81
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">82
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">83
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="lnt">84
&lt;/span>&lt;/span>&lt;span class="lnt">85
&lt;/span>&lt;span class="lnt">86
&lt;/span>&lt;span class="lnt">87
&lt;/span>&lt;span class="lnt">88
&lt;/span>&lt;span class="lnt">89
&lt;/span>&lt;span class="lnt">90
&lt;/span>&lt;span class="lnt">91
&lt;/span>&lt;span class="lnt">92
&lt;/span>&lt;span class="lnt">93
&lt;/span>&lt;span class="lnt">94
&lt;/span>&lt;span class="lnt">95
&lt;/span>&lt;span class="lnt">96
&lt;/span>&lt;span class="lnt">97
&lt;/span>&lt;span class="lnt">98
&lt;/span>&lt;span class="lnt">99
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">Description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Create a CodePipeline to include Github source, CodeBuild and Lambda deployment.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">Parameters&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">AppBaseName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">App base name&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Default&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">dingtalk-callback&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ArtifactStoreS3Location&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Name of the S3 bucket to store CodePipeline artificat.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">BranchName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GitHub branch name&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Default&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">master&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">RepositoryName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GitHub repository name&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Default&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">dingtalk-callback-on-aws&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">GitHubOAuthToken&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">String&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">NoEcho&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">Resources&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">BuildDingtalkProject&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">AWS::CodeBuild::Project&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Properties&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}-build-${AWS::StackName}&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Build, test, package dingtalk callback project&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ServiceRole&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::GetAtt&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">CodeBuildRole, Arn ]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Artifacts&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">S3&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Location&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Ref&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ArtifactStoreS3Location&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}-build-${AWS::StackName}&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">NamespaceType&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">BUILD_ID&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Path&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}/artifacts&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Packaging&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">NONE&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">OverrideArtifactName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">EncryptionDisabled&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Environment&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">LINUX_CONTAINER&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ComputeType&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">BUILD_GENERAL1_SMALL&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Image&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">aws/codebuild/java:openjdk-11&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">PrivilegedMode&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ImagePullCredentialsType&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">CODEBUILD&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">EnvironmentVariables&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">s3_bucket&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Value&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Ref&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ArtifactStoreS3Location&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Source&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">DingtalkCallbackPipeline&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;AWS::CodePipeline::Pipeline&amp;#39;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Properties&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}-pipeline-${AWS::StackName}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">RoleArn&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::GetAtt&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">CodePipelineRole, Arn ]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Stages&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Source&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Actions&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">SourceAction&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">ActionTypeId&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Category&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Source&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Owner&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ThirdParty&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Version&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Provider&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">GitHub&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">OutputArtifacts&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}-source-changed&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Configuration&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Owner&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>!&lt;span class="l">Ref GitHubOwner&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Repo&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>!&lt;span class="l">Ref RepositoryName&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Branch&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>!&lt;span class="l">Ref BranchName&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">OAuthToken&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>!&lt;span class="l">Ref GitHubOAuthToken&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">PollForSourceChanges&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">RunOrder&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Build&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>&lt;span class="nt">Actions&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="hl">&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Build_Test_Package&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">InputArtifacts&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}-source-changed&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ActionTypeId&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Category&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Build&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Owner&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">AWS&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Version&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Provider&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">CodeBuild&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">OutputArtifacts&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="nt">Name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Fn::Sub&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">${AppBaseName}-packaged-yml&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Configuration&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ProjectName&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">Ref&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">BuildDingtalkProject&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">RunOrder&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="m">1&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/p>
&lt;p>AWS版本完整的代码、CloudFormation配置以及部署文档可以通过&lt;a href="https://github.com/zxkane/dingtalk-callback-on-aws">这里&lt;/a>查看。&lt;/p></description></item><item><title>无服务器计算101</title><link>https://kane.mx/posts/effective-cloud-computing/serverless-computing-101/</link><pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/serverless-computing-101/</guid><description>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Serverless_computing">Serverless Computing(无服务器计算)&lt;/a>是目前最被看好的云端计算执行模型。其最大的好处是提供分布式弹性可伸缩的计算执行环境，仅为实际使用资源付费，并且将应用维护者从常规的运维事务中解放出来，更利于专注到具体的业务上。&lt;/p>
&lt;p>在主流的应用部署方式下，无论是使用&lt;a href="https://aws.amazon.com/cn/ec2">云主机&lt;/a>还是&lt;a href="https://kane.mx/posts/effective-cloud-computing/using-kubernetes-on-cloud/">Kubernetes&lt;/a>作为运行环境，都会有大量运维层面的事务需要考虑和处理，并且应用程序需要按照分布式程序的设计准则来应对应用的水平伸缩。同时随着云计算服务的发展和完善，云计算厂商提供了越来越多的基础服务，例如API网关、对象存储、消息队列、日志、监控等服务，函数计算可以完美的同其他云服务集成，帮助用户快速实现出生产级别的弹性可伸缩的应用。&lt;/p>
&lt;p>那&lt;a href="https://en.wikipedia.org/wiki/Serverless_computing">函数计算&lt;/a>是什么呢？让我们一起来看看&lt;a href="https://help.aliyun.com/document_detail/52895.html">阿里云对于函数计算的定义&lt;/a>。&lt;/p>
&lt;blockquote>
&lt;p>阿里云函数计算是事件驱动的全托管计算服务。通过函数计算，您无需管理服务器等基础设施，只需编写代码并上传。函数计算会为您准备好计算资源，以弹性、可靠的方式运行您的代码，并提供日志查询、性能监控、报警等功能。借助于函数计算，您可以快速构建任何类型的应用和服务，无需管理和运维。而且，您只需要为代码实际运行所消耗的资源付费，代码未运行则不产生费用。&lt;/p>
&lt;/blockquote>
&lt;p>基于函数计算的特点，可以很好满足以下需求，&lt;/p>
&lt;ul>
&lt;li>业务流量不确定或有明细的周期性&lt;/li>
&lt;li>构建分布式系统经验不足&lt;/li>
&lt;li>无需运维&lt;/li>
&lt;li>按需计算&lt;/li>
&lt;li>计费灵活&lt;/li>
&lt;/ul>
&lt;p>由于函数计算的扩展能力，对运维的要求极少，按量计费等特性用于需要快速验证的早期项目也是非常好的场景。&lt;/p>
&lt;p>下面这个slide是近期针对阿里云函数计算做的分享。&lt;/p>
&lt;div class="responsive-wrap">
&lt;iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQpucN0Imyd1rram7bmQJzO5lRwRrph5KDL18swF_MuKiUFm4_H2Hg8cpUnP_83yqleJnSXYtE9gvUv/embed?start=false&amp;amp;loop=false&amp;amp;delayms=60000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true">&lt;/iframe>
&lt;/div></description></item><item><title>为Kubernetes中任意应用添加基于oauth2的认证保护 (上)</title><link>https://kane.mx/posts/effective-cloud-computing/oauth2-proxy-on-kubernetes/part1/</link><pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/oauth2-proxy-on-kubernetes/part1/</guid><description>
&lt;p>企业随着业务的发展，必然会部署各种各样的IT系统。出于安全性的考虑，一些系统仅可企业内部使用，甚至仅开放给企业部分部门员工使用。&lt;/p>
&lt;p>这些IT系统大致可分为两类，&lt;/p>
&lt;ol>
&lt;li>系统本身不支持任何认证机制，例如资讯或文档类系统。需要增加认证保护，能够限制非企业员工访问即可。系统运维通常的做法是，为站点设置&lt;a href="https://en.wikipedia.org/wiki/Basic_access_authentication">HTTP Basic认证&lt;/a>保护。由于&lt;a href="https://en.wikipedia.org/wiki/Basic_access_authentication">HTTP Basic认证&lt;/a>是通过预设的用户、密码认证，认证信息比较容易泄露。即使定期更换密码，但需要额外的机制通知用户密码的变更，用户体验也不好。&lt;/li>
&lt;li>系统自身支持认证，甚至支持多种认证机制。比如最常用的开源CI/CD工具，&lt;a href="https://jenkins.io/">Jenkins&lt;/a>内置支持本地数据库认证、通过&lt;a href="https://plugins.jenkins.io/#">插件&lt;/a>支持多种第三方系统集成认证。如果大量的IT系统都有一套独立的用户管理，随着企业的员工的变更，用户的增删等操作对系统管理员来说是不小的工作量。同时，也很容易由于人为疏忽，造成资产、数据的安全隐患。&lt;/li>
&lt;/ol>
&lt;p>假设企业自身已经有了一套OA系统包含员工、组织结构管理，例如，国内目前最为普及流行的&lt;a href="https://www.dingtalk.com/">钉钉&lt;/a>或&lt;a href="https://work.weixin.qq.com/">企业微信&lt;/a>。我们完全可以提供一套基于&lt;a href="https://oauth.net/2/">oauth 2.0协议&lt;/a>的认证方式，让以上两类IT系统使用企业已有的OA系统(&lt;a href="https://www.dingtalk.com/">钉钉&lt;/a>或&lt;a href="https://work.weixin.qq.com/">企业微信&lt;/a>)来实现登录认证。做到这一点后，企业无论有多少IT系统都不再需要额外管理用户的成本，并且也避免了数据安全隐患。&lt;/p>
&lt;p>&lt;a href="https://www.dingtalk.com/">钉钉&lt;/a>通过&lt;a href="https://open-dev.dingtalk.com">钉钉开放平台&lt;/a>提供的API开放了许多钉钉内部的能力，例如，&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/vt6khw">身份验证&lt;/a>、&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/cqfmel">通讯录管理&lt;/a>等等。然而&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/kymkv6">钉钉的三方网站登录接口&lt;/a>并不是标准的&lt;a href="https://oauth.net/2/">oauth 2.0协议&lt;/a>实现，我们需要通过一个&lt;a href="https://github.com/zxkane/oauth2_proxy">oauth2 proxy&lt;/a>代理工具实现将&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/kymkv6">钉钉的三方网站登录&lt;/a>兼容&lt;a href="https://oauth.net/2/">oauth2&lt;/a>协议。同理，使用&lt;a href="https://github.com/bitly/oauth2_proxy">这个oauth2代理工具&lt;/a>，可以使用&lt;a href="https://github.com/bitly/oauth2_proxy#google-auth-provider">Google&lt;/a>、&lt;a href="https://github.com/bitly/oauth2_proxy#facebook-auth-provider">Facebook&lt;/a>等三方网站作为统一认证方式。&lt;/p>
&lt;p>有了基于&lt;a href="https://github.com/zxkane/oauth2_proxy">钉钉的oauth2代理&lt;/a>作为企业统一登录方式，对于上面两大类系统的认证需求解决方案分别如下，&lt;/p>
&lt;ol>
&lt;li>部署在&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>中无内置认证机制的Web应用，通过&lt;a href="https://kubernetes.github.io/ingress-nginx/">nginx-ingress&lt;/a>的&lt;a href="https://kubernetes.github.io/ingress-nginx/examples/auth/oauth-external-auth/">外部OAUTH认证&lt;/a>实现基于oauth2的安全认证。&lt;/li>
&lt;li>&lt;a href="https://jenkins.io/">Jenkins&lt;/a>可以通过&lt;a href="https://plugins.jenkins.io/reverse-proxy-auth-plugin">反向代理插件&lt;/a>实现使用oauth2认证登录。&lt;/li>
&lt;/ol>
&lt;p>在&lt;a href="https://kane.mx/posts/effective-cloud-computing/oauth2-proxy-on-kubernetes/part2/">下篇&lt;/a>中，我们将图文详解如何一步步实现为一个无认证的企业文档Web应用添加基于&lt;a href="https://open-doc.dingtalk.com/microapp/serverapi2/vt6khw">钉钉的统一认证&lt;/a>。&lt;/p></description></item><item><title>IAM最佳实践</title><link>https://kane.mx/posts/effective-cloud-computing/iam-best-practice/</link><pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/iam-best-practice/</guid><description>
&lt;p>企业使用公有云服务的第一件事情就是创建云帐号，有了帐号之后如何让企业员工安全合规的使用云帐号下的各种资源是开启云之旅后的第一个考验。&lt;/p>
&lt;p>云计算厂商针对企业上云后面临的第一个需求已经推出了完善的解决方案--&lt;a href="https://en.wikipedia.org/wiki/Identity_management">Identity and Access Management&lt;/a>。&lt;a href="https://en.wikipedia.org/wiki/Identity_management">IAM&lt;/a>可以帮助云帐号安全地控制对云计算服务资源的访问。企业可以使用IAM控制对哪个用户进行身份验证 (登录) 和授权 (具有权限) 以使用资源。&lt;/p>
&lt;p>云厂商是否提供完善的IAM服务可以作为整体产品解决方案是否成熟的一个衡量指标，比如AWS的&lt;a href="https://docs.aws.amazon.com/zh_cn/IAM/latest/UserGuide/introduction.html">IAM&lt;/a>和阿里云的&lt;a href="https://help.aliyun.com/document_detail/28627.html">访问控制&lt;/a>都是较为成熟完善的产品。国内某个以AI能力为卖点的云厂商，在IAM产品方面几乎为零，很难相信对安全合规有需求的企业会完整使用他的云产品作为解决方案。&lt;/p>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Identity_management">IAM&lt;/a>通常提供以下功能:&lt;/p>
&lt;h3 id="对云账户的共享访问权限">对云账户的共享访问权限&lt;/h3>
&lt;p>允许在一个云账户下创建并管理多个用户身份，并允许给单个身份或一组身份（既可以是当前云帐号下也可以是其他云帐号下）分配不同的权限策略，从而实现不同用户拥有不同的云资源访问权限，而不必共享云帐号根用户的密码或访问密钥。&lt;/p>
&lt;h3 id="精细权限">精细权限&lt;/h3>
&lt;p>可以针对不同资源向不同人员授予不同权限。可以要求用户必须使用安全信道（如 SSL）、在指定时间范围、或在指定源 IP 条件下才能操作指定的云资源。&lt;/p>
&lt;h3 id="多重验证-mfa">多重验证 (MFA)&lt;/h3>
&lt;p>可以向云账户和各个用户添加双重身份验证以实现更高安全性。借助&lt;a href="https://en.wikipedia.org/wiki/Multi-factor_authentication">MFA&lt;/a>，用户不仅必须提供使用账户所需的密码或访问密钥，还必须提供来自经过特殊配置的设备的代码。&lt;/p>
&lt;h3 id="联合身份">联合身份&lt;/h3>
&lt;p>可以允许已在其他位置（例如，在企业网络中或通过 Internet 身份提供商）获得密码的用户获取对云账户的用户访问权限。&lt;/p>
&lt;p>后面会有专门的文章来讲如何实践联合身份。&lt;/p>
&lt;h3 id="统一账单">统一账单&lt;/h3>
&lt;p>云账户接收包括所有用户的资源操作所发生费用的统一账单。&lt;/p>
&lt;blockquote>
&lt;p>尽管&lt;a href="https://en.wikipedia.org/wiki/Identity_management">IAM&lt;/a>提供了上面种种功能，云帐号的管理者仍可通过一些最佳实践来更好的使用IAM产品来提升安全级别和减少运维成本。&lt;/p>
&lt;/blockquote>
&lt;h2 id="iam最佳实践">IAM最佳实践&lt;/h2>
&lt;ul>
&lt;li>尽量不要使用云帐号的根用户，&lt;strong>不要为根用户创建AK&lt;/strong>。云帐号管理员也使用各自独立的子账号。&lt;/li>
&lt;li>&lt;strong>为企业中每一个需要使用云服务的员工单独创建子账户，且默认不允许创建AK&lt;/strong>。便于员工离职的时候，通过删除帐号来完全清理用户在云计算平台的各种权限。&lt;/li>
&lt;li>密码安全实践，
&lt;ul>
&lt;li>限制密码强度&lt;strong>不少于8位&lt;/strong>，必须&lt;strong>由大小写字母、数字和符号中的三种组成&lt;/strong>。&lt;/li>
&lt;li>强制密码&lt;strong>过期时间不超过90天&lt;/strong>，且过期后不可登录。&lt;/li>
&lt;li>新密码至少&lt;strong>禁止使用前3次密码&lt;/strong>。&lt;/li>
&lt;li>设置密码重试约束，例如，&lt;strong>一小时内使用错误密码最大尝试9次登录&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>强制所有用户启用&lt;a href="https://en.wikipedia.org/wiki/Multi-factor_authentication">两步认证&lt;/a>。&lt;/li>
&lt;li>对访问网络有限制的企业，可以开启登录IP限制。&lt;/li>
&lt;li>[&lt;strong>推荐做法&lt;/strong>]已有SSO单点登录系统的企业，可以通过&lt;a href="https://en.wikipedia.org/wiki/SAML_2.0">SAML 2.0标准&lt;/a>实现从企业本地账号系统登录到阿里云，从而满足企业的统一用户登录认证要求。&lt;/li>
&lt;li>细粒度的权限管理，
&lt;ul>
&lt;li>&lt;strong>为各种云资源创建最细粒度的权限策略&lt;/strong>。例如，分别为RDS实例&lt;code>rds-instance-1&lt;/code>创建只读权限策略&lt;code>rds-instance-1-readonly-access&lt;/code>，RDS实例&lt;code>rds-instance-2&lt;/code>创建只读权限策略&lt;code>rds-instance-2-readonly-access&lt;/code>。&lt;/li>
&lt;li>&lt;strong>根据职能、部门等维度为云帐号子用户创建用户组&lt;/strong>。例如，按项目创建用户组，&lt;code>group-project-a&lt;/code>，&lt;code>group-project-b&lt;/code>。如果&lt;code>project-a&lt;/code>用户需要访问&lt;code>rds-instance-1&lt;/code>的信息，将自定义权限&lt;code>rds-instance-1-readonly-access&lt;/code>授权给&lt;code>group-project-a&lt;/code>。再将相关用户加到用户组&lt;code>group-project-a&lt;/code>中，这样这些用户就具有只读访问RDS实例&lt;code>rds-instance-1&lt;/code>的权限。而不是将所有RDS的读写权限都授予这些用户，&lt;strong>最大限度的保证用户不获取超过实际需要的权限&lt;/strong>。&lt;/li>
&lt;li>在实际场景中，通常会通过云计算服务的API来完成某些周期性任务，比如每日RDS中的慢查询统计、云帐号每日花费统计等。这些任务都需要一个云帐号的AK来完成API的身份认证。最佳的做法是，&lt;strong>为每类相关的任务创建一个&lt;code>功能性子账号&lt;/code>&lt;/strong>，禁用他们的web登录，且遵循特殊的命名规范(&lt;code>functional-&lt;/code>开头)，比如&lt;code>functional-rds-stats&lt;/code>、&lt;code>functional-cost-stats&lt;/code>。创建最小的权限策略，然后分配给这些功能性用户。例如，&lt;code>functional-rds-stats&lt;/code>仅被授予RDS只读权限，&lt;code>functional-cost-stats&lt;/code>仅被授予费用的只读权限。为这些子账号创建AK，每类任务使用不同的AK来完成API认证，而不是都使用同一个AK。这样的好处是，不同类型任务的AK具有不同的权限，最大限度的保护了云帐号的安全，并且这些AK不跟实际的员工子账号关联，不会因为员工帐号的变更而受影响。如有更高的安全合规的要求下，可以定期作废已有AK，创建新AK替换。至于AK怎样安全管理，之后会有专门的文章来详解。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>不要自建Kubernetes</title><link>https://kane.mx/posts/effective-cloud-computing/using-kubernetes-on-cloud/</link><pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/using-kubernetes-on-cloud/</guid><description>
&lt;p>这是“如何高效使用云服务”系列文章的首篇分享。可能有朋友好奇为什么不是从云计算最基础的服务--计算资源&lt;a href="https://cn.aliyun.com/product/ecs">ECS&lt;/a>/&lt;a href="https://aws.amazon.com/cn/ec2/">EC2&lt;/a>讲起呢？在&lt;a href="https://pivotal.io/cloud-native">Cloud Native&lt;/a>已经被越来越接受的今天，基于&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>部署、编排应用的方式已经是业界的事实标准。无论是互联网巨头，传统500强企业，还是创业团队都在使用或规划使用&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>作为应用程序的自动化部署、可扩展管理平台。在云计算平台，虚拟机越来越不需要单独的管理，在绝大多数的业务场景下，它们只是作为容器集群所管理的计算资源。甚至虚拟机的创建到销毁整个生命周期管理都可以由&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>根据集群的负载来自动完成。&lt;/p>
&lt;p>所有主流的云计算厂商都在解决方案中力推托管的&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>，&lt;a href="https://aws.amazon.com/cn/">AWS&lt;/a>的&lt;a href="https://aws.amazon.com/eks">EKS&lt;/a>，&lt;a href="https://azure.microsoft.com/en-us/">Azure&lt;/a>上的&lt;a href="https://azure.microsoft.com/en-us/services/kubernetes-service/">AKS&lt;/a>，当然少不了Google家&lt;a href="https://cloud.google.com/">GCP&lt;/a>上的&lt;a href="https://cloud.google.com/kubernetes-engine/">Kubernetes Engine&lt;/a>。国内&lt;a href="https://www.aliyun.com/product/kubernetes">阿里云&lt;/a>，&lt;a href="https://cloud.tencent.com/product/tke">腾讯云&lt;/a>等每一个公有云玩家也都基于开源&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>推出了托管服务。如果一家云计算厂商在提供托管&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>这一服务上没跟上业界的步伐，将来极大可能被淘汰出这个市场。&lt;/p>
&lt;h2 id="托管的kubernetes类型">托管的Kubernetes类型&lt;/h2>
&lt;p>以国内的阿里云为例，目前提供了两大类三种不同的&lt;a href="https://help.aliyun.com/document_detail/86737.html">Kubernetes托管服务&lt;/a>。&lt;/p>
&lt;ul>
&lt;li>经典Dedicated Kubernetes模式。这种模式下用户可以选择宿主机实例规格和操作系统，指定Kubernetes版本、自定义Kubernetes特性开关设置等。用户需要手动维护集群，例如升级Kubernetes版本，内置组件版本等。可以手动或自动伸缩集群节点数目。目前该模式下有两种类型，第一种集群主节点需要使用用户的ECS，用户可远程登录或管理这些ECS。另一种是，主节点也由云厂商托管，用户只能通过API Server管理Kubernetes。在费用方面，无论是否托管集群主节点，集群服务免费，按使用的ECS实例及计费方式收费。&lt;/li>
&lt;li>Serverless 模式(目前公测中，暂时免费)。无需创建底层虚拟化资源，可以利用 Kubernetes 命令指明应用容器镜像、CPU和内存要求以及对外服务方式，直接启动应用程序。按容器使用的CPU和内存资源量计费。这种模式下应该是在一个集群内实现多租户，目前有些&lt;a href="https://help.aliyun.com/document_detail/86371.html">features不被支持&lt;/a>。例如，部署不支持DaemonSet，Ingress不支持NodePort类型，存储不支持PV和PVC等。&lt;/li>
&lt;/ul>
&lt;p>用户可以根据自己的业务类型来选择适合的托管Kubernetes集群。如果部署的应用是&lt;a href="https://kubernetes.io/docs/tutorials/stateless-application/">无状态的Web服务&lt;/a>，可以选择Serverless Kubernetes集群，进一步减少运维工作量。&lt;/p>
&lt;p>如果用户部署的应用有状态，需要挂载外部存储，例如MongDB集群，MQ集群，可以选择经典Dedicated Kubernetes模式。如果用户需要通过Kubernetes组件扩展或自定义实现某些功能，这些需求云厂商的标准版并没有提供，这时可以选择经典Dedicated Kubernetes模式，利用Kubernetes高度灵活的扩展机制来满足自定义需求。&lt;/p>
&lt;h2 id="托管kuberentes的优势">托管Kuberentes的优势&lt;/h2>
&lt;p>国内的阿里云有篇技术文档对比&lt;a href="https://help.aliyun.com/document_detail/69575.html">阿里云Kubernetes vs. 自建Kubernetes&lt;/a>，文章看起来虽然有厂商自卖自夸的嫌疑。作为&lt;a href="https://www.aliyun.com/product/kubernetes">阿里云K8S&lt;/a>的客户，在使用托管K8S近一年来，深切的体会到云厂商托管K8S带来的种种好处，文档中提到的种种优势确实是言之凿凿。&lt;/p>
&lt;p>接下来具体看看云厂商托管K8S到底有哪些优势。&lt;/p>
&lt;h3 id="便捷">便捷&lt;/h3>
&lt;ul>
&lt;li>通过Web界面/API一键创建Kubernetes集群，集群升级。&lt;/li>
&lt;li>Web界面/API实现集群的扩容或缩容。&lt;/li>
&lt;/ul>
&lt;p>集群的安装，补丁以及常规版本升级在运维工作中属于体力活。在规模不大的时候，使用人工实现需要花费不少时间准备环境测试验证，且易错。如果集群体量不够大的话，开发自动化运维脚本又浪费人力成本。云计算厂商的托管K8S集群将提供专业、稳定的技术运维服务，和几乎为零的人力成本。&lt;/p>
&lt;p>从效率和人力成本上看，&lt;strong>托管K8S集群完胜自建Kubernetes集群&lt;/strong>。&lt;/p>
&lt;h3 id="功能更强大">功能更强大&lt;/h3>
&lt;p>&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>作为一个容器编排系统，开源版本中许多组件没有默认实现或实现有限，需要跟运行环境(如托管K8S的云平台)集成。例如，存储，Load Balancer，网络等核心组件。官方文档&lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer">Internal load balancer&lt;/a>就提供了在不同的云厂商环境中的使用示例。部署一个强大且完整的K8S集群需要同许多云计算的基础组件集成(且只能通过API完成)，这往往是云计算厂商的强项。&lt;/p>
&lt;p>云厂商托管的K8S可以在以下方面提供强大的云计算平台支持，&lt;/p>
&lt;h4 id="网络">网络&lt;/h4>
&lt;ul>
&lt;li>高性能 VPC 网络插件。&lt;/li>
&lt;li>支持 network policy 和流控。&lt;/li>
&lt;/ul>
&lt;h4 id="负载均衡">负载均衡&lt;/h4>
&lt;p>支持创建公网或内网负载均衡实例，或者复用已有实例。支持指定带宽大小、计费方式、4层或7层协议代理等云厂商负载均衡功能。对应用运维来说可以把负载均衡的配置通过代码实现，并且支持版本控制。对比传统的云端部署，也可以将应用部署和应用运维集成在一起统一管理，避免应用发布和运维配置的割裂，减少人为运维失误。&lt;/p>
&lt;p>阿里云托管K8S的负载均衡详细配置可以参考这个&lt;a href="https://help.aliyun.com/document_detail/53759.html?spm=a2c4g.11186623.2.15.73364c07mR8rhS#h2-url-4">文档&lt;/a>，AWS上见此&lt;a href="https://docs.aws.amazon.com/eks/latest/userguide/load-balancing.html">文档&lt;/a>。&lt;/p>
&lt;h4 id="存储">存储&lt;/h4>
&lt;p>集成了云厂商的云盘、文件存储NAS、块存储等存储方案，基于标准的&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/flexvolume.md">FlexVolume&lt;/a>驱动，提供了最佳的无缝集成。&lt;/p>
&lt;p>如果是在云厂商的虚拟机上自建&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>集群，默认无法使用云上的存储资源。如果需要利用云厂商提供的存储方案，例如对象存储，就需要自行开发基于&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/flexvolume.md">FlexVolume&lt;/a>的驱动。在厂商托管K8S已经完美解决了存储集成的问题，何必自己又去费时费力的定制开发呢？&lt;/p>
&lt;p>可以看到，云厂商托管的K8S集群在网络、负载均衡和存储上有许多天然的优势。在其他几个维度，托管的K8S集群同样也优于自建的K8S，&lt;/p>
&lt;h4 id="运维">运维&lt;/h4>
&lt;ul>
&lt;li>集成厂商的日志服务，监控服务。&lt;/li>
&lt;li>K8S集群cluster autoscaler自动利用云厂商的弹性伸缩扩缩容集群节点。&lt;/li>
&lt;/ul>
&lt;h4 id="镜像仓库">镜像仓库&lt;/h4>
&lt;ul>
&lt;li>高可用，支持大并发。&lt;/li>
&lt;li>支持镜像加速。&lt;/li>
&lt;li>支持 p2p 分发。&lt;/li>
&lt;li>可集成云平台的用户权限。&lt;/li>
&lt;li>部分厂商目前免费且不限容量。&lt;/li>
&lt;/ul>
&lt;h4 id="高可用">高可用&lt;/h4>
&lt;ul>
&lt;li>提供多可用区支持。&lt;/li>
&lt;li>支持备份和容灾。&lt;/li>
&lt;/ul>
&lt;h4 id="技术支持">技术支持&lt;/h4>
&lt;ul>
&lt;li>专门的技术团队保障容器的稳定性。&lt;/li>
&lt;li>每个 Linux 版本，每个 Kubernetes 版本都会在经过严格测试之后之后才会提供给用户。&lt;/li>
&lt;li>提供 Kubernetes 升级能力，新版本一键升级。&lt;/li>
&lt;li>为开源软件提供兜底，无论是K8S、Docker甚至Linux自身的问题提供支持。&lt;/li>
&lt;/ul>
&lt;p>专业的技术团队是提供稳定K8S服务必不可少的。但绝大多数企业是无法做到有专业的技术团队来维护K8S、提供K8S或容器技术自身的各种最佳实践、发现以及修复开源软件Bug。&lt;/p>
&lt;p>在笔者的使用托管K8S的时候就遇到这样的状况。其中一个集群升级到新版本&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>后，内置DNS组件从&lt;a href="https://github.com/kubernetes/dns">KubeDNS&lt;/a>被替换为全新的&lt;a href="https://coredns.io/">CoreDNS&lt;/a>，而当时的&lt;a href="https://coredns.io/">CoreDNS&lt;/a>版本在&lt;a href="https://kubernetes.io/docs/concepts/services-networking/service/#externalname">Service ExternalName&lt;/a>支持上有Bug，导致已有的这种Service无法提供服务。在同云厂商的技术团队沟通后，先用workaround将问题快速绕过，不影响业务的使用。同时，云厂商的技术人员（也是K8S社区committer）继续调研，发现该问题是&lt;a href="https://coredns.io/">CoreDNS&lt;/a>的Bug。在为开源&lt;a href="https://coredns.io/">CoreDNS&lt;/a>项目创建Issue后，同时提供Patch，又在CoreDNS committer建议下完善了测试用例，推动了该问题快速在CoreDNS中被修复。CoreDNS包含Fix的版本发布后，云厂商技术支持团队将更完美的解决方案提供给了我们。作为K8S服务的用户，这种体验是极好的。当时我们的技术团队既没有精力也没有能力快速发现并修复开源软件中的这类问题，而云厂商的服务间接帮我们实现了这种能力。&lt;/p>
&lt;p>&lt;strong>这其实是一种非常好的共赢商业模式，云厂商有能力且有动力投入顶尖技术团队将开源技术商业化，云厂商的用户则用最小的代价获得了最优的基础服务来为核心业务赋能。&lt;/strong>&lt;/p></description></item><item><title>真的会用云服务吗？</title><link>https://kane.mx/posts/effective-cloud-computing/preface/</link><pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/effective-cloud-computing/preface/</guid><description>
&lt;p>这是“如何高效使用云服务”系列文章的引子。该系列将讲述如何利用各种公有云服务来安全合规、高质量、快速、低成本的打造产品/系统，帮助企业（特别是中小微创业团队）在人少，钱缺的情况下做到最高效率。&lt;/p>
&lt;h2 id="个人使用公有云服务的经历">个人使用公有云服务的经历&lt;/h2>
&lt;h3 id="初会">初会&lt;/h3>
&lt;p>最早是2012年在parttime项目中开始接触使用云计算服务，当时的初创团队也是希望用最低的成本来验证idea，所有使用了云服务来做POC。目前国内市场最领先的云计算厂商&lt;a href="https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E4%BA%91#4">阿里云那时也才提供公有云服务不到1年&lt;/a>。由于云产品不够成熟，加上团队技能经验不足，自助互助的渠道不畅，导致最初的云计算使用体验并不好，团队没有选择完全使用云服务构建产品。&lt;/p>
&lt;h3 id="iaas-or-paas">IaaS or PaaS&lt;/h3>
&lt;p>云计算兴起的早期，云厂商大致分为两类，提供基于&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_a_service">IaaS&lt;/a>或&lt;a href="https://en.wikipedia.org/wiki/Platform_as_a_service">PaaS&lt;/a>的云服务。2013年起也有尝试不同类型的厂商平台，虽然也较好的完成一些体量不大的项目，但要在他们上面构建大规模用户产品或企业级应用，在云产品完善度上或支持开发团队协作上都有不少欠缺，还有大量的基础工作或限制留给了开发团队自身解决。&lt;/p>
&lt;h3 id="all-in-cloud">All-in Cloud&lt;/h3>
&lt;p>2015年我开始一个微电影项目创业，团队是不到10人的微型团队。从效率和成本考虑，我们将所有的服务都放到了阿里云上。我们使用了多种云产品，例如，云主机（多种OS），对象存储，图片处理，CDN，SLB，人脸识别等云服务，结合&lt;a href="https://en.wikipedia.org/wiki/DevOps">Devops&lt;/a>集成开发，测试，部署pipeline来加速产品的迭代和更新。每名工程师承担一种以上角色，前端，后端，运维，数据，视频渲染等。合理使用云厂商的各种产品帮我们在质量，效率，成本上获得巨大的收益。&lt;/p>
&lt;p>2017年我加入了一家企业财税服务的初创公司负责技术团队。公司在2018年获得了B轮投资，研发产品运营团队近百人，属于中等规模。随着各种开源技术的巨大进步和影响逐步扩大，&lt;a href="https://en.wikipedia.org/wiki/Microservices">微服务&lt;/a>架构的流行，基于&lt;a href="https://kubernetes.io/">Kubernetes&lt;/a>的&lt;a href="https://www.cncf.io/">Cloud Native Computing&lt;/a>兴起。我们利用云厂商的容器服务，&lt;a href="https://en.wikipedia.org/wiki/Cloud_database">DBaaS&lt;/a>，Big Data，AI技术等用最高效的方式将数个单体应用平滑升级到高可用弹性的分布式架构，更好的满足复杂业务的多变需求，公司服务也在全国300多个城市落地，服务了数十万中小微企业客户。同时利用云厂商的VPC，访问控制，WAF等产品进行权限控制和安全保护，有效防范了因为团队扩大管理难度增加而出现安全问题。&lt;/p>
&lt;h2 id="缘起">缘起&lt;/h2>
&lt;p>作为一名云计算服务6年的用户，见证了开源技术的快速发展和影响力急剧扩大，感受到整个云计算行业和厂商的长足进步。见证了国内头部云厂商从最初的使用难度颇大，现在成长为万众创业的首选服务商。&lt;/p>
&lt;p>过去的一年参加了数场技术会议，其中主题大多偏向于由知名的互联网或行业公司分享在海量数据下的技术应用。这些技术广泛涉及开发语言、应用架构、性能、大数据、机器学习和人工智能等领域，无论这些公司是否采用开源产品，在团队单兵技术能力，专业的分工，对开源项目的研发投入力量，这些经验和方法并不是中小企业可以轻易借鉴的。而云计算厂商将这些领域最基础通用的能力以产品的方式输出给用户，以按用量的方式计费，使用更简单，有专业团队维护和支持。中小团队就应该将这些事情“外包”给云厂商，集中精力到业务上，将最大的研发资源用到最核心最关键的地方。&lt;/p>
&lt;p>我同团队同事沟通中，和公司研发候选人面试交流中，发现许多从业者对云计算服务了解还不够深入。许多人理解中的云计算服务只有云服务器、云数据库等少数产品，需要自己安装维护应用服务器、负载均衡、收集日志等等看起来每个应用都绕不开的事情。他们的认知还停留在排查应用异常还需要远程登录服务器看日志，做不到合理的根据场景高效组合使用云服务，将云服务当做水电一样，作为最基础的能力加速业务的发展。业务上是采用名气大且成熟的产品，尝试新鲜看起来酷但不那么完善的产品，还是二次开发或自研开发？要做出最优的选择需要工程师能够从有高度的全局角度来考量，甚至在短时间内能用POC项目验证多个可选的方案，基于数据做出最终的选择。&lt;/p>
&lt;p>这就是这个系列的缘起，之后我将陆续分享使用那些高效的云服务产品的场景、心得、体会等等。&lt;/p>
&lt;blockquote>
&lt;p>封面图片&lt;a href="http://www.thebluediamondgallery.com/tablet/c/cloud-computing.html">Cloud Computing&lt;/a>引用自&lt;a href="http://www.thebluediamondgallery.com/">The Blue Diamond Gallery&lt;/a> under &lt;a href="http://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0&lt;/a>&lt;/p>
&lt;/blockquote></description></item></channel></rss>