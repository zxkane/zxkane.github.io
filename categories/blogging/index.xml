<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blogging on The road</title><link>https://kane.mx/categories/blogging/</link><description>Recent content in Blogging on The road</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 14 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://kane.mx/categories/blogging/index.xml" rel="self" type="application/rss+xml"/><item><title>Deep dive clickstream analytic series: Data Processing</title><link>https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/</link><pubDate>Sat, 14 Sep 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/</guid><description>
&lt;p>In this post, we will delve into the data processing module of our &lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/preface/">clickstream solution&lt;/a>. This module is an optional component that normalizes raw clickstream events by cleaning, transforming, and enriching them to fit the standard clickstream data schema defined in the solution. It's designed for flexibility, reliability, high performance, and cost-effectiveness.&lt;/p>
&lt;h2 id="overview-architecture">Overview Architecture&lt;/h2>
&lt;p>
&lt;figure>
&lt;picture>
&lt;source srcset="https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/images/architecture.avif" type="image/avif">
&lt;source srcset="https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/images/architecture.webp" type="image/webp">
&lt;img
loading="lazy"
decoding="async"
alt="Overview architecture"
class="image_figure image_internal image_processed"
width="921"
height="401"
src="https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/images/architecture.png"
title="Overview architecture for data process module"
/>
&lt;figcaption class="caption_figure caption_internal">Overview architecture for data process module&lt;/figcaption>&lt;/picture>
&lt;/figure>
&lt;/p>
&lt;p>The data processing is designed for batch or micro-batch data processing to optimize performance and cost-effectiveness. It's primarily an Apache Spark application running on &lt;a href="https://aws.amazon.com/emr/serverless/">Amazon EMR Serverless&lt;/a> to achieve a balance between high performance and cost. It offers the following capabilities:&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/data-processing/">Read More&lt;/a>&lt;/p></description></item><item><title>Deep dive clickstream analytic series: Data Ingestion</title><link>https://kane.mx/posts/deep-dive-clickstream-analytics/data-ingestion/</link><pubDate>Sun, 08 Sep 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/deep-dive-clickstream-analytics/data-ingestion/</guid><description>
&lt;p>In this post, we will delve into the data ingestion service of our &lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/preface/">clickstream solution&lt;/a>. This service is a vital part of the clickstream analytics system. It is designed to be reliable, resilient, high-performing, flexible, and cost-effective. It plays a key role in capturing clickstream data from various sources and delivering it to downstream processing and modeling components.&lt;/p>
&lt;h2 id="overview-architecture">Overview Architecture&lt;/h2>
&lt;p>
&lt;figure>
&lt;picture>
&lt;source srcset="https://kane.mx/posts/deep-dive-clickstream-analytics/data-ingestion/images/architecture.avif" type="image/avif">
&lt;source srcset="https://kane.mx/posts/deep-dive-clickstream-analytics/data-ingestion/images/architecture.webp" type="image/webp">
&lt;img
loading="lazy"
decoding="async"
alt="Overview architecture"
class="image_figure image_internal image_processed"
width="1000"
height="458"
src="https://kane.mx/posts/deep-dive-clickstream-analytics/data-ingestion/images/architecture.png"
title="Overview architecture for data ingestion service"
/>
&lt;figcaption class="caption_figure caption_internal">Overview architecture for data ingestion service&lt;/figcaption>&lt;/picture>
&lt;/figure>
&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/data-ingestion/">Read More&lt;/a>&lt;/p></description></item><item><title>Deep dive clickstream analytic series: Serverless web console</title><link>https://kane.mx/posts/deep-dive-clickstream-analytics/web-console/</link><pubDate>Wed, 04 Sep 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/deep-dive-clickstream-analytics/web-console/</guid><description>
&lt;p>This post explores the &lt;a href="https://docs.aws.amazon.com/solutions/latest/clickstream-analytics-on-aws/how-the-solution-works.html#web-console">web console&lt;/a> module of the &lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/preface/">clickstream solution&lt;/a>.&lt;/p>
&lt;p>The web console allows users to create and manage projects with their data pipeline, which ingests, processes, analyzes, and visualizes clickstream data. In version 1.1, the &lt;a href="https://docs.aws.amazon.com/solutions/latest/clickstream-analytics-on-aws/analytics-studio.html">Analytics Studio&lt;/a> was introduced for &lt;strong>business analysts&lt;/strong>, enabling them to view metrics dashboards, explore clickstream data, design customized dashboards, and manage metadata without requiring in-depth knowledge of data warehouses and SQL.&lt;/p>
&lt;h2 id="one-code-base-for-different-architectures">One code base for different architectures&lt;/h2>
&lt;p>The web console is a web application built using AWS serverless technologies, as demonstrated in the &lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/intro/">Build serverless web application with AWS Serverless&lt;/a> series.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/web-console/">Read More&lt;/a>&lt;/p></description></item><item><title>How to build a clickstream analytic system for small businesses to large-scale events</title><link>https://kane.mx/posts/deep-dive-clickstream-analytics/preface/</link><pubDate>Tue, 03 Sep 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/deep-dive-clickstream-analytics/preface/</guid><description>
&lt;p>In the last couple of months, I led a team to build a comprehensive and open-sourced &lt;a href="https://aws.amazon.com/solutions/implementations/clickstream-analytics-on-aws/">solution&lt;/a> that helps customers analyze clickstream events on the cloud. The solution provides data autonomy, allowing users full access to raw data, near real-time ingestion, flexible configurations, and cost-effectiveness. It is a system that utilizes serverless services to cater to various customers, whether small businesses or large-scale events with massive data volumes, offering fully managed services with minimal operational efforts or the flexibility to use preferred open-source technical stacks.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/deep-dive-clickstream-analytics/preface/">Read More&lt;/a>&lt;/p></description></item><item><title>Analyzing Clickstream Events Using Amazon Athena UDFs</title><link>https://kane.mx/posts/2024/analyzing-clickstream-events-using-amazon-athena-udfs/</link><pubDate>Sat, 17 Aug 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/analyzing-clickstream-events-using-amazon-athena-udfs/</guid><description>
&lt;p>In today's digital age, businesses are constantly seeking ways to understand and analyze user behavior on their websites. Clickstream events provide valuable insights into how users interact with a website, and analyzing this data can help businesses make informed decisions to improve user experience and drive conversions.&lt;/p>
&lt;p>&lt;a href="https://aws.amazon.com/solutions/implementations/clickstream-analytics-on-aws/">Clickstream Analytics on AWS&lt;/a> collects, ingests, analyzes, and visualizes clickstream events from your websites and mobile applications. The solution manages an &lt;a href="https://docs.aws.amazon.com/solutions/latest/clickstream-analytics-on-aws/ingestion-endpoint.html">ingestion endpoint&lt;/a> to receive clickstream events, which are multiple events in a batch sent by the solution‘s SDKs.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/analyzing-clickstream-events-using-amazon-athena-udfs/">Read More&lt;/a>&lt;/p></description></item><item><title>Scan Your Code with Ephemeral SonarQube in GitHub Actions</title><link>https://kane.mx/posts/2024/scan-your-code-with-ephemeral-sonarqube-in-github-actions/</link><pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/scan-your-code-with-ephemeral-sonarqube-in-github-actions/</guid><description>
&lt;p>As developers, we all know the importance of maintaining high code quality standards. One powerful tool that can help us achieve this is &lt;a href="https://www.sonarsource.com/products/sonarqube/">SonarQube&lt;/a>, a renowned platform for continuous code quality inspection. However, setting up and maintaining a dedicated SonarQube instance can be a cumbersome task, requiring significant resources and ongoing maintenance.&lt;/p>
&lt;p>Fortunately, GitHub Actions offers a convenient solution by allowing us to spin up an ephemeral (short-lived) SonarQube instance directly within our workflow. This approach streamlines the process, eliminating the need for a permanent SonarQube server while still reaping the benefits of its code analysis capabilities.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/scan-your-code-with-ephemeral-sonarqube-in-github-actions/">Read More&lt;/a>&lt;/p></description></item><item><title>Avoiding Pitfalls When Using Amazon DynamoDB Interface VPC Endpoints</title><link>https://kane.mx/posts/2024/dynamodb-interface-vpc-endpoint/</link><pubDate>Sat, 04 May 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/dynamodb-interface-vpc-endpoint/</guid><description>
&lt;p>&lt;a href="https://aws.amazon.com/about-aws/whats-new/2024/03/amazon-dynamodb-aws-privatelink/">Amazon DynamoDB now supports AWS PrivateLink&lt;/a> as of March 19, 2024. This feature allows you to securely access DynamoDB from your Amazon Virtual Private Cloud (VPC) without exposing your traffic to the public internet.&lt;/p>
&lt;p>However, unlike &lt;a href="https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html#interface-endpoints">VPC endpoints&lt;/a> for other AWS managed services, the AWS PrivateLink for Amazon DynamoDB does not support the &lt;a href="https://docs.aws.amazon.com/vpc/latest/privatelink/privatelink-share-your-services.html#endpoint-service-private-dns">Private DNS&lt;/a> feature. This means that if your subnets are configured with only a DynamoDB Interface VPC endpoint, the public DNS name of the DynamoDB service (e.g., &lt;code>dynamodb.us-east-1.amazonaws.com&lt;/code> in the &lt;code>us-east-1&lt;/code> region) cannot be resolved in those subnets.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/dynamodb-interface-vpc-endpoint/">Read More&lt;/a>&lt;/p></description></item><item><title>Redshift Serverless: Cost Deep Dive and Use Cases</title><link>https://kane.mx/posts/2024/redshift-serverless-cost-deep-dive/</link><pubDate>Sat, 24 Feb 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/redshift-serverless-cost-deep-dive/</guid><description>
&lt;p>Serverless computing is all the rage, promising pay-as-you-go magic and freedom from infrastructure woes. But what about serverless for data warehouses? Let's delve into the fascinating (and sometimes confusing) world of &lt;strong>&lt;a href="https://aws.amazon.com/redshift/redshift-serverless/">Redshift Serverless&lt;/a>&lt;/strong>: its cost structure, ideal use cases, and situations where it might not be the best fit.&lt;/p>
&lt;h2 id="cost-breakdown-beyond-the-illusion-of-free">Cost Breakdown: Beyond the Illusion of Free&lt;/h2>
&lt;p>Redshift Serverless offers a compelling promise: only pay for what you use. But like any good magic trick, there's more to the story. Here's the primary cost breakdown:&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/redshift-serverless-cost-deep-dive/">Read More&lt;/a>&lt;/p></description></item><item><title>Custom compliance implementation in AWS CDK</title><link>https://kane.mx/posts/2024/custom-compliance-for-aws-cdk/</link><pubDate>Tue, 09 Jan 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/custom-compliance-for-aws-cdk/</guid><description>
&lt;p>&lt;a href="https://aws.amazon.com/cdk/?nc1=h_ls">AWS CDK&lt;/a> accelerates cloud development using common programming languages to model your applications. I had a series of posts using CDK to demonstrate &lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/intro/">Building serverless web applications with AWS Serverless&lt;/a>. Because CDK uses a programming language to model your application, you can encapsulate your library via &lt;a href="https://docs.aws.amazon.com/cdk/v2/guide/constructs.html">Constructs&lt;/a>, and then reuse it crossing the entire application.&lt;/p>
&lt;p>Meanwhile, you can create your own constructs to encapsulate the compliance requirements to simplify the code. For example, in our solution, I used the construct &lt;code>SolutionFunction&lt;/code> to force using the same Node.js version(18.x), architecture(ARM64), Lambda logging configuration(JSON log), environment variables for &lt;a href="https://docs.powertools.aws.dev/lambda/typescript/latest/core/logger/">Powertools Logger&lt;/a> and so on crossing all &lt;code>NodejsFunction&lt;/code>. In addition, using &lt;a href="https://docs.aws.amazon.com/cdk/v2/guide/aspects.html">Aspects&lt;/a> and &lt;a href="https://docs.aws.amazon.com/cdk/v2/guide/cfn_layer.html">escape hatches&lt;/a> to make sure the application meets the compliance requirements.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/custom-compliance-for-aws-cdk/">Read More&lt;/a>&lt;/p></description></item><item><title>Awesome AWS CLI</title><link>https://kane.mx/posts/2024/awscli-collection/</link><pubDate>Sun, 07 Jan 2024 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2024/awscli-collection/</guid><description>
&lt;blockquote>
&lt;p>&lt;strong>Disclaimer&lt;/strong>: the cover image was generated by Amazon Bedrock's Titan Image Generator G1.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a href="https://aws.amazon.com/cli/">AWS CLI&lt;/a> is a swiss knife for orchestrating the operations of AWS resources. Especially, the filter option could help your filter and transform the output then combine with other Linux commands together.&lt;/p>
&lt;p>This post collects the CLI usages to resolve my AWS operation needs.&lt;/p>
&lt;h3 id="delete-the-legacy-versions-of-a-service-catalog-product">Delete the legacy versions of a service catalog product&lt;/h3>
&lt;p>AWS Service Catalog has &lt;a href="https://docs.aws.amazon.com/servicecatalog/latest/adminguide/limits.html">default 100 versions per product&lt;/a>. Below is a one line command to delete the legacy versions.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2024/awscli-collection/">Read More&lt;/a>&lt;/p></description></item><item><title>Build serverless web application with AWS Lambda web adapter</title><link>https://kane.mx/posts/2023/build-serverless-web-application-with-aws-lambda-web-adapter/</link><pubDate>Thu, 26 Oct 2023 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2023/build-serverless-web-application-with-aws-lambda-web-adapter/</guid><description>
&lt;blockquote>
&lt;p>&lt;strong>Disclaimer&lt;/strong>: the cover image was generated by StableDiffusionXL with prompts 'cover image, spring boot, flask framework running in aws lambda'.&lt;/p>
&lt;/blockquote>
&lt;p>When deploying and operating a web application on the cloud, you prefer to use your favorite programming language and web framework. Also, you want to benefit from Serverless technologies for stability, scalability, cost optimization, and operation excellence.&lt;/p>
&lt;p>&lt;a href="https://github.com/awslabs/aws-lambda-web-adapter">AWS Lambda Web Adapter&lt;/a> is a tool that perfectly meets your expectations. It lifts and shifts the web application based on your preferred language and web framework, including FastAPI, Flask, Django, Express.js, Next.js, Spring Boot, Nginx, PHP, Rust, Golang Gin, Laravel, ASP.NET, and so on! You don't have to change any code to migrate your application to Lambda runtime. It also supports WebSocket and streaming features that work well with your LLM applications.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2023/build-serverless-web-application-with-aws-lambda-web-adapter/">Read More&lt;/a>&lt;/p></description></item><item><title>Verbose logging for AWS JS SDK v3</title><link>https://kane.mx/posts/2023/aws-js-sdk-v3-verbose-logging/</link><pubDate>Sun, 10 Sep 2023 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2023/aws-js-sdk-v3-verbose-logging/</guid><description>
&lt;p>When programming with the AWS SDK, developers sometimes want to debug a specific HTTP request when invoking an SDK API. Due to the &lt;a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/Package/-aws-sdk-types/Interface/LoggerOptions/">poor documentation&lt;/a> of AWS JS SDK v3, it takes a lot of work to find a way to print the verbose logging of AWS SDK by asking it to the LLMs.&lt;/p>
&lt;p>Below is a practical tip for enabling verbose logging for AWS JS SDK v3.&lt;/p>
&lt;h3 id="solution-1---specify-a-custom-logger-for-aws-sdk-clients">Solution 1 - specify a custom logger for AWS SDK clients&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-typescript" data-lang="typescript">&lt;span class="line">&lt;span class="ln"> 1&lt;/span>&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">DescribeParametersCommand&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">SSMClient&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="kr">from&lt;/span> &lt;span class="s2">&amp;#34;@aws-sdk/client-ssm&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 2&lt;/span>&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="o">*&lt;/span> &lt;span class="kr">as&lt;/span> &lt;span class="nx">log4js&lt;/span> &lt;span class="kr">from&lt;/span> &lt;span class="s2">&amp;#34;log4js&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 3&lt;/span>&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 4&lt;/span>&lt;span class="cl">&lt;span class="nx">log4js&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">configure&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 5&lt;/span>&lt;span class="cl"> &lt;span class="nx">appenders&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">out&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="kr">type&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;stdout&amp;#34;&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 6&lt;/span>&lt;span class="cl"> &lt;span class="nx">categories&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="k">default&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">appenders&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="p">[&lt;/span>&lt;span class="s2">&amp;#34;out&amp;#34;&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="nx">level&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s2">&amp;#34;debug&amp;#34;&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="p">},&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 7&lt;/span>&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 8&lt;/span>&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 9&lt;/span>&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">logger&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nx">log4js&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">getLogger&lt;/span>&lt;span class="p">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">10&lt;/span>&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">11&lt;/span>&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">ssmClient&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">SSMClient&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">12&lt;/span>&lt;span class="cl"> &lt;span class="nx">logger&lt;/span>: &lt;span class="kt">logger&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">13&lt;/span>&lt;span class="cl">&lt;span class="p">});&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;h3 id="solution-2---use-middleware-to-hook-the-life-cyele-of-request">Solution 2 - use middleware to hook the life cyele of request&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-typescript" data-lang="typescript">&lt;span class="line">&lt;span class="ln"> 1&lt;/span>&lt;span class="cl">&lt;span class="kr">import&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">DescribeParametersCommand&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">SSMClient&lt;/span> &lt;span class="p">}&lt;/span> &lt;span class="kr">from&lt;/span> &lt;span class="s2">&amp;#34;@aws-sdk/client-ssm&amp;#34;&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 2&lt;/span>&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 3&lt;/span>&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">logRequestMiddleware&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">next&lt;/span>: &lt;span class="kt">any&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">_context&lt;/span>: &lt;span class="kt">any&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span> &lt;span class="kr">async&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="nx">args&lt;/span>: &lt;span class="kt">any&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">=&amp;gt;&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 4&lt;/span>&lt;span class="cl"> &lt;span class="nx">console&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">log&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Request:&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="nx">args&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">request&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 5&lt;/span>&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="nx">next&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">args&lt;/span>&lt;span class="p">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 6&lt;/span>&lt;span class="cl">&lt;span class="p">};&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 7&lt;/span>&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 8&lt;/span>&lt;span class="cl">&lt;span class="kr">const&lt;/span> &lt;span class="nx">ssmClient&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="k">new&lt;/span> &lt;span class="nx">SSMClient&lt;/span>&lt;span class="p">({&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln"> 9&lt;/span>&lt;span class="cl">&lt;span class="p">});&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">10&lt;/span>&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="ln">11&lt;/span>&lt;span class="cl">&lt;span class="nx">ssmClient&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">middlewareStack&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nx">logRequestMiddleware&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="p">{&lt;/span> &lt;span class="nx">step&lt;/span>&lt;span class="o">:&lt;/span> &lt;span class="s1">&amp;#39;finalizeRequest&amp;#39;&lt;/span> &lt;span class="p">});&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>See complete working example gist below,&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2023/aws-js-sdk-v3-verbose-logging/">Read More&lt;/a>&lt;/p></description></item><item><title>Define your API via OpenAPI definition on AWS</title><link>https://kane.mx/posts/2022/import-oas-as-api-on-aws/</link><pubDate>Thu, 27 Oct 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/import-oas-as-api-on-aws/</guid><description>
&lt;p>Application Programming Interfaces(APIs) is a critical part of the web service, Werner Vogel, the CTO of AWS had a great
&lt;a href="https://thenewstack.io/werner-vogels-6-rules-for-good-api-design/">6 Rules for Good API Design&lt;/a> presentation in 2021 re:Invent keynote.&lt;/p>
&lt;p>In AWS the developers could manage and proxy the APIs via &lt;a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway&lt;/a>. The developers can use
console, CLI, API or IaC code(for example, Terraform/CloudFormation/CDK) to provisioning the API resources on AWS.
However some developers might flavor with using &lt;a href="https://oai.github.io/Documentation/">OpenAPI specification&lt;/a> to define the APIs. It enables multiple services/tools
to understand the APIs' specification, such as Postman. Amazon API Gateway supports this use case, you can import the
existing OpenAPI definition as API.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/import-oas-as-api-on-aws/">Read More&lt;/a>&lt;/p></description></item><item><title>Setup DevOps pipeline with few code</title><link>https://kane.mx/posts/2022/build-serverless-app-on-aws/devops-pipeline/</link><pubDate>Wed, 14 Sep 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/build-serverless-app-on-aws/devops-pipeline/</guid><description>
&lt;p>DevOps pipeline is a key component of project operation,
it helps you automate steps in your software delivery process.&lt;/p>
&lt;p>Amazon itself has rich expirence on DevOps with large scale services,
it &lt;a href="https://aws.amazon.com/builders-library/?nc1=h_ls&amp;cards-body.sort-by=item.additionalFields.sortDate&amp;cards-body.sort-order=desc&amp;awsf.filter-content-category=content-category%23software-delivery-operations&amp;awsf.filter-content-type=*all&amp;awsf.filter-content-level=*all">shares the lesson and learn&lt;/a> from operating the Amazon's services.
You can read &lt;a href="https://kane.mx/posts/2020/the-best-practise-of-deployment-at-amazon/">this summary post&lt;/a> written in Chinese.&lt;/p>
&lt;p>Also AWS provides fully managed SaaS services for the lifecycle of software development, including
&lt;a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline&lt;/a> for automating continuous delivery pipelines,
&lt;a href="https://aws.amazon.com/codecommit/">AWS CodeCommit&lt;/a> for securely hosting highly scalable private Git repositories,
&lt;a href="https://aws.amazon.com/codeartifact/">AWS CodeArtifact&lt;/a> for artifact management,
&lt;a href="https://aws.amazon.com/codebuild/">AWS CodeBuild&lt;/a> for building and testing code with continuous scaling and
&lt;a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy&lt;/a> for automating code deployments to maintain application uptime.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/devops-pipeline/">Read More&lt;/a>&lt;/p></description></item><item><title>Federated OIDC login with Cognito and Amplify</title><link>https://kane.mx/posts/2022/build-serverless-app-on-aws/federated-oidc-login-with-cognito-and-amplify/</link><pubDate>Mon, 12 Sep 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/build-serverless-app-on-aws/federated-oidc-login-with-cognito-and-amplify/</guid><description>
&lt;p>When working on either 2C application or 2B service, the customers do not want to
or is not allowed to sign up the new account, they can login the application via existing
IdP or enterprise SSO. So, building the application supports the federated OIDC login
to address such requirements.&lt;/p>
&lt;p>This post extends the capability of &lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/protect-website-with-cognito/">Todolist application protected by Amazon Cognito&lt;/a>,
using &lt;a href="https://auth0.com/">Auth0&lt;/a> as the third party &lt;a href="https://en.wikipedia.org/wiki/OpenID">OpenID Connect&lt;/a> provider introduces the external user pool.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/federated-oidc-login-with-cognito-and-amplify/">Read More&lt;/a>&lt;/p></description></item><item><title>Protect website with Cognito</title><link>https://kane.mx/posts/2022/build-serverless-app-on-aws/protect-website-with-cognito/</link><pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/build-serverless-app-on-aws/protect-website-with-cognito/</guid><description>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/static-website/">Previous post&lt;/a> we demonstrated how distributing and securely deploying the website to global end users.
The authentication and authorization are always mandatory features of web application.
&lt;a href="https://aws.amazon.com/cognito/">Amazon Cognito&lt;/a> is a managed AWS serverless service helping the applications to implement AuthN and AuthZ,
with Cognito the applications securely scales to millions of users(up to 50,000 free users)
supporting identity and access management standards, such as OAuth 2.0, SAML 2.0, and OpenID Connect.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/protect-website-with-cognito/">Read More&lt;/a>&lt;/p></description></item><item><title>Distribute the website globally</title><link>https://kane.mx/posts/2022/build-serverless-app-on-aws/static-website/</link><pubDate>Fri, 02 Sep 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/build-serverless-app-on-aws/static-website/</guid><description>
&lt;p>It's a well known pattern to distribute the website via CDN globally,
it reduces the latency of the site and improve the availibity and security leveraging the infrastructure of cloud provider.&lt;/p>
&lt;p>Using CDN service &lt;a href="https://aws.amazon.com/cloudfront/">CloudFront&lt;/a> and simple storage &lt;a href="https://aws.amazon.com/s3/">S3&lt;/a> on AWS hosts the static website.
It well fits the SPA(single page application) framework technologies, for example, React, Vue and Angularjs.
There are lots of existing project and code snippets to sharing this pattern,
such as &lt;a href="https://serverlessland.com/patterns/cloudfront-s3-lambda-cdk">CloudFront to S3 and API Gateway&lt;/a> and &lt;a href="https://github.com/cdk-patterns/serverless/blob/main/s3-react-website/README.md">AWS S3 / React Website Pattern&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/static-website/">Read More&lt;/a>&lt;/p></description></item><item><title>Build no code restful HTTP API with API Gateway and DynamoDB</title><link>https://kane.mx/posts/2022/build-serverless-app-on-aws/restful-api/</link><pubDate>Sat, 27 Aug 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/build-serverless-app-on-aws/restful-api/</guid><description>
&lt;p>Most web applications are using &lt;a href="https://en.wikipedia.org/wiki/Representational_state_transfer">Restful APIs&lt;/a> to interactive with the backend services.
In the TODO application, it's the straight forward to get, update and delete the items from backend database.
&lt;a href="https://aws.amazon.com/dynamodb/">Amazon DynamoDB&lt;/a> is a key-value database, it fits for this scenario with scalability and optimized pay-as-you-go cost.
Also &lt;a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway&lt;/a> has built-in integration with AWS serivces, the restful API can be transformed to
the request to DynamoDB APIs. Using this combination you can provide the restful APIs only provisioning AWS resources
without writing the CRUD code!&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/restful-api/">Read More&lt;/a>&lt;/p></description></item><item><title>Build serverless web application with AWS Serverless</title><link>https://kane.mx/posts/2022/build-serverless-app-on-aws/intro/</link><pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/build-serverless-app-on-aws/intro/</guid><description>
&lt;p>Building web application is a common use case, leveraging cloud services could accelerate
the builders to develop and deploy the services. With AWS serverless services,
the application can easily get the capabilities like security, highly availability,
scalability, resiliency and cost optimized.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/build-serverless-app-on-aws/intro/">Read More&lt;/a>&lt;/p></description></item><item><title>FluxCD GitOps debugging tip</title><link>https://kane.mx/posts/gitops/fluxcd-local-debug-tip/</link><pubDate>Thu, 16 Jun 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/gitops/fluxcd-local-debug-tip/</guid><description>
&lt;p>After enabling E2E testing of FluxCD powered GitOps continuous deployment, the feedback of new commits are quite slow.
Because you have to wait for the E2E testing result, lots of time cost on setuping the environment and provisioning
your development from scrath.&lt;/p>
&lt;p>Inspired by &lt;a href="https://github.com/zxkane/eks-gitops/actions/workflows/e2e.yaml">E2E testing in Github actions&lt;/a>, the DevOps engineers can build local debugging environment in
&lt;a href="https://kind.sigs.k8s.io/">Kind&lt;/a> or &lt;a href="https://minikube.sigs.k8s.io/docs/start/">minikube&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/gitops/fluxcd-local-debug-tip/">Read More&lt;/a>&lt;/p></description></item><item><title>使用外部Secrets Manager管理Kubernetes密钥</title><link>https://kane.mx/posts/gitops/manage-k8s-secrets-in-external-secrets-manager/</link><pubDate>Sun, 12 Jun 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/gitops/manage-k8s-secrets-in-external-secrets-manager/</guid><description>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>密钥的管理对于使用 GitOps 方式做持续发布是一个挑战，特别是当目标部署平台是 Kubernetes 的时候。
K8S 使用声明式配置管理最终状态，而&lt;a href="https://kubernetes.io/docs/concepts/configuration/secret/">K8S中的密钥&lt;/a>仅仅是将密钥内容做了&lt;a href="https://en.wikipedia.org/wiki/Base64">base64&lt;/a>格式的编码。
在&lt;a href="https://kane.mx/posts/gitops/flux-in-action-1/">基于 Flux 的 GitOps 实战&lt;/a>介绍了使用&lt;a href="https://kane.mx/posts/gitops/flux-in-action-1/#3-密钥的管理">Bitnami Sealed Secrets&lt;/a>加密密钥内容，
可以安全的将加密后的Kubernetes Manifest文件提交到Git代码仓库，由Sealed Secrets发现这些SealedSecret的密码，
并解密后动态的创建K8S原生Secrets对象。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/gitops/manage-k8s-secrets-in-external-secrets-manager/">Read More&lt;/a>&lt;/p></description></item><item><title>基于 Flux 的 GitOps 管理 Crossplane 部署及资源</title><link>https://kane.mx/posts/gitops/crossplane-meets-gitops/</link><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/gitops/crossplane-meets-gitops/</guid><description>
&lt;h2 id="背景">背景&lt;/h2>
&lt;p>在&lt;a href="https://kane.mx/posts/gitops/flux-in-action-2/#六小结及展望">Flux 部署实战的总结展望&lt;/a>中有一个方向是如何将云上基础设施资源同Kubernetes内资源统一管理，
而&lt;a href="https://crossplane.io/">Crossplane&lt;/a>提供了一个高度可扩展的后端，使用声明式程序同时编排应用程序和基础设施，不用关心它们在哪里运行。&lt;/p>
&lt;p>近期 AWS 官方博客宣布了 &lt;a href="https://aws.amazon.com/blogs/opensource/introducing-aws-blueprints-for-crossplane/">AWS Blueprints for Crossplane&lt;/a>，为客户提供了在 &lt;a href="https://aws.amazon.com/eks/">Amazon EKS&lt;/a>
上应用 Crossplane 的参考实现。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/gitops/crossplane-meets-gitops/">Read More&lt;/a>&lt;/p></description></item><item><title>Publish your AWS CDK applications via AWS CloudFormation templates</title><link>https://kane.mx/posts/2022/publish-cdk-app-via-cloudformation/</link><pubDate>Sun, 15 May 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/publish-cdk-app-via-cloudformation/</guid><description>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a> is a great abstract to accelerate managing the cloud infrastructure as code.
The journey will be enjoyful with leveraging the &lt;a href="https://constructs.dev/">Construct Hub&lt;/a> to use the high level contributions from AWS partners and commnunity.&lt;/p>
&lt;h3 id="use-case">Use Case&lt;/h3>
&lt;p>&lt;a href="https://aws.amazon.com/cloudformation/?nc1=h_ls">AWS CloudFormation&lt;/a> is one of the underly technologies of AWS CDK to manage the cloud infrastructure.
It easily to enable the IT administrators even business operators whom has no/limited developer skills to
develop the &lt;a href="https://aws.amazon.com/solutions/browse-all/">end-to-end solutions&lt;/a> with one-click user experience.&lt;/p>
&lt;p>So it's a use case for effectively developing the &lt;strong>Cloud Application&lt;/strong> via AWS CDK,
then publishing it as CloudFormation template with better user experimental experience.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/publish-cdk-app-via-cloudformation/">Read More&lt;/a>&lt;/p></description></item><item><title>基于 Flux 的 GitOps 实战（下）</title><link>https://kane.mx/posts/gitops/flux-in-action-2/</link><pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/gitops/flux-in-action-2/</guid><description>
&lt;p>在&lt;a href="https://kane.mx/posts/gitops/flux-in-action-1/">上篇&lt;/a>介绍基于 CNCF 下的 GitOps 工具 FluxCD v2
实现了管理多账户的 Kubernetes 集群的共享组件，Secrets 使用的最佳实践，
GitOps 流水线事件同 IM(Slack) 的集成，以及对 GitOps 代码的 CI 流程。&lt;/p>
&lt;p>本文将围绕如何使用 Flux 的多租户管理最佳实践，打造基于 GitOps 工作流程的共享服务平台，
实现租户(业务/应用团队)可自助的持续部署。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/gitops/flux-in-action-2/">Read More&lt;/a>&lt;/p></description></item><item><title>基于 Flux 的 GitOps 实战（上）</title><link>https://kane.mx/posts/gitops/flux-in-action-1/</link><pubDate>Fri, 22 Apr 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/gitops/flux-in-action-1/</guid><description>
&lt;p>在&lt;a href="https://kane.mx/posts/gitops/the-best-practise-of-gitops-in-kubernetes/">前文&lt;/a>介绍了 GitOps 的概念，Kubernetes 上 GitOps 最佳实践以及对比了 CNCF 基金会下
云原生的 GitOps 工具（ArgoCD 和 Flux）。本篇将带你按照 Flux 的最佳实践在跨VPC跨账户的 Kubernetes
上实践 GitOps 的持续集成，轻松管理数十数百乃至更多的集群及部署在上面的应用。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/gitops/flux-in-action-1/">Read More&lt;/a>&lt;/p></description></item><item><title>Kuberentes 上 GitOps 最佳实践</title><link>https://kane.mx/posts/gitops/the-best-practise-of-gitops-in-kubernetes/</link><pubDate>Wed, 30 Mar 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/gitops/the-best-practise-of-gitops-in-kubernetes/</guid><description>
&lt;p>今天 Kuberentes 已经成为IT基础设施的重要玩家，容器编排领域的事实标准。写于3年前的文章&lt;a href="https://kane.mx/posts/effective-cloud-computing/using-kubernetes-on-cloud/">不要自建 Kuberentes&lt;/a> 的观点已经被绝大多数的企业所认可和接受。&lt;/p>
&lt;p>然而同众多企业接触中发现，企业有很高的意愿采用 Kuberentes 管理工作负载，并且已有大量的企业已经将 Kuberentes 用于生产环境。
但如何对多套不同阶段的 Kuberentes 集群来做持续部署，做到高安全性、权限分离、可审计、保证业务团队的敏捷等需求感到困惑。
目前客户实现方式非常多样，并没有很好的遵循业界的最佳实践。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/gitops/the-best-practise-of-gitops-in-kubernetes/">Read More&lt;/a>&lt;/p></description></item><item><title>Find out the most costly resources in your AWS account</title><link>https://kane.mx/posts/2022/find-out-most-costly-resource-in-your-aws-account/</link><pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/find-out-most-costly-resource-in-your-aws-account/</guid><description>
&lt;p>As a builder in cloud, you might feel confused about which resources cost mostly in your account.&lt;/p>
&lt;p>In AWS, you can quickly find out which services even functionality cost a lot via &lt;a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-what-is.html">AWS Billing&lt;/a> or
&lt;a href="https://aws.amazon.com/aws-cost-management/aws-cost-explorer/">AWS Cost Explorer&lt;/a>. However sometimes it sucks on finding out which functions cost mostly if
you have hundreds of Lambda functions, or which metrics/log groups cost mostly in &lt;a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/find-out-most-costly-resource-in-your-aws-account/">Read More&lt;/a>&lt;/p></description></item><item><title>Grant federated users accessing kubernetes resources in EKS console</title><link>https://kane.mx/posts/2022/grant-federated-users-accessing-k8s-resources-in-eks-console/</link><pubDate>Wed, 09 Feb 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/grant-federated-users-accessing-k8s-resources-in-eks-console/</guid><description>
&lt;p>Though you're administrator of your AWS account, you probably see below warnings when viewing your cluster in EKS console.&lt;/p>
&lt;blockquote>
&lt;p>Your current user or role does not have access to Kubernetes objects on this EKS cluster.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a href="https://kane.mx/posts/2022/grant-federated-users-accessing-k8s-resources-in-eks-console/">Read More&lt;/a>&lt;/p></description></item><item><title>Publishing npm packages to multiple registries with Projen</title><link>https://kane.mx/posts/2022/publishing-npm-packages-to-multiple-registries-with-projen/</link><pubDate>Fri, 04 Feb 2022 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2022/publishing-npm-packages-to-multiple-registries-with-projen/</guid><description>
&lt;p>&lt;a href="https://constructs.dev/">Construct Hub&lt;/a> is a web portal to collect the &lt;a href="https://docs.aws.amazon.com/cdk/latest/guide/constructs.html">constructs&lt;/a> for &lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a>, CDK8s and CDKtf.
The construct could support multiple programming languages, such as Javascript/TypeScript, Python, Java and C#.
Actually the construct is developed by TypeScript, then it's compiled as across languages library by &lt;a href="https://aws.github.io/jsii/">jsii&lt;/a>!
Any npm/pypi package with certain tags will be discovered by Construct Hub, the package will be automatically recognized as
construct package and listed in Construct Hub.&lt;/p>
&lt;p>&lt;a href="https://github.com/projen/projen">Projen&lt;/a> is a project generator to create project with simplifying the project configuration to support dependencies management,
building, unit testing, code style linting, CI/CD via Github actions PR and actions. So &lt;a href="https://projen.io/awscdk-construct.html">projen&lt;/a>
supports the construct project out of box, which configures construct project with jsii configuration
that build the construct to across languages library, though publish the packages
to kinds of package registries, such as npmjs, pypi and maven central.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2022/publishing-npm-packages-to-multiple-registries-with-projen/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS上构建共享自服务平台服务去中心化研发团队</title><link>https://kane.mx/posts/2021/shared-service-platform-for-decentralized-developer-teams/</link><pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/shared-service-platform-for-decentralized-developer-teams/</guid><description>
&lt;p>近期在一个 Webinar 分享了如何在 AWS 上服务去中心化研发团队构建共享服务平台，核心观点总结如下，&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/shared-service-platform-for-decentralized-developer-teams/">Read More&lt;/a>&lt;/p></description></item><item><title>应用程序弹性设计</title><link>https://kane.mx/posts/2021/application-resilience/</link><pubDate>Sun, 28 Nov 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/application-resilience/</guid><description>
&lt;p>&lt;a href="https://aws.amazon.com/architecture/well-architected/?wa-lens-whitepapers.sort-by=item.additionalFields.sortDate&amp;wa-lens-whitepapers.sort-order=desc">AWS架构的完善&lt;/a>(AWS Well-Architected)框架涉及了五大支柱，
其中可靠性支柱要求侧重于确保工作负载在预期的时间内正确、一致地执行其预期功能。
这要求应用程序系统具备弹性设计，可从故障中快速恢复，以便满足业务和客户需求。
然而设计、开发、且验证具备弹性设计的应用程序，对经验和实践能力都有很高的要求。
利用成熟的经验和良好的工具将加快构建符合预期的弹性应用程序。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/application-resilience/">Read More&lt;/a>&lt;/p></description></item><item><title>元宇宙风口下的机会</title><link>https://kane.mx/posts/2021/metaverse/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/metaverse/</guid><description>
&lt;p>元宇宙是近期的热点话题，近期做了些学习了解，将一些学习内容总结为一个deck。分享如下，&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/metaverse/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS上的混沌工程</title><link>https://kane.mx/posts/2021/chaos-engineering-on-aws/</link><pubDate>Sun, 21 Nov 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/chaos-engineering-on-aws/</guid><description>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Chaos_engineering">混沌工程&lt;/a>是一种帮助系统满足弹性需求的技术，它起源于&lt;a href="https://www.gremlin.com/chaos-monkey/">Netflix的工程实践&lt;/a>，著名的猴子军团。&lt;/p>
&lt;p>AWS一直提倡&lt;a href="https://aws.amazon.com/architecture/well-architected/?wa-lens-whitepapers.sort-by=item.additionalFields.sortDate&amp;wa-lens-whitepapers.sort-order=desc">架构的完善&lt;/a>(AWS Well-Architected)，混沌工程正是卓越运营和可靠性支柱的实践。
因此在 &lt;a href="https://www.youtube.com/watch?v=yoNeMLj3CHc">re:Invent 2020 AWS发布了Fault Injection Simulator&lt;/a>服务来简化开发者在AWS上的混动工程实践。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/chaos-engineering-on-aws/">Read More&lt;/a>&lt;/p></description></item><item><title>Turn off Filevault on macOS</title><link>https://kane.mx/posts/2021/turn-off-filevault-on-macosx/</link><pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/turn-off-filevault-on-macosx/</guid><description>
&lt;p>I'm trying to upgrade my Macbook Pro to macOS Monterey, however the installation can not be started due to the disk is encrypted by Filevault &amp;#x1f615; I have to turn off Filevault to disable disk encrpytion before installing macOS Monterey.&lt;/p>
&lt;p>I found this &lt;a href="https://support.apple.com/guide/mac-help/turn-off-filevault-encryption-on-mac-mchlp2560/11.0/mac/11.0">support article on how turning off Filevault&lt;/a>, but it does not work at all. There is nothing hint or error message after clicking the option &lt;code>Turn off Filevault&lt;/code>.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/turn-off-filevault-on-macosx/">Read More&lt;/a>&lt;/p></description></item><item><title>Mirror Helm Charts to AWS ECR</title><link>https://kane.mx/posts/2021/mirror-helm-chart-to-aws-ecr/</link><pubDate>Mon, 27 Sep 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/mirror-helm-chart-to-aws-ecr/</guid><description>
&lt;p>I met a case to mirror existing &lt;a href="https://helm.sh/">Helm&lt;/a> charts to another repository. It might be caused by network availability or compliance requirements.&lt;/p>
&lt;p>There are multiple ways to host a Helm repository, for example, &lt;a href="https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/">Nexus OSS Repository&lt;/a>, &lt;a href="https://harness.io/blog/helm-chart-repo/">Github Pages&lt;/a>, &lt;a href="https://aws.amazon.com/blogs/containers/oci-artifact-support-in-amazon-ecr/">AWS ECR&lt;/a> and so on.&lt;/p>
&lt;p>Amazon Elastic Container Registry (&lt;a href="https://aws.amazon.com/ecr/">Amazon ECR&lt;/a>) is a fully managed container registry that makes it easy to store, manage, share, and deploy your container images and artifacts anywhere. It's built with scale and secure. In my case I'm using this existing service to mirror the Helm charts.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/mirror-helm-chart-to-aws-ecr/">Read More&lt;/a>&lt;/p></description></item><item><title>The practise of Amazon Neptune</title><link>https://kane.mx/posts/2021/the-practise-of-amazon-neptune/</link><pubDate>Fri, 03 Sep 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/the-practise-of-amazon-neptune/</guid><description>
&lt;p>&lt;a href="https://aws.amazon.com/neptune/">Amazon Neptune&lt;/a> is a managed Graph database on AWS, whose compute and storage is decoupled like &lt;a href="https://aws.amazon.com/blogs/database/introducing-the-aurora-storage-engine/">Amazon Aurora&lt;/a>. Neptune leverages popular open-source APIs such as Gremlin and SPARQL, and easily migrate existing applications.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/the-practise-of-amazon-neptune/">Read More&lt;/a>&lt;/p></description></item><item><title>The update of Sonatype Nexus repository OSS on AWS solution</title><link>https://kane.mx/posts/2021/nexus-oss-on-aws-v110-update/</link><pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/nexus-oss-on-aws-v110-update/</guid><description>
&lt;p>Last year I shared the production-ready, cloud native solution to &lt;a href="https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/">deploy Sonatype Nexus Repository OSS on AWS&lt;/a>.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/nexus-oss-on-aws-v110-update/">Read More&lt;/a>&lt;/p></description></item><item><title>在AWS上快速部署专用的NAT实例</title><link>https://kane.mx/posts/2021/simple-nat-on-aws/</link><pubDate>Fri, 16 Apr 2021 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2021/simple-nat-on-aws/</guid><description>
&lt;p>本方案的起因是，一个源代码托管在Github上的项目fix一个重要的bug后，在AWS上的持续部署流水线一直失败。分析日志后，发现流水线中的数个步骤需要克隆源代码，但是访问Github的网络非常不稳定，这数个流水线任务持续因连接超时，连接拒绝等网络错误而失败。而流水线任务大量使用了CodeBuild, Lambda等AWS托管服务，无法为执行环境配置可靠的网络连接。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2021/simple-nat-on-aws/">Read More&lt;/a>&lt;/p></description></item><item><title>Effective AWS CDK for AWS CloudFormation</title><link>https://kane.mx/posts/2020/effective-aws-cdk-for-aws-cloudformation/</link><pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/effective-aws-cdk-for-aws-cloudformation/</guid><description>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">Infrastructure as Code&lt;/a> is the trend to manage the resources of application. &lt;a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation&lt;/a> is the managed service offering the IaC capability on AWS &lt;a href="https://aws.amazon.com/blogs/aws/cloudformation-create-your-aws-stack-from-a-recipe/">since 2011&lt;/a>. CloudFormation uses the &lt;a href="https://en.wikipedia.org/wiki/Declarative_programming">declarative language&lt;/a> to manage your AWS resources with the style what you get is what you declare.&lt;/p>
&lt;p>However there are cons of CloudFormation as a declarative language,&lt;/p>
&lt;ul>
&lt;li>the readability and maintenance for applications involving lots of resources&lt;/li>
&lt;li>the reuseable of code, &lt;a href="https://aws.amazon.com/blogs/mt/introducing-aws-cloudformation-modules/">CloudFormation modules&lt;/a> released in re:Invent 2020 might help mitigate it&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a> provides the programming way to define the infra in code by your preferred programming languages, such as Typescript, Javascript, Python, Java and C#. AWS CDK will synthesis the code to CloudFormation template, then deploying the stack via AWS CloudFormation service. It benefits the Devops engineers manage the infra on AWS as programming application, having version control, code review, unit testing, integration testing and CI/CD pipelines, the deployment still depends on the mature CloudFormation service to rolling update the resources and rollback when failing.&lt;/p>
&lt;p>For solution development, using CDK indeed improves the productivity then publish the deployment assets as CloudFormation templates.&lt;/p>
&lt;p>Though CDK application can be synthesized to CloudFormation template, there are still some differences blocking the synthesized templates to be deployed across multiple AWS regions.&lt;/p>
&lt;p>This post will share the tips on how effectively writing AWS CDK application then deploying the application by CloudFormation across multiple regions.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/effective-aws-cdk-for-aws-cloudformation/">Read More&lt;/a>&lt;/p></description></item><item><title>亚马逊的部署最佳实践</title><link>https://kane.mx/posts/2020/the-best-practise-of-deployment-at-amazon/</link><pubDate>Sat, 28 Nov 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/the-best-practise-of-deployment-at-amazon/</guid><description>
&lt;p>近期&lt;a href="https://aws.amazon.com/builders-library/">Amazon Builders Library&lt;/a>发布了数篇文章介绍亚马逊如何实践持续部署，同时分享了亚马逊在部署方面的最佳实践。&lt;/p>
&lt;p>这里将这三篇文章核心内容做个概述，方便大家按需细读。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/the-best-practise-of-deployment-at-amazon/">Read More&lt;/a>&lt;/p></description></item><item><title>跨账号跨区域部署AWS CDK编排的应用</title><link>https://kane.mx/posts/2020/deploy-aws-cdk-applications-cross-accounts/</link><pubDate>Wed, 14 Oct 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/deploy-aws-cdk-applications-cross-accounts/</guid><description>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cdk/">AWS CDK&lt;/a>是编排部署AWS云上资源最佳的工具之一。基于AWS CDK的应用应该如何实践DevOps持续集成和部署呢？&lt;/p>
&lt;p>通常我们有下面几种方法，&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/deploy-aws-cdk-applications-cross-accounts/">Read More&lt;/a>&lt;/p></description></item><item><title>Deploy Sonatype Nexus repository OSS on EKS</title><link>https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/</link><pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/</guid><description>
&lt;p>&lt;a href="https://www.sonatype.com/nexus-repository-oss">Sonatype Nexus repository OSS&lt;/a> is an artifact repository that supports most software repositories such as Maven, Pypi, Npmjs, Rubygems, Yum, Apt, Docker registry and etc. In the enterprise Nexus repository is widely used for storing proprietary artifacts and caching the artifacts for speeding up the devops.&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/deploy-sonatype-nexus-oss-on-eks/">Read More&lt;/a>&lt;/p></description></item><item><title>无服务器架构的Docker镜像数据分析应用</title><link>https://kane.mx/posts/2020/serverless-docker-images-analytics/</link><pubDate>Mon, 04 May 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/serverless-docker-images-analytics/</guid><description>
&lt;p>近期对Docker镜像做了些数据分析，这里分享一下利用云原生技术快速且低成本的实现任意数量的数据分析。&lt;/p>
&lt;p>之前通过文章介绍了&lt;a href="https://kane.mx/posts/2020/get-docker-image-size-without-pulling-image/">不用拉取Docker镜像就可获取镜像的大小&lt;/a>的一种方法，通过其中的示例脚本，我们可以获取到待分析的原始数据。&lt;/p>
&lt;p>比如&lt;code>nginx&lt;/code>镜像的部分原始数据(csv格式)如下，&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-txt" data-lang="txt">&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:676b8117782d9e8c20af8e1b19356f64acc76c981f3a65c66e33a9874877892a,amd64,linux,null,null,&amp;#34;sha256:cbdbe7a5bc2a134ca8ec91be58565ec07d037386d1f1d8385412d224deafca08&amp;#34;,2813316
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:676b8117782d9e8c20af8e1b19356f64acc76c981f3a65c66e33a9874877892a,amd64,linux,null,null,&amp;#34;sha256:6ade829cd166df9b2331da48e3e60342aef9f95e1e45cde8d20e6b01be7e6d9a&amp;#34;,6477096
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:70feed62d5204358ed500463c0953dce6c269a0ebeef147a107422a2c78799a9,arm,linux,v6,null,&amp;#34;sha256:b9e3228833e92f0688e0f87234e75965e62e47cfbb9ca8cc5fa19c2e7cd13f80&amp;#34;,2619936
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:70feed62d5204358ed500463c0953dce6c269a0ebeef147a107422a2c78799a9,arm,linux,v6,null,&amp;#34;sha256:a03f81873d278ad248976b107883f0452d33c6f907ebcdd832a6041f1d33118a&amp;#34;,6080562
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:2ba714ccbdc4c2a7b5a5673ebbc8f28e159cf2687a664d540dcb91d325934f32,arm64,linux,v8,null,&amp;#34;sha256:29e5d40040c18c692ed73df24511071725b74956ca1a61fe6056a651d86a13bd&amp;#34;,2724424
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:2ba714ccbdc4c2a7b5a5673ebbc8f28e159cf2687a664d540dcb91d325934f32,arm64,linux,v8,null,&amp;#34;sha256:806787fcd4f9e2f814506fb53e81b6fb33f9eea04e5b537b31fa5fb601a497ee&amp;#34;,6423816
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:6d6f19360150548bbb568ecd3e1affabbdce0fcc39156e70fbae8a0aa656541a,386,linux,null,null,&amp;#34;sha256:2826c1e79865da7e0da0a993a2a38db61c3911e05b5df617439a86d4deac90fb&amp;#34;,2808418
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:6d6f19360150548bbb568ecd3e1affabbdce0fcc39156e70fbae8a0aa656541a,386,linux,null,null,&amp;#34;sha256:f2ab0e3b0ff04d1695df322540631708c42b0a68925788de2290c9497e44fef3&amp;#34;,6845295
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:c0684c6ee14c7383e4ef1d458edf3535cd62b432eeba6b03ddf0d880633207da,ppc64le,linux,null,null,&amp;#34;sha256:9a8fdc5b698322331ee7eba7dd6f66f3a4e956554db22dd1e834d519415b4f8e&amp;#34;,2821843
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:c0684c6ee14c7383e4ef1d458edf3535cd62b432eeba6b03ddf0d880633207da,ppc64le,linux,null,null,&amp;#34;sha256:30a37aac8b54a38e14e378f5122186373cf233951783587517243e342728a828&amp;#34;,6746511
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:714439fec7e1f55c29b57552213e45c96bbfeefddea2b3b30d7568591966c914,s390x,linux,null,null,&amp;#34;sha256:7184c046fdf17da4c16ca482e5ede36e1f2d41ac8cea9c036e488fd149d6e8e7&amp;#34;,2582859
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">1.18.0-alpine,sha256:714439fec7e1f55c29b57552213e45c96bbfeefddea2b3b30d7568591966c914,s390x,linux,null,null,&amp;#34;sha256:214dff8a034aad01facf6cf63613ed78e9d23d9a6345f1dee2ad871d6f94b689&amp;#34;,6569410&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;p>各列的含义分别是，&lt;code>镜像tag&lt;/code>, &lt;code>镜像&lt;/code>&lt;a href="https://docs.docker.com/registry/spec/api/#content-digests">Digest&lt;/a>, &lt;code>镜像对应平台的Architecture&lt;/code>, &lt;code>镜像对应平台的OS&lt;/code>, &lt;code>镜像对应平台的变种&lt;/code>（例如，ARM的v7, v8等）, &lt;code>镜像对应平台的OS版本&lt;/code>, &lt;code>镜像组成层的&lt;/code>&lt;a href="https://docs.docker.com/registry/spec/api/#content-digests">Digest&lt;/a>, &lt;code>镜像组成层的大小&lt;/code>。&lt;/p>
&lt;p>上面&lt;code>nginx&lt;/code>镜像的示例数据，告诉我们镜像名&lt;code>nginx&lt;/code>且tag为&lt;code>1.18.0-alpine&lt;/code>的镜像包含了&lt;code>amd64-linux&lt;/code>, &lt;code>arm-linux-v6&lt;/code>, &lt;code>arm64-linux-v8&lt;/code>, &lt;code>386-linux&lt;/code>, &lt;code>ppc64le-linux&lt;/code>以及&lt;code>s390x-linux&lt;/code>共5种Arch合计6个版本的镜像。且每个平台的对应镜像包含了两个层以及这两个层的大小。&lt;/p>
&lt;p>当我们有了成百数千甚至海量镜像的原始数据后，如何能快速且低成本的分析这些数据呢？&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/serverless-docker-images-analytics/">Read More&lt;/a>&lt;/p></description></item><item><title>Get the size of Docker image without pulling image</title><link>https://kane.mx/posts/2020/get-docker-image-size-without-pulling-image/</link><pubDate>Sat, 02 May 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/get-docker-image-size-without-pulling-image/</guid><description>
&lt;p>Recently I had a requirement to stats the size of some Docker images. It would be waste if pulling them all firstly then calculating the size of each image. Also you know the docker image consists of some Docker layers that probably are shared by other images. It's hard to get the disk usage if only sum the size of each image.&lt;/p>
&lt;p>Is there any way to get the size of Docker image without pulling it?&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/get-docker-image-size-without-pulling-image/">Read More&lt;/a>&lt;/p></description></item><item><title>oh-my-zsh性能调优思路</title><link>https://kane.mx/posts/2020/zsh-performance-tuning/</link><pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/zsh-performance-tuning/</guid><description>
&lt;p>&lt;a href="https://zh.wikipedia.org/wiki/Z_shell">Z shell&lt;/a>搭配&lt;a href="https://ohmyz.sh/">oh-my-zsh&lt;/a>自定义配置已成为众多Linux/Macosx用户的标准terminal配置。&lt;/p>
&lt;p>最近遇到在&lt;code>zsh&lt;/code>中执行任意命令都变得特别慢(哪怕简单执行&lt;code>ls&lt;/code>也要花费肉眼可见的1，2秒钟)，这里记录下如何排查&lt;a href="https://zh.wikipedia.org/wiki/Z_shell">Z shell&lt;/a>下启用&lt;a href="https://ohmyz.sh/">oh-my-zsh&lt;/a>的性能问题。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/zsh-performance-tuning/">Read More&lt;/a>&lt;/p></description></item><item><title>基于CodeCommit代码管理的无服务器架构Devops</title><link>https://kane.mx/posts/2020/codecommit-devops-model/</link><pubDate>Thu, 26 Mar 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/codecommit-devops-model/</guid><description>
&lt;p>&lt;a href="https://github.com/">Github&lt;/a>/&lt;a href="https://about.gitlab.com/">Gitlab&lt;/a>已经成为众多开发者非常熟悉的代码协作平台，通过他们参与开源项目或实施企业内部项目协作。&lt;/p>
&lt;p>AWS也提供了托管的、基于Git、安全且高可用的代码服务&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>。&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>主要针对企业用户场景，所以他并没有社交功能以及代码仓库fork功能，是否&lt;a href="https://aws.amazon.com/codecommit/">CodeCommit&lt;/a>就无法实现&lt;a href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests">Github基于Pull Request&lt;/a>的协同工作模式呢？&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/codecommit-devops-model/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS发布更快、更便宜、更易用的HTTP APIs</title><link>https://kane.mx/posts/2020/new-http-apis-of-api-gateway/</link><pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2020/new-http-apis-of-api-gateway/</guid><description>
&lt;p>AWS在3月12日&lt;a href="https://aws.amazon.com/blogs/compute/building-better-apis-http-apis-now-generally-available/">正式发布了新一代的API网关 -- HTTP APIs&lt;/a>。AWS发布的第一代API Gateway服务已经快5年了，通过这些年来大规模服务客户的心得以及客户反馈，由此重新构建了更快（相比第一代网关60%的延迟减少）、更便宜（至少节省71%的费用）、更易用的第二代网关服务。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2020/new-http-apis-of-api-gateway/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS Cloud Debugging初探</title><link>https://kane.mx/posts/2019/aws-cloud-debugging/</link><pubDate>Thu, 26 Dec 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-cloud-debugging/</guid><description>
&lt;p>在&lt;a href="https://reinvent.awsevents.com/?nc2=h_ql_re">re:Invent&lt;/a> 2019之前，&lt;a href="https://aws.amazon.com/getting-started/tools-sdks/?nc2=h_ql_prod_dt_tsdk">AWS Toolkit&lt;/a>发布了&lt;a href="https://aws.amazon.com/about-aws/whats-new/2019/11/announcing-cloud-debugging-beta/?nc1=h_ls">Cloud Debugging beta&lt;/a>功能。该功能支持在IntelliJ IDEs(IntelliJ, PyCharm, Webstorm, 以及 Rider)中远程调试 ECS &lt;a href="https://aws.amazon.com/fargate/">Fargate&lt;/a> 容器中执行的应用程序。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cloud-debugging/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS Batch简介</title><link>https://kane.mx/posts/2019/aws-batch/</link><pubDate>Wed, 25 Dec 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-batch/</guid><description>
&lt;p>&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>是一个全托管的批处理调度服务，它可为用户管理所有基础设施，从而避免了预置、管理、监控和扩展批处理计算作业所带来的复杂性。当然&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>已与 AWS 平台原生集成，让用户能够利用 AWS 的扩展、联网和访问管理功能。让用户轻松运行能够安全地从 AWS 数据存储（如 Amazon S3 和 Amazon DynamoDB）中检索数据并向其中写入数据的作业。&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>可根据所提交的批处理作业的数量和资源要求预置计算资源并优化作业分配。能够将计算资源动态扩展至运行批处理作业所需的任何数量，从而不必受固定容量集群的限制。&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>还可以利用 Spot 实例，从而进一步降低运行批处理作业产生的费用。&lt;/p>
&lt;p>&lt;a href="https://aws.amazon.com/batch/">AWS Batch&lt;/a>服务本身是&lt;strong>免费&lt;/strong>的，仅收取实际使用的 EC2 实例费用。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-batch/">Read More&lt;/a>&lt;/p></description></item><item><title>免费邮件转发服务</title><link>https://kane.mx/posts/2019/email-forwarding/</link><pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/email-forwarding/</guid><description>
&lt;p>在拥有域名后，通常希望创建一些自有域名下的邮箱来收取不同用途的邮件，同时不希望为这部分功能付费&amp;#x1f603;。使用免费的企业邮箱(比如网易企业邮箱、阿里云企业邮箱)是一种选择。这时就需要配置邮件地址和邮件客户端来收取邮件，如果有多个邮箱地址，配置会特别麻烦。有时，这些企业邮箱的收件服务会莫名其妙的丢失一些邮件。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/email-forwarding/">Read More&lt;/a>&lt;/p></description></item><item><title>实战Aliyun EDAS应用迁移AWS</title><link>https://kane.mx/posts/2019/aliyun-edas-migration-in-action/</link><pubDate>Mon, 02 Dec 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aliyun-edas-migration-in-action/</guid><description>
&lt;p>近期实践了将阿里云EDAS微服务应用迁移到AWS上，在这里分享一下迁移方案。&lt;/p>
&lt;p>该方案涉及了以下三个方面，&lt;/p>
&lt;ol>
&lt;li>微服务应用集群。在AWS上采用的&lt;a href="https://aws.amazon.com/cn/ecs/">ECS&lt;/a>集群部署微服务应用，通过&lt;a href="https://aws.amazon.com/cn/cloud-map/">Cloudmap&lt;/a>实现服务注册发现，&lt;a href="https://aws.amazon.com/cn/app-mesh/">App Mesh&lt;/a>实现服务间流量控制。更加详尽的微服务迁移要点和对应方案，详见下面的deck。&lt;/li>
&lt;li>Devops pipeline。使用托管的&lt;a href="https://aws.amazon.com/cn/codepipeline/">CodePipeline&lt;/a>，&lt;a href="https://aws.amazon.com/cn/codebuild/">CodeBuild&lt;/a>实现CI/CD。&lt;/li>
&lt;li>Infra as Code。利用AWS强大的&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">Infra as Code&lt;/a>能力，将云上的基础设施和微服务应用编排通过&lt;a href="https://kane.mx/posts/2019/aws-cdk/">CDK&lt;/a>代码实现。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>下面是迁移方案的deck。完整且可部署的PoC代码，点&lt;a href="https://github.com/zxkane/alibabacloud-microservice-demo">这里&lt;/a>。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aliyun-edas-migration-in-action/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS RDS数据库日志分析及展示</title><link>https://kane.mx/posts/2019/rds-log-analysis/</link><pubDate>Tue, 05 Nov 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/rds-log-analysis/</guid><description>
&lt;p>托管的RDS数据库已经是云计算服务中非常成熟的服务，绝大部分的云计算用户会采用RDS服务来提升数据库服务的可用性同时减少数据库的各类运维事务。&lt;/p>
&lt;p>AWS RDS服务支持开启和查询各类的数据库日志，包括常规日志、慢日志、错误日志和审计日志。但RDS服务默认提供的日志查看工具仅仅类似文本查看器，无法针对日志数据做统计和查看历史滚动的存档。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/rds-log-analysis/">Read More&lt;/a>&lt;/p></description></item><item><title>使用Openswan连接AWS VPC</title><link>https://kane.mx/posts/2019/using-openswan-connect-aws-vpn/</link><pubDate>Mon, 16 Sep 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/using-openswan-connect-aws-vpn/</guid><description>
&lt;p>业务上云之后，经常也有需求将多云、数据中心或办公室的私有网络同云端的私有网络建立连接。&lt;a href="https://docs.aws.amazon.com/zh_cn/vpn/latest/s2svpn/VPC_VPN.html">AWS Site-to-Site VPN&lt;/a>正是AWS提供的托管VPN服务，我们可以在另一端的私有网络通过&lt;a href="https://www.openswan.org/">Openswan&lt;/a>同AWS VPC网络建立基于IPSec协议的安全连接。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/using-openswan-connect-aws-vpn/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS CDK简介</title><link>https://kane.mx/posts/2019/aws-cdk/</link><pubDate>Sun, 08 Sep 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-cdk/</guid><description>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">Infrastructure as Code&lt;/a>(架构即代码)一直是衡量公有云是否支持良好运维能力的重要指标。作为云计算领先的AWS，通过服务&lt;a href="https://aws.amazon.com/cn/cloudformation/">CloudFormation&lt;/a>来编排云环境中的基础设施资源。不过由于CloudFormation是使用YAML/JSON编写的声明式语言，不善于处理逻辑，编写繁琐且不利于调试排错，对于新上手的Devops工程师来说也有不小的学习曲线。三方开源的工具&lt;a href="https://en.wikipedia.org/wiki/Terraform_(software)">Terraform&lt;/a>同样没有很好解决&lt;a href="https://aws.amazon.com/cn/cloudformation/">CloudFormation&lt;/a>存在的这些问题。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-cdk/">Read More&lt;/a>&lt;/p></description></item><item><title>Amazon Alexa Android版本国内登录问题</title><link>https://kane.mx/posts/2019/alexa-login-issue/</link><pubDate>Wed, 14 Aug 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/alexa-login-issue/</guid><description>
&lt;p>近期需要做一些Alexa上的开发，在手机上安装了Amazon Alexa，一直得到下面这样的错误提示而无法登录。&lt;/p>
&lt;blockquote>
&lt;p>Connection Timed Out.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a href="https://kane.mx/posts/2019/alexa-login-issue/">Read More&lt;/a>&lt;/p></description></item><item><title>使用AWS S3作为MacOSX时间机器(Time Machine)的备份存储</title><link>https://kane.mx/posts/2019/using-s3-as-device-for-mac-time-machine-backup/</link><pubDate>Sun, 30 Jun 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/using-s3-as-device-for-mac-time-machine-backup/</guid><description>
&lt;p>个人电脑数据备份一直都是一个强烈的需求。使用网盘等云存储产品可以部分满足数据的备份需求，仍然无法做到使用便利性和很高的数据安全保障。&lt;/p>
&lt;p>MacOSX上系统内置了备份解决方案 -- &lt;a href="https://support.apple.com/zh-cn/HT201250">时间机器(Time Machine)&lt;/a>。Time Machine支持AirPort Time Capsule，NAS存储或者外置的存储设备。然而这些备份方案都依赖于硬件设备，有容量限制或不便于移动。在云计算已经大行其道的今天，有没有使用云计算厂商对象存储作为目标存储的备份方案，为MacOSX数据备份提供无限容量、高度的安全性的云方案？经过一番搜索，既找到了开源免费的工具&lt;a href="https://restic.net/">Restic&lt;/a>，也有付费软件&lt;a href="https://www.arqbackup.com/">Arq&lt;/a>。无论Restic还是Arq提供的是独立的三方工具来实现备份到云端存储或从云端恢复，有没有将Time Machine和云端储存结合在一起的方案呢？&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/using-s3-as-device-for-mac-time-machine-backup/">Read More&lt;/a>&lt;/p></description></item><item><title>公有云对比</title><link>https://kane.mx/posts/2019/aws-vs-aliyun/</link><pubDate>Wed, 26 Jun 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-vs-aliyun/</guid><description>
&lt;p>AWS是全球云计算领域的领跑者，它在计算、存储、网络等方面都做出了很多创新，同时也是其他云计算厂商学习及模仿的对象。&lt;/p>
&lt;p>阿里云是目前国内市场份额最大的云计算厂商，其份额&lt;a href="http://www.sohu.com/a/302064020_465914">超过了第二至五位厂商的总和&lt;/a>，份额领先优势比AWS在全球还要显著，同时&lt;a href="https://www.canalys.com/newsroom/cloud-market-share-q4-2018-and-full-year-2018">全球份额也超过IBM来到第四&lt;/a>。&lt;/p>
&lt;p>本文将对AWS和阿里云核心服务做一个简要对比，以及这两家厂商发展方向的一些个人见解。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-vs-aliyun/">Read More&lt;/a>&lt;/p></description></item><item><title>Serverless framework 101</title><link>https://kane.mx/posts/2019/serverless-framework/</link><pubDate>Thu, 16 May 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/serverless-framework/</guid><description>
&lt;p>&lt;a href="https://serverless.com/">Serverless Framework&lt;/a>是一个开源命令行工具。他提供函数脚手架、流程自动化、最佳实践等帮助开发、部署跨云厂商的托管无服务器计算服务(官方已支持aws, Azure, GCP, IBM Cloud等各种厂商的无服务器计算)。同时支持使用插件来扩展各种功能，比如支持更多云厂商无服务器计算服务，例如&lt;a href="https://github.com/aliyun/serverless-aliyun-function-compute">阿里云的函数计算&lt;/a>。&lt;/p>
&lt;p>这里使用&lt;a href="https://kane.mx/posts/effective-cloud-computing/serverless-dingtalk-callback/">基于函数计算的钉钉回调函数接口&lt;/a>示例来演示如何使用&lt;a href="https://serverless.com/">Serverless Framework&lt;/a>将一个无服务器函数部署到&lt;a href="https://aws.amazon.com/lambda">AWS Lambda&lt;/a>。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/serverless-framework/">Read More&lt;/a>&lt;/p></description></item><item><title>AWS Lambda Layer实践</title><link>https://kane.mx/posts/2019/aws-lambda-layers/</link><pubDate>Tue, 14 May 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/aws-lambda-layers/</guid><description>
&lt;p>在&lt;a href="https://kane.mx/posts/effective-cloud-computing/serverless-dingtalk-callback/">基于函数计算的钉钉回调函数接口&lt;/a>中使用钉钉回调函数案例实践了&lt;a href="https://aws.amazon.com/lambda/">AWS Lambda&lt;/a>无服务函数。该示例中，我们将自定义的函数代码及依赖的第三方库（比如json处理库jackson, 钉钉openapi加密库, aws dynamodb client等）整体打包为一个部署包，上传到lamdba代码仓库用于函数执行。&lt;/p>
&lt;p>然而实际项目中，其实有大量的相关函数可能会共享这些基础依赖库、三方函数库(比如headless chrome(Puppeteer), pandoc, OCR library -- Tesseract等等)或者使用自定义runtime(如官方未支持的java11)的需求。AWS Lambda在去年底发布了&lt;a href="https://aws.amazon.com/about-aws/whats-new/2018/11/aws-lambda-now-supports-custom-runtimes-and-layers/">Lambda layers功能&lt;/a>来满足上述这些实际开发中的需求。&lt;/p>
&lt;p>接下来，让我们看看如何将&lt;a href="https://kane.mx/posts/effective-cloud-computing/serverless-dingtalk-callback/">前文&lt;/a>中的&lt;a href="https://github.com/zxkane/dingtalk-callback-on-aws/blob/267b5f11851148f5a23a834b8b7ecd4d3b247ce7/build.gradle.kts#L71-L91">函数依赖&lt;/a>放置到一个单独的layer中，作为不同函数的共享依赖库。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/aws-lambda-layers/">Read More&lt;/a>&lt;/p></description></item><item><title>QCon2019北京站回顾</title><link>https://kane.mx/posts/2019/2019-qconbeijing-reviews/</link><pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2019/2019-qconbeijing-reviews/</guid><description>
&lt;p>这周参加了&lt;a href="https://2019.qconbeijing.com/">QCon 2019北京站&lt;/a>，这里记录下部分印象深刻的主题以及个人感受。&lt;/p>
&lt;p>QCon是由InfoQ主办的综合性技术盛会，主题涵盖了大前端、高可用架构、容器技术、大数据、机器学习等各种热门技术主题。其中也不乏&lt;a href="https://2019.qconbeijing.com/track/501">下一代分布式应用&lt;/a>、&lt;a href="https://2019.qconbeijing.com/track/565">混沌工程&lt;/a>等前沿有意思的主题，后面会详细介绍相关的主题演讲。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2019/2019-qconbeijing-reviews/">Read More&lt;/a>&lt;/p></description></item><item><title>2018北京ArchSummit回顾</title><link>https://kane.mx/posts/2018/2018-12-13-bj-archsummit-review/</link><pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2018/2018-12-13-bj-archsummit-review/</guid><description>
&lt;p>上周参加了&lt;a href="https://bj2018.archsummit.com">ArchSummit(全球架构师峰会)&lt;/a>，在这里记录下部分参加的主题以及个人感受。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2018/2018-12-13-bj-archsummit-review/">Read More&lt;/a>&lt;/p></description></item><item><title>如何修复Jenkins CI无法读取存在的任务配置</title><link>https://kane.mx/posts/2016/how-to-fix-jenkins-fail-to-load-job-config/</link><pubDate>Wed, 12 Oct 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/how-to-fix-jenkins-fail-to-load-job-config/</guid><description>
&lt;p>&lt;a href="https://vme360.com">V秘&lt;/a>开发团队一直使用着&lt;a href="https://jenkins.io/">Jenkins CI&lt;/a>来持续集成&lt;a href="https://vme360.com">V秘&lt;/a>服务的新功能和各种改进。近日，&lt;a href="https://jenkins.io/">Jenkins CI&lt;/a>在重启之后，很多已有任务的配置无法被&lt;a href="https://jenkins.io/">Jenkins CI&lt;/a>完整的加载，导致很多功能无法使用。导致我们整个网站的各种服务无法被升级更新了:-(&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/how-to-fix-jenkins-fail-to-load-job-config/">Read More&lt;/a>&lt;/p></description></item><item><title>MongoDB中如何找出慢查询</title><link>https://kane.mx/posts/2016/how-to-find-slow-queries-in-mongodb/</link><pubDate>Thu, 29 Sep 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/how-to-find-slow-queries-in-mongodb/</guid><description>
&lt;p>&lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>是目前最为流行的&lt;a href="https://en.wikipedia.org/wiki/NoSQL">NoSQL&lt;/a>数据库之一。&lt;a href="https://vme360.com">V秘&lt;/a>的后台数据就是保存在&lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>中的哦;)&lt;/p>
&lt;p>尽管&lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>的性能为业界称道，但任何数据库系统使用中都存在着慢查询的问题。慢查询的性能问题，可能是由于使用非最优的查询语句，不正确的索引或其他配置原因导致的。但开发人员或数据库维护人员首先要找出这些低效的查询，才能做出对应的查询优化。&lt;/p>
&lt;!-- more -->
&lt;p>在&lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>中实现慢查询的profile是非常容易，因为&lt;a href="https://www.mongodb.com/">MongoDB&lt;/a>内置了&lt;a href="https://docs.mongodb.com/manual/reference/method/db.setProfilingLevel/">profile开关&lt;/a>来记录执行时间触发了profile条件的查询。&lt;/p>
&lt;p>参照&lt;a href="https://docs.mongodb.com/manual/reference/method/db.setProfilingLevel/">db.setProfileLevel()&lt;/a>的文档，通过以下命令就可以记录执行时长超过&lt;strong>300ms&lt;/strong>的查询。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-javascript" data-lang="javascript">&lt;span class="line">&lt;span class="ln">1&lt;/span>&lt;span class="cl">&lt;span class="nx">db&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">setProfilingLevel&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">300&lt;/span>&lt;span class="p">)&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>当慢查询被重现后，可以通过查找&lt;code>system.profile&lt;/code> collection来查看执行时长超过&lt;strong>300ms&lt;/strong>的查询。&lt;/p>
&lt;p>被profiler记录下来慢查询record看起来如下，&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/how-to-find-slow-queries-in-mongodb/">Read More&lt;/a>&lt;/p></description></item><item><title>Docker Swarm mode(v1.12.x)的一些使用限制</title><link>https://kane.mx/posts/2016/the-limitations-docker-swarm-mode-v1.12/</link><pubDate>Tue, 20 Sep 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/the-limitations-docker-swarm-mode-v1.12/</guid><description>
&lt;p>&lt;a href="https://docs.docker.com/engine/swarm/">Swarm mode&lt;/a>在&lt;a href="https://www.docker.com">Docker&lt;/a> v1.12中正式发布，&lt;a href="https://docs.docker.com/engine/swarm/">Swarm mode&lt;/a>带来了诸如Docker集群，容器编排，多主机网络等激动人心的特性。&lt;a href="https://vme360.com">V秘&lt;/a>团队也尝试着将各种后台服务部署到&lt;a href="https://docs.docker.com/engine/swarm/">Docker Swarm Cluster&lt;/a>获取更好的弹性计算能力。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/the-limitations-docker-swarm-mode-v1.12/">Read More&lt;/a>&lt;/p></description></item><item><title>创建于Docker Swarm的服务无法在Ubuntu 14.04 LTS中运行</title><link>https://kane.mx/posts/2016/docker-swarm-mode-in-ubuntu-1404/</link><pubDate>Tue, 13 Sep 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/docker-swarm-mode-in-ubuntu-1404/</guid><description>
&lt;p>&lt;a href="https://vme360.com">V秘&lt;/a>团队一直致力于用技术改善产品。&lt;a href="https://vme360.com">V秘&lt;/a>后台的各种服务一直是通过完善的Devops流程自动部署到&lt;a href="https://www.docker.com">Docker&lt;/a>容器集群。随着&lt;a href="https://docs.docker.com/engine/swarm/">Swarm mode&lt;/a>在&lt;a href="https://www.docker.com">Docker&lt;/a> v1.12中正式发布，&lt;a href="https://docs.docker.com/engine/swarm/">Swarm mode&lt;/a>带来了诸如Docker集群，多主机网络等激动人心的特性。我们也在尝试将&lt;a href="https://vme360.com">V秘&lt;/a>服务部署到&lt;a href="https://docs.docker.com/engine/swarm/">Docker Swarm Cluster&lt;/a>获取更好的弹性计算能力。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/docker-swarm-mode-in-ubuntu-1404/">Read More&lt;/a>&lt;/p></description></item><item><title>基于Angularjs单页面应用的SEO优化</title><link>https://kane.mx/posts/2016/seo-optimization-for-angularajs-based-app/</link><pubDate>Thu, 19 May 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/seo-optimization-for-angularajs-based-app/</guid><description>
&lt;p>在之前的&lt;a href="https://kane.mx/posts/2016/single-page-app-meets-weixin-pay/">文章&lt;/a>我曾提到基于&lt;a href="https://angularjs.org/">Angularjs&lt;/a>的单页面应用在用户体验上的种种好处。然而任何事情都不是完美的，&lt;a href="https://angularjs.org/">Angular&lt;/a>和类似的框架通过应用内做页面路由的实现给SEO（也俗称搜索引擎优化）带来了不少麻烦。&lt;/p>
&lt;p>首先，我们来看看页面内路由是如何实现的。默认&lt;a href="https://angularjs.org/">Angularjs&lt;/a>生成的页面uri类型如下，&lt;/p>
&lt;p>&lt;code>http://mydomain.com/#/app/page1&lt;/code>&lt;/p>
&lt;p>浏览器请求上面这个uri的时候，实际发送给服务器的请求地址是&lt;strong>&lt;a href="http://mydomain.com/">http://mydomain.com/&lt;/a>&lt;/strong>, web服务器会将默认的页面响应给浏览器，比如&lt;em>index.html&lt;/em>或&lt;em>index.php&lt;/em>等。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/seo-optimization-for-angularajs-based-app/">Read More&lt;/a>&lt;/p></description></item><item><title>Spring框架下的分布式session管理</title><link>https://kane.mx/posts/2016/clustered-session-under-spring-framework/</link><pubDate>Sat, 07 May 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/clustered-session-under-spring-framework/</guid><description>
&lt;p>在微服务和容器等技术的帮助下，Web应用可以较为容易的进行水平扩展，来部署更多的应用实例来提升请求处理数QPS。当Web服务有状态的时候，如何在集群下管理用户session成为新的待解决问题。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/clustered-session-under-spring-framework/">Read More&lt;/a>&lt;/p></description></item><item><title>V秘是如何构建的</title><link>https://kane.mx/posts/2016/how-we-build-videome/</link><pubDate>Thu, 07 Apr 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/how-we-build-videome/</guid><description>
&lt;p>春天来了，&lt;a href="https://vme360.com">V秘&lt;/a>大家庭也新增了两位10后的传人。新爸爸经过一番忙乱后，希望在这里与大家分享&lt;a href="https://vme360.com">V秘&lt;/a>的架构，共同探讨如何快速的构建高可用，高性能的Web服务。&lt;/p>
&lt;p>&lt;a href="https://vme360.com">V秘&lt;/a>致力于提供最好的在线视频制作云平台。让用户随时随地零门槛的快速制作出高质量高清晰度的视频，来纪念记录生活中有意义的时刻，同时将这份快乐传递给更多的家人朋友一起分享。&lt;/p>
&lt;p>然而要可靠的可扩展的实现这样看似简单的需求，其背后确由众多知名开源技术，可靠的云服务，不间歇的监控运维来实现和保证的。&lt;/p>
&lt;!-- more -->
&lt;p>&lt;a href="https://vme360.com">V秘&lt;/a>架构的基本目标就是要实现，&lt;/p>
&lt;ul>
&lt;li>服务的高扩展性。有有效可靠的方法支撑数万并发到数十万，百万及更多的并发请求。&lt;/li>
&lt;li>服务的高可用性。各种服务都是多实例的集群，某些服务故障后，集群中的其他实例仍然能够提供服务。&lt;/li>
&lt;li>服务的自动化构建。从代码到服务部署上线是一套自动化的流程，越少的人工介入保证了服务的可用性。&lt;/li>
&lt;li>系统的实时监控。7x24小时的监控保证服务的可用性，当监控到数据异常或服务停止运行能及时告警引入人工运维团队。&lt;/li>
&lt;/ul>
&lt;p>更多细节请参阅下面的&lt;a href="http://www.slideshare.net/zxkane/how-we-build-vme">slides&lt;/a>,&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/how-we-build-videome/">Read More&lt;/a>&lt;/p></description></item><item><title>说一说阿里云ossfs</title><link>https://kane.mx/posts/2016/aliyun-ossfs-sucks/</link><pubDate>Fri, 26 Feb 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/aliyun-ossfs-sucks/</guid><description>
&lt;p>阿里云提供的对象或者文件存储叫&lt;a href="https://www.aliyun.com/product/oss">OSS&lt;/a>，为应用程序提供了海量存储，按需付费等服务。应用程序则需要通过&lt;a href="https://www.aliyun.com/product/oss">Aliyun OSS&lt;/a>的各语言SDK才能操作（读，写，遍历等）OSS中的文件。&lt;/p>
&lt;p>对运维人员来说，做一些数据维护工作的时候，通过SDK操作&lt;a href="https://www.aliyun.com/product/oss">OSS&lt;/a>中的文件就会比较麻烦。在linux/unix环境下，通常有一些工具把远程文件系统或云盘挂载为本地文件。在网络状况比较好的情况下，操作远程文件就像操作本地文件一样。例如，把&lt;a href="https://github.com/s3fs-fuse/s3fs-fuse">Amazon S3&lt;/a>，&lt;a href="https://github.com/joe42/CloudFusion">Dropbox云盘&lt;/a>，&lt;a href="https://github.com/libfuse/sshfs">可通过ssh登录的远程服务器上的磁盘&lt;/a>挂载为本地文件系统。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/aliyun-ossfs-sucks/">Read More&lt;/a>&lt;/p></description></item><item><title>如何使用微信公众平台的临时素材</title><link>https://kane.mx/posts/2016/weixin-temporary-materials/</link><pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/weixin-temporary-materials/</guid><description>
&lt;p>微信给公众平台提供了&lt;a href="http://mp.weixin.qq.com/wiki/15/2d353966323806a202cd2deaafe8e557.html">素材管理&lt;/a>的接口，通过这一系列接口可以上传，接收以及管理图片，视频等多媒体文件。其中又分为&lt;strong>临时&lt;/strong>和&lt;strong>永久&lt;/strong>两种类型。永久素材有总量的限制，临时素材微信服务器只给保存3天。&lt;/p>
&lt;p>最近&lt;a href="https://vme360.com">V秘&lt;/a>刚好有个同微信用户互动的场景，为用户美化微信拍摄的小视频。&lt;a href="https://vme360.com">V秘&lt;/a>后台服务器收到用户发送过来小视频（微信将其认做临时素材），将其美化处理后，再将美化的视频上传为临时素材，最终美化后的视频作为视频类型的客服消息被推送给用户。整个流程很简洁，用户发送小视频后，就坐等观看美化后的小视频了。&lt;/p>
&lt;p>然而最终经过V秘开发团队的实践及测试，得出的结论是，&lt;/p>
&lt;!-- more -->
&lt;p>##&lt;strong>微信公众平台的临时素材不能用！绝对的鸡肋！&lt;/strong>&lt;/p>
&lt;p>公众平台上传素材的API以及使用已有素材发送视频消息API都很健壮。但问题出在了微信后台资源的服务上面。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/weixin-temporary-materials/">Read More&lt;/a>&lt;/p></description></item><item><title>单页面应用(single page application)中使用微信支付</title><link>https://kane.mx/posts/2016/single-page-app-meets-weixin-pay/</link><pubDate>Sun, 24 Jan 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/single-page-app-meets-weixin-pay/</guid><description>
&lt;p>随着&lt;strong>AngularJS&lt;/strong>等前端MVC框架的流行，AJAX的异步请求数据结合H5的push state等特性，极大的改善了网站的用户体验和页面加载性能。这类网站应用通常只有一个入口页面，通过应用内路由到不同的页面，所以俗称单页面(signle page application)应用。页面&lt;strong>URL&lt;/strong>看起来如下，&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/single-page-app-meets-weixin-pay/">Read More&lt;/a>&lt;/p></description></item><item><title>文件系统的Inode耗尽，会导致Docker编译镜像出现'No space left on device'错误</title><link>https://kane.mx/posts/2016/docker-build-no-space-left-caused-by-inode-exhausted/</link><pubDate>Thu, 21 Jan 2016 00:00:00 +0000</pubDate><guid>https://kane.mx/posts/2016/docker-build-no-space-left-caused-by-inode-exhausted/</guid><description>
&lt;p>最近在提交前端代码后，前端代码的自动发布老是失败。失败的原因多是编译Docker镜像时在执行&lt;code>COPY&lt;/code>语句拷贝文件到镜像文件系统时，扔出了'No space left on device'这个错误。这个错误根据描述非常好理解，就是docker文件系统所在磁盘没有了空间。&lt;/p>
&lt;p>&lt;a href="https://kane.mx/posts/2016/docker-build-no-space-left-caused-by-inode-exhausted/">Read More&lt;/a>&lt;/p></description></item></channel></rss>