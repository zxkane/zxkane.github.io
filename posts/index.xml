<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The Road</title>
    <link>https://kane.mx/posts/</link>
    <description>Recent content in Posts on The Road</description>
    <meta name="generator" content="Hugo 0.53" />
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jan 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://kane.mx/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>不要自建Kubernetes</title>
      <link>https://kane.mx/posts/effective-cloud-computing-series/using-kubernetes-on-cloud/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kane.mx/posts/effective-cloud-computing-series/using-kubernetes-on-cloud/</guid>
      <description>&lt;p&gt;这是“如何高效使用云服务”系列文章的首篇分享。可能有朋友好奇为什么不是从云计算最基础的服务&amp;ndash;计算资源&lt;a href=&#34;https://cn.aliyun.com/product/ecs&#34;&gt;ECS&lt;/a&gt;/&lt;a href=&#34;https://aws.amazon.com/cn/ec2/&#34;&gt;EC2&lt;/a&gt;讲起呢？在&lt;a href=&#34;https://pivotal.io/cloud-native&#34;&gt;Cloud Native&lt;/a&gt;已经被越来越接受的今天，基于&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;部署、编排应用的方式已经是业界的事实标准。无论是互联网巨头，传统500强企业，还是创业团队都在使用或规划使用&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;作为应用程序的自动化部署、可扩展管理平台。在云计算平台，虚拟机越来越不需要单独的管理，在绝大多数的业务场景下，它们只是作为容器集群所管理的计算资源。甚至虚拟机的创建到销毁整个生命周期管理都可以由&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;根据集群的负载来自动完成。&lt;/p&gt;

&lt;p&gt;所有主流的云计算厂商都在解决方案中力推托管的&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;，&lt;a href=&#34;https://aws.amazon.com/cn/&#34;&gt;AWS&lt;/a&gt;的&lt;a href=&#34;https://aws.amazon.com/eks&#34;&gt;EKS&lt;/a&gt;，&lt;a href=&#34;https://azure.microsoft.com/en-us/&#34;&gt;Azure&lt;/a&gt;上的&lt;a href=&#34;https://azure.microsoft.com/en-us/services/kubernetes-service/&#34;&gt;AKS&lt;/a&gt;，当然少不了Google家&lt;a href=&#34;https://cloud.google.com/&#34;&gt;GCP&lt;/a&gt;上的&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/&#34;&gt;Kubernetes Engine&lt;/a&gt;。国内&lt;a href=&#34;https://www.aliyun.com/product/kubernetes&#34;&gt;阿里云&lt;/a&gt;，&lt;a href=&#34;https://cloud.tencent.com/product/tke&#34;&gt;腾讯云&lt;/a&gt;等每一个公有云玩家也都基于开源&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;推出了托管服务。如果一家云计算厂商在提供托管&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;这一服务上没跟上业界的步伐，将来极大可能被淘汰出这个市场。&lt;/p&gt;

&lt;h2 id=&#34;托管的kubernetes类型&#34;&gt;托管的Kubernetes类型&lt;/h2&gt;

&lt;p&gt;以国内的阿里云为例，目前提供了两大类三种不同的&lt;a href=&#34;https://help.aliyun.com/document_detail/86737.html&#34;&gt;Kubernetes托管服务&lt;/a&gt;。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;经典Dedicated Kubernetes模式。这种模式下用户可以选择宿主机实例规格和操作系统，指定Kubernetes版本、自定义Kubernetes特性开关设置等。用户需要手动维护集群，例如升级Kubernetes版本，内置组件版本等。可以手动或自动伸缩集群节点数目。目前该模式下有两种类型，第一种集群主节点需要使用用户的ECS，用户可远程登录或管理这些ECS。另一种是，主节点也由云厂商托管，用户只能通过API Server管理Kubernetes。在费用方面，无论是否托管集群主节点，集群服务免费，按使用的ECS实例及计费方式收费。&lt;/li&gt;
&lt;li&gt;Serverless 模式(目前公测中，暂时免费)。无需创建底层虚拟化资源，可以利用 Kubernetes 命令指明应用容器镜像、CPU和内存要求以及对外服务方式，直接启动应用程序。按容器使用的CPU和内存资源量计费。这种模式下应该是在一个集群内实现多租户，目前有些&lt;a href=&#34;https://help.aliyun.com/document_detail/86371.html&#34;&gt;features不被支持&lt;/a&gt;。例如，部署不支持DaemonSet，Ingress不支持NodePort类型，存储不支持PV和PVC等。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;用户可以根据自己的业务类型来选择适合的托管Kubernetes集群。如果部署的应用是&lt;a href=&#34;https://kubernetes.io/docs/tutorials/stateless-application/&#34;&gt;无状态的Web服务&lt;/a&gt;，可以选择Serverless Kubernetes集群，进一步减少运维工作量。&lt;/p&gt;

&lt;p&gt;如果用户部署的应用有状态，需要挂载外部存储，例如MongDB集群，MQ集群，可以选择经典Dedicated Kubernetes模式。如果用户需要通过Kubernetes组件扩展或自定义实现某些功能，这些需求云厂商的标准版并没有提供，这时可以选择经典Dedicated Kubernetes模式，利用Kubernetes高度灵活的扩展机制来满足自定义需求。&lt;/p&gt;

&lt;h2 id=&#34;托管kuberentes的优势&#34;&gt;托管Kuberentes的优势&lt;/h2&gt;

&lt;p&gt;国内的阿里云有篇技术文档对比&lt;a href=&#34;https://help.aliyun.com/document_detail/69575.html&#34;&gt;阿里云Kubernetes vs. 自建Kubernetes&lt;/a&gt;，文章看起来虽然有厂商自卖自夸的嫌疑。作为&lt;a href=&#34;https://www.aliyun.com/product/kubernetes&#34;&gt;阿里云K8S&lt;/a&gt;的客户，在使用托管K8S近一年来，深切的体会到云厂商托管K8S带来的种种好处，文档中提到的种种优势确实是言之凿凿。&lt;/p&gt;

&lt;p&gt;接下来具体看看云厂商托管K8S到底有哪些优势。&lt;/p&gt;

&lt;h3 id=&#34;便捷&#34;&gt;便捷&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;通过Web界面/API一键创建Kubernetes集群，集群升级。&lt;/li&gt;
&lt;li&gt;Web界面/API实现集群的扩容或缩容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;集群的安装，补丁以及常规版本升级在运维工作中属于体力活。在规模不大的时候，使用人工实现需要花费不少时间准备环境测试验证，且易错。如果集群体量不够大的话，开发自动化运维脚本又浪费人力成本。云计算厂商的托管K8S集群将提供专业、稳定的技术运维服务，和几乎为零的人力成本。&lt;/p&gt;

&lt;p&gt;从效率和人力成本上看，&lt;strong&gt;托管K8S集群完胜自建Kubernetes集群&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;功能更强大&#34;&gt;功能更强大&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;作为一个容器编排系统，开源版本中许多组件没有默认实现或实现有限，需要跟运行环境(如托管K8S的云平台)集成。例如，存储，Load Balancer，网络等核心组件。官方文档&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer&#34;&gt;Internal load balancer&lt;/a&gt;就提供了在不同的云厂商环境中的使用示例。部署一个强大且完整的K8S集群需要同许多云计算的基础组件集成(且只能通过API完成)，这往往是云计算厂商的强项。&lt;/p&gt;

&lt;p&gt;云厂商托管的K8S可以在以下方面提供强大的云计算平台支持，&lt;/p&gt;

&lt;h4 id=&#34;网络&#34;&gt;网络&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;高性能 VPC 网络插件。&lt;/li&gt;
&lt;li&gt;支持 network policy 和流控。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;负载均衡&#34;&gt;负载均衡&lt;/h4&gt;

&lt;p&gt;支持创建公网或内网负载均衡实例，或者复用已有实例。支持指定带宽大小、计费方式、4层或7层协议代理等云厂商负载均衡功能。对应用运维来说可以把负载均衡的配置通过代码实现，并且支持版本控制。对比传统的云端部署，也可以将应用部署和应用运维集成在一起统一管理，避免应用发布和运维配置的割裂，减少人为运维失误。&lt;/p&gt;

&lt;p&gt;阿里云托管K8S的负载均衡详细配置可以参考这个&lt;a href=&#34;https://help.aliyun.com/document_detail/53759.html?spm=a2c4g.11186623.2.15.73364c07mR8rhS#h2-url-4&#34;&gt;文档&lt;/a&gt;，AWS上见此&lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/load-balancing.html&#34;&gt;文档&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;存储&#34;&gt;存储&lt;/h4&gt;

&lt;p&gt;集成了云厂商的云盘、文件存储NAS、块存储等存储方案，基于标准的&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/devel/flexvolume.md&#34;&gt;FlexVolume&lt;/a&gt;驱动，提供了最佳的无缝集成。&lt;/p&gt;

&lt;p&gt;如果是在云厂商的虚拟机上自建&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;集群，默认无法使用云上的存储资源。如果需要利用云厂商提供的存储方案，例如对象存储，就需要自行开发基于&lt;a href=&#34;https://github.com/kubernetes/community/blob/master/contributors/devel/flexvolume.md&#34;&gt;FlexVolume&lt;/a&gt;的驱动。在厂商托管K8S已经完美解决了存储集成的问题，何必自己又去费时费力的定制开发呢？&lt;/p&gt;

&lt;p&gt;可以看到，云厂商托管的K8S集群在网络、负载均衡和存储上有许多天然的优势。在其他几个维度，托管的K8S集群同样也优于自建的K8S，&lt;/p&gt;

&lt;h4 id=&#34;运维&#34;&gt;运维&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;集成厂商的日志服务，监控服务。&lt;/li&gt;
&lt;li&gt;K8S集群cluster autoscaler自动利用云厂商的弹性伸缩扩缩容集群节点。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;镜像仓库&#34;&gt;镜像仓库&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;高可用，支持大并发。&lt;/li&gt;
&lt;li&gt;支持镜像加速。&lt;/li&gt;
&lt;li&gt;支持 p2p 分发。&lt;/li&gt;
&lt;li&gt;可集成云平台的用户权限。&lt;/li&gt;
&lt;li&gt;部分厂商目前免费且不限容量。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;高可用&#34;&gt;高可用&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;提供多可用区支持。&lt;/li&gt;
&lt;li&gt;支持备份和容灾。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;技术支持&#34;&gt;技术支持&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;专门的技术团队保障容器的稳定性。&lt;/li&gt;
&lt;li&gt;每个 Linux 版本，每个 Kubernetes 版本都会在经过严格测试之后之后才会提供给用户。&lt;/li&gt;
&lt;li&gt;提供 Kubernetes 升级能力，新版本一键升级。&lt;/li&gt;
&lt;li&gt;为开源软件提供兜底，无论是K8S、Docker甚至Linux自身的问题提供支持。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;专业的技术团队是提供稳定K8S服务必不可少的。但绝大多数企业是无法做到有专业的技术团队来维护K8S、提供K8S或容器技术自身的各种最佳实践、发现以及修复开源软件Bug。&lt;/p&gt;

&lt;p&gt;在笔者的使用托管K8S的时候就遇到这样的状况。其中一个集群升级到新版本&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;后，内置DNS组件从&lt;a href=&#34;https://github.com/kubernetes/dns&#34;&gt;KubeDNS&lt;/a&gt;被替换为全新的&lt;a href=&#34;https://coredns.io/&#34;&gt;CoreDNS&lt;/a&gt;，而当时的&lt;a href=&#34;https://coredns.io/&#34;&gt;CoreDNS&lt;/a&gt;版本在&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/service/#externalname&#34;&gt;Service ExternalName&lt;/a&gt;支持上有Bug，导致已有的这种Service无法提供服务。在同云厂商的技术团队沟通后，先用workaround将问题快速绕过，不影响业务的使用。同时，云厂商的技术人员（也是K8S社区committer）继续调研，发现该问题是&lt;a href=&#34;https://coredns.io/&#34;&gt;CoreDNS&lt;/a&gt;的Bug。在为开源&lt;a href=&#34;https://coredns.io/&#34;&gt;CoreDNS&lt;/a&gt;项目创建Issue后，同时提供Patch，又在CoreDNS committer建议下完善了测试用例，推动了该问题快速在CoreDNS中被修复。CoreDNS包含Fix的版本发布后，云厂商技术支持团队将更完美的解决方案提供给了我们。作为K8S服务的用户，这种体验是极好的。当时我们的技术团队既没有精力也没有能力快速发现并修复开源软件中的这类问题，而云厂商的服务间接帮我们实现了这种能力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这其实是一种非常好的共赢商业模式，云厂商有能力且有动力投入顶尖技术团队将开源技术商业化，云厂商的用户则用最小的代价获得了最优的基础服务来为核心业务赋能。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>真的会用云服务吗？</title>
      <link>https://kane.mx/posts/effective-cloud-computing-series/preface/</link>
      <pubDate>Mon, 07 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://kane.mx/posts/effective-cloud-computing-series/preface/</guid>
      <description>&lt;p&gt;这是“如何高效使用云服务”系列文章的引子。该系列将讲述如何利用各种公有云服务来安全合规、高质量、快速、低成本的打造产品/系统，帮助企业（特别是中小微创业团队）在人少，钱缺的情况下做到最高效率。&lt;/p&gt;

&lt;h2 id=&#34;个人使用公有云服务的经历&#34;&gt;个人使用公有云服务的经历&lt;/h2&gt;

&lt;h3 id=&#34;初会&#34;&gt;初会&lt;/h3&gt;

&lt;p&gt;最早是2012年在parttime项目中开始接触使用云计算服务，当时的初创团队也是希望用最低的成本来验证idea，所有使用了云服务来做POC。目前国内市场最领先的云计算厂商&lt;a href=&#34;https://baike.baidu.com/item/%E9%98%BF%E9%87%8C%E4%BA%91#4&#34;&gt;阿里云那时也才提供公有云服务不到1年&lt;/a&gt;。由于云产品不够成熟，加上团队技能经验不足，自助互助的渠道不畅，导致最初的云计算使用体验并不好，团队没有选择完全使用云服务构建产品。&lt;/p&gt;

&lt;h3 id=&#34;iaas-or-paas&#34;&gt;IaaS or PaaS&lt;/h3&gt;

&lt;p&gt;云计算兴起的早期，云厂商大致分为两类，提供基于&lt;a href=&#34;https://en.wikipedia.org/wiki/Infrastructure_as_a_service&#34;&gt;IaaS&lt;/a&gt;或&lt;a href=&#34;https://en.wikipedia.org/wiki/Platform_as_a_service&#34;&gt;PaaS&lt;/a&gt;的云服务。2013年起也有尝试不同类型的厂商平台，虽然也较好的完成一些体量不大的项目，但要在他们上面构建大规模用户产品或企业级应用，在云产品完善度上或支持开发团队协作上都有不少欠缺，还有大量的基础工作或限制留给了开发团队自身解决。&lt;/p&gt;

&lt;h3 id=&#34;all-in-cloud&#34;&gt;All-in Cloud&lt;/h3&gt;

&lt;p&gt;2015年我开始一个微电影项目创业，团队是不到10人的微型团队。从效率和成本考虑，我们将所有的服务都放到了阿里云上。我们使用了多种云产品，例如，云主机（多种OS），对象存储，图片处理，CDN，SLB，人脸识别等云服务，结合&lt;a href=&#34;https://en.wikipedia.org/wiki/DevOps&#34;&gt;Devops&lt;/a&gt;集成开发，测试，部署pipeline来加速产品的迭代和更新。每名工程师承担一种以上角色，前端，后端，运维，数据，视频渲染等。合理使用云厂商的各种产品帮我们在质量，效率，成本上获得巨大的收益。&lt;/p&gt;

&lt;p&gt;2017年我加入了一家企业财税服务的初创公司负责技术团队。公司在2018年获得了B轮投资，研发产品运营团队近百人，属于中等规模。随着各种开源技术的巨大进步和影响逐步扩大，&lt;a href=&#34;https://en.wikipedia.org/wiki/Microservices&#34;&gt;微服务&lt;/a&gt;架构的流行，基于&lt;a href=&#34;https://kubernetes.io/&#34;&gt;Kubernetes&lt;/a&gt;的&lt;a href=&#34;https://www.cncf.io/&#34;&gt;Cloud Native Computing&lt;/a&gt;兴起。我们利用云厂商的容器服务，&lt;a href=&#34;https://en.wikipedia.org/wiki/Cloud_database&#34;&gt;DBaaS&lt;/a&gt;，Big Data，AI技术等用最高效的方式将数个单体应用平滑升级到高可用弹性的分布式架构，更好的满足复杂业务的多变需求，公司服务也在全国300多个城市落地，服务了数十万中小微企业客户。同时利用云厂商的VPC，访问控制，WAF等产品进行权限控制和安全保护，有效防范了因为团队扩大管理难度增加而出现安全问题。&lt;/p&gt;

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;作为一名云计算服务6年的用户，见证了开源技术的快速发展和影响力急剧扩大，感受到整个云计算行业和厂商的长足进步。见证了国内头部云厂商从最初的使用难度颇大，现在成长为万众创业的首选服务商。&lt;/p&gt;

&lt;p&gt;过去的一年参加了数场技术会议，其中主题大多偏向于由知名的互联网或行业公司分享在海量数据下的技术应用。这些技术广泛涉及开发语言、应用架构、性能、大数据、机器学习和人工智能等领域，无论这些公司是否采用开源产品，在团队单兵技术能力，专业的分工，对开源项目的研发投入力量，这些经验和方法并不是中小企业可以轻易借鉴的。而云计算厂商将这些领域最基础通用的能力以产品的方式输出给用户，以按用量的方式计费，使用更简单，有专业团队维护和支持。中小团队就应该将这些事情“外包”给云厂商，集中精力到业务上，将最大的研发资源用到最核心最关键的地方。&lt;/p&gt;

&lt;p&gt;我同团队同事沟通中，和公司研发候选人面试交流中，发现许多从业者对云计算服务了解还不够深入。许多人理解中的云计算服务只有云服务器、云数据库等少数产品，需要自己安装维护应用服务器、负载均衡、收集日志等等看起来每个应用都绕不开的事情。他们的认知还停留在排查应用异常还需要远程登录服务器看日志，做不到合理的根据场景高效组合使用云服务，将云服务当做水电一样，作为最基础的能力加速业务的发展。业务上是采用名气大且成熟的产品，尝试新鲜看起来酷但不那么完善的产品，还是二次开发或自研开发？要做出最优的选择需要工程师能够从有高度的全局角度来考量，甚至在短时间内能用POC项目验证多个可选的方案，基于数据做出最终的选择。&lt;/p&gt;

&lt;p&gt;这就是这个系列的缘起，之后我将陆续分享使用那些高效的云服务产品的场景、心得、体会等等。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;封面图片&lt;a href=&#34;http://www.thebluediamondgallery.com/tablet/c/cloud-computing.html&#34;&gt;Cloud Computing&lt;/a&gt;引用自&lt;a href=&#34;http://www.thebluediamondgallery.com/&#34;&gt;The Blue Diamond Gallery&lt;/a&gt; under &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/3.0/&#34;&gt;CC BY-SA 3.0&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;</description>
    </item>
    
    <item>
      <title>2018北京ArchSummit回顾</title>
      <link>https://kane.mx/posts/2018/2018-12-13-bj-archsummit-review/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://kane.mx/posts/2018/2018-12-13-bj-archsummit-review/</guid>
      <description>&lt;p&gt;上周参加了&lt;a href=&#34;https://bj2018.archsummit.com&#34;&gt;ArchSummit(全球架构师峰会)&lt;/a&gt;，在这里记录下部分参加的主题以及个人感受。&lt;/p&gt;

&lt;h3 id=&#34;会议回顾&#34;&gt;会议回顾&lt;/h3&gt;

&lt;p&gt;今年参加了几次技术会议，&lt;code&gt;微服务&lt;/code&gt;、&lt;code&gt;容器技术&lt;/code&gt;、&lt;code&gt;区块链&lt;/code&gt;、&lt;code&gt;大数据&lt;/code&gt;、&lt;code&gt;机器学习&lt;/code&gt;以及&lt;code&gt;人工智能&lt;/code&gt;都是当下最热门的主题。同样这次ArchSummit绝大部分topics都跟这些主题相关。&lt;/p&gt;

&lt;p&gt;这次会议主要参加了两个专场主题，&lt;a href=&#34;https://bj2018.archsummit.com/track/440&#34;&gt;Kubernetes的应用&lt;/a&gt;和&lt;a href=&#34;https://bj2018.archsummit.com/track/446&#34;&gt;快手科技技术专题&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://bj2018.archsummit.com/presentation/928&#34;&gt;基于 Kubernetes 的 DevOps&lt;/a&gt;是来自微软Azure的容器工程师分享如何基于 Kubernetes 的 CI/CD 落地实践。该分享中提到了CI/CD各个步骤中都有众多的工具支持，如何选择合适Kubernetes的工具将持续集成和部署串联在一起是Devops中的主要挑战。分享者也安利了AKS提供Devops完整的工具链，以及将开源工具同AKS中的服务集成实现CI/CD的最佳实践。&lt;/p&gt;

&lt;p&gt;我们噼里啪团队在CI/CD、Devops这块做得还不错。CI/CD pipelines持续将应用部署在运行的Kubernetes集群，过程中使用的工具链基本也是社区或CNCF推荐的主流工具。下一步可以考虑同云厂商的Devops工具链集成，进一步减少维护成本。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://bj2018.archsummit.com/presentation/1258&#34;&gt;基于Istio on Kubernetes云原生应用的最佳实践&lt;/a&gt;来自阿里云容器工程师的分享。他概要的分享了Istio技术和实现原理。当然也大力介绍了阿里云容器服务对Istio的原生支持，以及阿里云对客户使用Istio的支持，即使客户问题非常的初级他们的技术支持也很到位。&lt;/p&gt;

&lt;p&gt;Istio可以说是CNCF在Kubernetes上事实的服务治理实现。噼里啪技术团队也一直在关注这一块，正在尝试引入Istio提升服务的SLA。&lt;/p&gt;

&lt;p&gt;快手技术团队的4个分享都是围绕解决明确的业务问题而做得技术工作，非常具有实战性。其中&lt;a href=&#34;https://bj2018.archsummit.com/presentation/1337&#34;&gt;快手万亿级实时 OLAP 平台的建设与实践&lt;/a&gt;介绍了快手实时OLAP平台从0到1的搭建过程。该平台从今年4月开始搭建，截止到11月，每日可以实时计算处理超过万亿的数据。而整个平台的搭建由两名大数据工程师外加一名前端工程师负责portal等UI，人效产出让人非常佩服。结合朋友间传言快手给技术人员的offer，快手应该是一家在实践类似Netflix管理文化的公司。&lt;/p&gt;

&lt;p&gt;最后给大家推荐一个国产的分布式New SQL数据库TiDB相关的主题。TiDB是国内技术团队开源的一个分布式数据库，已被CNCF作为Database实现推荐方案之一。他们的CTO分享了&lt;a href=&#34;https://bj2018.archsummit.com/presentation/1331&#34;&gt;TiDB on Kubernetes 最佳实践&lt;/a&gt;，以及他们客户北京银行在&lt;a href=&#34;https://bj2018.archsummit.com/presentation/962&#34;&gt;两地多活的核心系统&lt;/a&gt;中采用的数据库就是TiDB。&lt;/p&gt;

&lt;h3 id=&#34;个人感受&#34;&gt;个人感受&lt;/h3&gt;

&lt;p&gt;会议的分享者大多来自国内一线的互联网公司，他们普遍具备流量大、数据多、技术团队能力更强等特质。并且很少使用公有云服务，使用开源产品多数也会维护私有版本。他们的业务解决方案对中小型技术团队来说可复制性不强，照搬实施的难度高，更多的是在扩展思路了解业界技术动态。中小型技术团队最紧迫的事情是满足业务快速发展和需求多变，更合理的解法是选用云厂商的服务或第三方服务快速高效的满足业务需求。极客邦旗下的会议大多缺少这类的分享，相比之下AWS的reInvent大会在这方面做得更好。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
